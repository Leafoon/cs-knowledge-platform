# Chapter 14: Accelerate åº“å®Œå…¨æŒ‡å—

> **å®˜æ–¹æ–‡æ¡£**: https://huggingface.co/docs/accelerate  
> **GitHub**: https://github.com/huggingface/accelerate  
> **å‘å¸ƒç‰ˆæœ¬**: Accelerate v0.27+ï¼ˆ2026å¹´1æœˆï¼‰

## 14.1 Accelerate è®¾è®¡å“²å­¦

### 14.1.1 ç»Ÿä¸€çš„åˆ†å¸ƒå¼è®­ç»ƒæ¥å£

Hugging Face Accelerate æ˜¯ä¸€ä¸ªæ—¨åœ¨**å°†åˆ†å¸ƒå¼è®­ç»ƒçš„å¤æ‚æ€§é™åˆ°æœ€ä½**çš„åº“ã€‚å®ƒçš„æ ¸å¿ƒç†å¿µæ˜¯ï¼š

> **"å†™ä¸€æ¬¡ä»£ç ï¼Œåœ¨ä»»ä½•é…ç½®ä¸‹è¿è¡Œ"**

#### ä¼ ç»Ÿå¤š GPU è®­ç»ƒçš„ç—›ç‚¹

åœ¨ Accelerate å‡ºç°ä¹‹å‰ï¼Œç ”ç©¶äººå‘˜éœ€è¦ä¸ºä¸åŒç¡¬ä»¶é…ç½®ç¼–å†™ä¸åŒçš„ä»£ç ï¼š

```python
# å• GPU ä»£ç 
model = Model()
model.to("cuda")
optimizer = torch.optim.AdamW(model.parameters())

for batch in dataloader:
    outputs = model(batch)
    loss = outputs.loss
    loss.backward()
    optimizer.step()
```

```python
# å¤š GPU DDP ä»£ç ï¼ˆéœ€è¦å¤§é‡ä¿®æ”¹ï¼‰
import torch.distributed as dist
dist.init_process_group(backend='nccl')
local_rank = int(os.environ["LOCAL_RANK"])

model = Model()
model = model.to(local_rank)
model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])

sampler = DistributedSampler(dataset)
dataloader = DataLoader(dataset, sampler=sampler)
optimizer = torch.optim.AdamW(model.parameters())

for batch in dataloader:
    batch = {k: v.to(local_rank) for k, v in batch.items()}
    outputs = model(batch)
    loss = outputs.loss
    loss.backward()
    optimizer.step()
```

#### Accelerate çš„è§£å†³æ–¹æ¡ˆ

ä½¿ç”¨ Accelerate åï¼Œ**åªéœ€ä¿®æ”¹ 3-5 è¡Œä»£ç **ï¼Œå³å¯åœ¨å•å¡ã€å¤šå¡ã€æ··åˆç²¾åº¦ã€FSDPã€DeepSpeed ç­‰é…ç½®é—´è‡ªç”±åˆ‡æ¢ï¼š

```python
from accelerate import Accelerator

# 1. åˆ›å»º Accelerator å®ä¾‹
accelerator = Accelerator()

model = Model()
optimizer = torch.optim.AdamW(model.parameters())
dataloader = DataLoader(dataset, batch_size=32)

# 2. ä½¿ç”¨ prepare() åŒ…è£…
model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

for batch in dataloader:
    outputs = model(batch)
    loss = outputs.loss
    # 3. ä½¿ç”¨ backward() æ›¿ä»£ loss.backward()
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()
```

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… **ä»£ç ç»Ÿä¸€**ï¼šåŒä¸€ä»½ä»£ç å¯åœ¨ CPUã€å• GPUã€å¤š GPUã€TPU ä¸Šè¿è¡Œ
- âœ… **è‡ªåŠ¨è®¾å¤‡ç®¡ç†**ï¼š`prepare()` è‡ªåŠ¨å¤„ç†æ¨¡å‹ã€æ•°æ®çš„è®¾å¤‡åˆ†é…
- âœ… **æ··åˆç²¾åº¦æ”¯æŒ**ï¼šæ— éœ€æ‰‹åŠ¨ `autocast()` å’Œ `GradScaler`
- âœ… **æ¢¯åº¦ç´¯ç§¯**ï¼šè‡ªåŠ¨å¤„ç†è·¨è®¾å¤‡çš„æ¢¯åº¦åŒæ­¥
- âœ… **Checkpoint ç»Ÿä¸€**ï¼šä¸»è¿›ç¨‹ä¿å­˜ï¼Œå…¶ä»–è¿›ç¨‹è·³è¿‡

<div data-component="AccelerateWorkflow"></div>

---

### 14.1.2 ä¸ Trainer çš„å…³ç³»

Accelerate ä¸ Hugging Face `Trainer` çš„å…³ç³»ï¼š

| ç‰¹æ€§ | Trainer | Accelerate |
|------|---------|------------|
| **æŠ½è±¡å±‚çº§** | é«˜å±‚ APIï¼ˆéšè—è®­ç»ƒå¾ªç¯ï¼‰ | ä¸­å±‚ APIï¼ˆä¿ç•™è®­ç»ƒå¾ªç¯æ§åˆ¶ï¼‰ |
| **çµæ´»æ€§** | é€šè¿‡ callback å’Œ `TrainingArguments` å®šåˆ¶ | å®Œå…¨è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘ |
| **åˆ†å¸ƒå¼æ”¯æŒ** | å†…éƒ¨è°ƒç”¨ Accelerate | ç›´æ¥æš´éœ²åˆ†å¸ƒå¼ API |
| **é€‚ç”¨åœºæ™¯** | æ ‡å‡†ç›‘ç£å­¦ä¹ ã€å¾®è°ƒ | å¼ºåŒ–å­¦ä¹ ã€å¯¹æŠ—è®­ç»ƒã€è‡ªå®šä¹‰æŸå¤± |
| **å­¦ä¹ æ›²çº¿** | ä½ï¼ˆå‡ ä¹é›¶é…ç½®ï¼‰ | ä¸­ï¼ˆéœ€ç†è§£è®­ç»ƒå¾ªç¯ï¼‰ |

**Trainer åº•å±‚ä½¿ç”¨ Accelerate**ï¼š

```python
# Trainer å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
class Trainer:
    def __init__(self, args):
        self.accelerator = Accelerator(
            mixed_precision=args.fp16 or args.bf16,
            gradient_accumulation_steps=args.gradient_accumulation_steps,
        )
    
    def training_step(self, model, inputs):
        outputs = model(**inputs)
        loss = outputs.loss
        self.accelerator.backward(loss)  # å†…éƒ¨è°ƒç”¨ Accelerate
        return loss
```

**ä½•æ—¶ä½¿ç”¨ Accelerate è€Œé Trainer**ï¼š
1. éœ€è¦**è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯**ï¼ˆå¦‚ GAN çš„ç”Ÿæˆå™¨-åˆ¤åˆ«å™¨äº¤æ›¿è®­ç»ƒï¼‰
2. éæ ‡å‡†ä¼˜åŒ–å™¨æ›´æ–°ç­–ç•¥ï¼ˆå¦‚æ¢¯åº¦æƒ©ç½šã€æ¢¯åº¦è£å‰ªçš„ç‰¹æ®Šé¡ºåºï¼‰
3. å¤šæ¨¡å‹è”åˆè®­ç»ƒï¼ˆå¦‚å¤šä»»åŠ¡å­¦ä¹ éœ€è¦å¤šä¸ªæ¨¡å‹ï¼‰
4. å¸Œæœ›**æ˜¾å¼æ§åˆ¶**æ¯ä¸ªè®­ç»ƒæ­¥éª¤çš„ç»†èŠ‚

---

### 14.1.3 æ”¯æŒçš„åç«¯

Accelerate æ”¯æŒå¤šç§åˆ†å¸ƒå¼åç«¯ï¼Œå¹¶é€šè¿‡**ç»Ÿä¸€é…ç½®æ–‡ä»¶**ç®¡ç†ï¼š

| åç«¯ | æè¿° | é€‚ç”¨åœºæ™¯ | é…ç½®å…³é”®å­— |
|------|------|----------|------------|
| **DDP** | PyTorch DistributedDataParallel | å•æœºå¤šå¡ã€å°æ¨¡å‹ | `use_ddp: true` |
| **FSDP** | Fully Sharded Data Parallel | å¤§æ¨¡å‹ï¼ˆ7B-70Bï¼‰ | `use_fsdp: true` |
| **DeepSpeed** | å¾®è½¯ ZeRO ä¼˜åŒ–å™¨ | è¶…å¤§æ¨¡å‹ï¼ˆ70B+ï¼‰ã€éœ€è¦ Offload | `use_deepspeed: true` |
| **TPU** | Google Cloud TPU | TPU v2/v3/v4 | `tpu_config_file` |
| **MEGATRON-LM** | NVIDIA 3D å¹¶è¡Œ | åƒäº¿çº§æ¨¡å‹ | `use_megatron_lm: true` |

**è‡ªåŠ¨åç«¯é€‰æ‹©ç¤ºä¾‹**ï¼š

```bash
# é…ç½®å‘å¯¼ä¼šè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶å¹¶æ¨èåç«¯
$ accelerate config

In which compute environment are you running?
  [0] This machine
  [1] AWS (Amazon SageMaker)
Please select: 0

Which type of machine are you using?
  [0] No distributed training
  [1] multi-CPU
  [2] multi-GPU
  [3] TPU
Please select: 2

How many machines are you using? 1
How many processes in total? 4  # æ£€æµ‹åˆ° 4 ä¸ª GPU

Do you want to use FSDP? [yes/NO]: yes
# è‡ªåŠ¨ç”Ÿæˆ default_config.yaml æ–‡ä»¶
```

ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ `~/.cache/huggingface/accelerate/default_config.yaml`ï¼š

```yaml
compute_environment: LOCAL_MACHINE
distributed_type: FSDP
fsdp_config:
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_backward_prefetch_policy: BACKWARD_PRE
  fsdp_cpu_ram_efficient_loading: true
  fsdp_sharding_strategy: 1  # FULL_SHARD
  fsdp_state_dict_type: SHARDED_STATE_DICT
  fsdp_transformer_layer_cls_to_wrap: LlamaDecoderLayer
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 4
use_cpu: false
```

---

## 14.2 Accelerate åŸºç¡€å·¥ä½œæµ

### 14.2.1 accelerate config é…ç½®å‘å¯¼

`accelerate config` æ˜¯äº¤äº’å¼é…ç½®å·¥å…·ï¼Œä¼šç”Ÿæˆé€‚åˆå½“å‰ç¡¬ä»¶çš„é…ç½®æ–‡ä»¶ã€‚

#### é…ç½®æµç¨‹è¯¦è§£

```bash
$ accelerate config

# Step 1: è®¡ç®—ç¯å¢ƒ
In which compute environment are you running?
  [0] This machine
  [1] AWS (Amazon SageMaker)
Please select: 0

# Step 2: åˆ†å¸ƒå¼ç±»å‹
What type of machine are you using?
  [0] No distributed training
  [1] multi-CPU
  [2] multi-GPU
  [3] TPU
Please select: 2

# Step 3: GPU æ•°é‡
How many different machines will you use? 1
How many processes in total will you use? 4

# Step 4: æ··åˆç²¾åº¦
Do you wish to use FP16 or BF16 (mixed precision)?
  [0] no
  [1] fp16
  [2] bf16
  [3] fp8
Please select: 2

# Step 5: DeepSpeedï¼ˆå¯é€‰ï¼‰
Do you want to use DeepSpeed? [yes/NO]: no

# Step 6: FSDPï¼ˆå¯é€‰ï¼‰
Do you want to use FullyShardedDataParallel? [yes/NO]: yes

# FSDP è¯¦ç»†é…ç½®
What should be your sharding strategy?
  [0] FULL_SHARD (ZeRO-3)
  [1] SHARD_GRAD_OP (ZeRO-2)
  [2] NO_SHARD (DDP)
Please select: 0

Do you want to offload parameters to CPU? [yes/NO]: no

# æœ€ç»ˆç”Ÿæˆé…ç½®æ–‡ä»¶
accelerate configuration saved at ~/.cache/huggingface/accelerate/default_config.yaml
```

#### æ‰‹åŠ¨ç¼–å†™é…ç½®æ–‡ä»¶

ä¹Ÿå¯ä»¥è·³è¿‡å‘å¯¼ï¼Œç›´æ¥åˆ›å»º `accelerate_config.yaml`ï¼š

```yaml
# accelerate_config.yaml
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: all
machine_rank: 0
main_process_ip: null
main_process_port: null
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 4  # ä½¿ç”¨ 4 ä¸ª GPU
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

**ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶å¯åŠ¨**ï¼š

```bash
accelerate launch --config_file accelerate_config.yaml train.py
```

---

### 14.2.2 Accelerator ç±»æ ¸å¿ƒ API

`Accelerator` æ˜¯ Accelerate çš„æ ¸å¿ƒç±»ï¼Œæä¾›ä»¥ä¸‹å…³é”®æ–¹æ³•ï¼š

#### åˆå§‹åŒ–å‚æ•°

```python
from accelerate import Accelerator

accelerator = Accelerator(
    # æ··åˆç²¾åº¦
    mixed_precision='bf16',  # 'no' | 'fp16' | 'bf16' | 'fp8'
    
    # æ¢¯åº¦ç´¯ç§¯
    gradient_accumulation_steps=4,  # æ¯ 4 æ­¥æ›´æ–°ä¸€æ¬¡å‚æ•°
    
    # Logging
    log_with='tensorboard',  # 'tensorboard' | 'wandb' | 'comet_ml'
    project_dir='./outputs',  # checkpoint ä¿å­˜è·¯å¾„
    
    # CPU Offload
    cpu=False,  # å¼ºåˆ¶ä½¿ç”¨ CPU
    
    # è®¾å¤‡æ”¾ç½®ç­–ç•¥
    device_placement=True,  # è‡ªåŠ¨å°†æ¨¡å‹/æ•°æ®ç§»åˆ°è®¾å¤‡
    
    # åˆ†å¸ƒå¼åç«¯ï¼ˆé€šå¸¸ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
    # dispatch_batchesã€split_batches ç­‰é«˜çº§é€‰é¡¹
)
```

#### prepare() æ–¹æ³•

**æœ€é‡è¦çš„æ–¹æ³•**ï¼Œç”¨äºåŒ…è£…æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨ï¼š

```python
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

**å†…éƒ¨æœºåˆ¶**ï¼š
1. **æ¨¡å‹åŒ…è£…**ï¼š
   - å• GPU â†’ `model.to(device)`
   - å¤š GPU DDP â†’ `torch.nn.parallel.DistributedDataParallel(model)`
   - FSDP â†’ `FullyShardedDataParallel(model)`
   
2. **ä¼˜åŒ–å™¨åŒ…è£…**ï¼š
   - æ·»åŠ æ··åˆç²¾åº¦çš„ `GradScaler`ï¼ˆè‹¥å¯ç”¨ FP16ï¼‰
   - é›†æˆæ¢¯åº¦ç´¯ç§¯é€»è¾‘
   
3. **æ•°æ®åŠ è½½å™¨åŒ…è£…**ï¼š
   - è‡ªåŠ¨æ·»åŠ  `DistributedSampler`ï¼ˆå¤š GPUï¼‰
   - å¤„ç† batch size ä¸ GPU æ•°é‡çš„å…³ç³»

#### backward() æ–¹æ³•

```python
accelerator.backward(loss)
```

ç­‰ä»·äºï¼š
```python
# å• GPU
loss.backward()

# FP16 æ··åˆç²¾åº¦
scaler.scale(loss).backward()

# æ¢¯åº¦ç´¯ç§¯
(loss / gradient_accumulation_steps).backward()
```

#### å…¶ä»–æ ¸å¿ƒæ–¹æ³•

```python
# æ”¶é›†åˆ†å¸ƒå¼ç»“æœ
all_losses = accelerator.gather(loss)  # ä»æ‰€æœ‰è¿›ç¨‹æ”¶é›†

# ç­‰å¾…æ‰€æœ‰è¿›ç¨‹
accelerator.wait_for_everyone()

# æ‰“å°ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
accelerator.print(f"Epoch {epoch} completed")

# ä¸»è¿›ç¨‹æ£€æŸ¥
if accelerator.is_main_process:
    model.save_pretrained("./outputs")

# ä¿å­˜/åŠ è½½ checkpoint
accelerator.save_state("checkpoint_dir")  # ä¿å­˜ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€RNG çŠ¶æ€
accelerator.load_state("checkpoint_dir")

# Logging
accelerator.log({"train_loss": loss.item(), "lr": lr}, step=global_step)

# ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with accelerator.accumulate(model):  # æ¢¯åº¦ç´¯ç§¯ä¸Šä¸‹æ–‡
    outputs = model(batch)
    loss = outputs.loss
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()
```

<div data-component="AcceleratorAPIDemo"></div>

---

### 14.2.3 ä»£ç ä¿®æ”¹æœ€å°åŒ–ï¼ˆ3 è¡Œæ”¹åŠ¨ï¼‰

ä»å• GPU ä»£ç è¿ç§»åˆ° Accelerate çš„**æœ€å°ä¿®æ”¹ç¤ºä¾‹**ï¼š

#### åŸå§‹å• GPU ä»£ç 

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from torch.utils.data import DataLoader

# æ¨¡å‹å’Œæ•°æ®
model = AutoModelForCausalLM.from_pretrained("gpt2")
model.to("cuda")
tokenizer = AutoTokenizer.from_pretrained("gpt2")
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

train_dataset = ...
train_dataloader = DataLoader(train_dataset, batch_size=8)

# è®­ç»ƒå¾ªç¯
for epoch in range(3):
    for batch in train_dataloader:
        batch = {k: v.to("cuda") for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        print(f"Loss: {loss.item()}")
```

#### Accelerate ç‰ˆæœ¬ï¼ˆä»… 3 å¤„ä¿®æ”¹ï¼‰

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from torch.utils.data import DataLoader
from accelerate import Accelerator  # å¯¼å…¥

# âœ… ä¿®æ”¹ 1: åˆ›å»º Accelerator
accelerator = Accelerator()

# æ¨¡å‹å’Œæ•°æ®
model = AutoModelForCausalLM.from_pretrained("gpt2")
# model.to("cuda")  # âŒ åˆ é™¤æ‰‹åŠ¨è®¾å¤‡åˆ†é…
tokenizer = AutoTokenizer.from_pretrained("gpt2")
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

train_dataset = ...
train_dataloader = DataLoader(train_dataset, batch_size=8)

# âœ… ä¿®æ”¹ 2: ä½¿ç”¨ prepare() åŒ…è£…
model, optimizer, train_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader
)

# è®­ç»ƒå¾ªç¯
for epoch in range(3):
    for batch in train_dataloader:
        # batch = {k: v.to("cuda") for k, v in batch.items()}  # âŒ åˆ é™¤
        outputs = model(**batch)
        loss = outputs.loss
        
        # âœ… ä¿®æ”¹ 3: ä½¿ç”¨ accelerator.backward()
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
        
        accelerator.print(f"Loss: {loss.item()}")  # ä»…ä¸»è¿›ç¨‹æ‰“å°
```

**3 è¡Œä¿®æ”¹æ€»ç»“**ï¼š
1. `accelerator = Accelerator()`
2. `model, optimizer, dataloader = accelerator.prepare(...)`
3. `accelerator.backward(loss)` æ›¿æ¢ `loss.backward()`

**é¢å¤–æ”¶ç›Š**ï¼š
- è‡ªåŠ¨æ”¯æŒå¤š GPUï¼ˆæ— éœ€ä¿®æ”¹ä»£ç ï¼Œä»…éœ€ `accelerate launch --num_processes=4 train.py`ï¼‰
- è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆæ·»åŠ  `--mixed_precision bf16`ï¼‰
- è‡ªåŠ¨æ¢¯åº¦ç´¯ç§¯ï¼ˆ`Accelerator(gradient_accumulation_steps=4)`ï¼‰

---

### 14.2.4 accelerate launch å¯åŠ¨è„šæœ¬

#### åŸºç¡€å¯åŠ¨

```bash
# å• GPU
accelerate launch train.py

# å¤š GPUï¼ˆ4 å¡ï¼‰
accelerate launch --num_processes=4 train.py

# æŒ‡å®š GPU
CUDA_VISIBLE_DEVICES=0,1,2 accelerate launch --num_processes=3 train.py

# ä½¿ç”¨é…ç½®æ–‡ä»¶
accelerate launch --config_file fsdp_config.yaml train.py

# æ··åˆç²¾åº¦
accelerate launch --mixed_precision bf16 --num_processes=4 train.py
```

#### å¤šæœºè®­ç»ƒ

**ä¸»èŠ‚ç‚¹ï¼ˆæœºå™¨ 0ï¼‰**ï¼š
```bash
accelerate launch \
    --num_processes=8 \  # æ€»è¿›ç¨‹æ•°ï¼ˆ2 æœºå™¨ Ã— 4 GPUï¼‰
    --num_machines=2 \
    --machine_rank=0 \
    --main_process_ip=192.168.1.100 \
    --main_process_port=29500 \
    train.py
```

**ä»èŠ‚ç‚¹ï¼ˆæœºå™¨ 1ï¼‰**ï¼š
```bash
accelerate launch \
    --num_processes=8 \
    --num_machines=2 \
    --machine_rank=1 \
    --main_process_ip=192.168.1.100 \
    --main_process_port=29500 \
    train.py
```

#### ä¸ torchrun çš„å¯¹æ¯”

```bash
# Accelerate æ–¹å¼
accelerate launch --num_processes=4 train.py

# ç­‰ä»·çš„ torchrun æ–¹å¼
torchrun --nproc_per_node=4 train.py
```

**Accelerate çš„ä¼˜åŠ¿**ï¼š
- ç»Ÿä¸€çš„é…ç½®æ–‡ä»¶ç®¡ç†
- è‡ªåŠ¨å¤„ç†ç¯å¢ƒå˜é‡ï¼ˆ`RANK`ã€`LOCAL_RANK`ã€`WORLD_SIZE`ï¼‰
- æ›´å‹å¥½çš„é”™è¯¯æç¤º
- æ”¯æŒ FSDP/DeepSpeed çš„é«˜çº§é…ç½®

---

## 14.3 ä»å•å¡åˆ°å¤šå¡

### 14.3.1 å• GPU è®­ç»ƒ

æœ€ç®€å•çš„åœºæ™¯ï¼ŒAccelerate ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å•ä¸ª GPUï¼š

```python
from accelerate import Accelerator
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from datasets import load_dataset
from torch.utils.data import DataLoader

accelerator = Accelerator()

# åŠ è½½æ¨¡å‹
model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# å‡†å¤‡æ•°æ®
dataset = load_dataset("glue", "sst2", split="train[:1000]")
def tokenize_function(examples):
    return tokenizer(examples["sentence"], padding="max_length", truncation=True)

tokenized_dataset = dataset.map(tokenize_function, batched=True)
tokenized_dataset.set_format("torch", columns=["input_ids", "attention_mask", "label"])
train_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=True)

# å‡†å¤‡è®­ç»ƒ
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)

# è®­ç»ƒ
model.train()
for epoch in range(3):
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
    
    accelerator.print(f"Epoch {epoch} completed, Loss: {loss.item():.4f}")
```

**é¢„æœŸè¾“å‡º**ï¼š

```
Epoch 0 completed, Loss: 0.6234
Epoch 1 completed, Loss: 0.3421
Epoch 2 completed, Loss: 0.1876
```

**å• GPU ä¸‹çš„ Accelerate è¡Œä¸º**ï¼š
- `prepare()` å°†æ¨¡å‹ç§»è‡³ `cuda:0`
- `backward()` ç­‰ä»·äº `loss.backward()`
- ä¸ä¼šåˆ›å»ºåˆ†å¸ƒå¼è¿›ç¨‹

---

### 14.3.2 å¤š GPU å•æœºï¼ˆDDPï¼‰

**æ— éœ€ä¿®æ”¹ä»£ç **ï¼Œä»…éœ€æ›´æ”¹å¯åŠ¨å‘½ä»¤ï¼š

```bash
# ä½¿ç”¨ 4 ä¸ª GPU
accelerate launch --multi_gpu --num_processes=4 train.py
```

**æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶**ï¼š

```yaml
# ddp_config.yaml
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
num_processes: 4
mixed_precision: bf16
use_cpu: false
```

```bash
accelerate launch --config_file ddp_config.yaml train.py
```

#### DDP å†…éƒ¨æœºåˆ¶

å½“æ£€æµ‹åˆ°å¤š GPU æ—¶ï¼ŒAccelerate ä¼šï¼š

1. **åˆå§‹åŒ–è¿›ç¨‹ç»„**ï¼š
   ```python
   torch.distributed.init_process_group(backend='nccl')
   ```

2. **ä¸ºæ¯ä¸ªè¿›ç¨‹åˆ†é… GPU**ï¼š
   - è¿›ç¨‹ 0 â†’ `cuda:0`
   - è¿›ç¨‹ 1 â†’ `cuda:1`
   - è¿›ç¨‹ 2 â†’ `cuda:2`
   - è¿›ç¨‹ 3 â†’ `cuda:3`

3. **åŒ…è£…æ¨¡å‹ä¸º DDP**ï¼š
   ```python
   model = torch.nn.parallel.DistributedDataParallel(
       model,
       device_ids=[local_rank],
       output_device=local_rank
   )
   ```

4. **æ•°æ®åŠ è½½å™¨æ·»åŠ é‡‡æ ·å™¨**ï¼š
   ```python
   sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)
   dataloader = DataLoader(dataset, sampler=sampler, batch_size=16)
   ```

5. **æ¢¯åº¦åŒæ­¥**ï¼š
   - æ¯ä¸ª GPU ç‹¬ç«‹å‰å‘ä¼ æ’­
   - `backward()` æ—¶è‡ªåŠ¨ all-reduce æ¢¯åº¦
   - æ‰€æœ‰ GPU ä½¿ç”¨ç›¸åŒçš„æ¢¯åº¦æ›´æ–°å‚æ•°

<div data-component="DistributedCommunicationVisualizer"></div>

#### æœ‰æ•ˆ Batch Size è®¡ç®—

```python
# DDP é…ç½®
num_gpus = 4
per_device_batch_size = 8
gradient_accumulation_steps = 2

# æœ‰æ•ˆ batch size è®¡ç®—
effective_batch_size = (
    per_device_batch_size 
    * num_gpus 
    * gradient_accumulation_steps
)
# = 8 Ã— 4 Ã— 2 = 64
```

**ä»£ç ç¤ºä¾‹**ï¼š

```python
accelerator = Accelerator(gradient_accumulation_steps=2)
model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

for batch in dataloader:
    # ä½¿ç”¨ç´¯ç§¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with accelerator.accumulate(model):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

å¯åŠ¨æ—¶ batch size ä¸º 8ï¼Œä½†æ¯ 2 æ­¥æ‰æ›´æ–°ä¸€æ¬¡å‚æ•°ï¼Œå› æ­¤æ¯ä¸ª GPU çš„æœ‰æ•ˆ batch size = 8 Ã— 2 = 16ï¼Œæ€»æœ‰æ•ˆ batch size = 16 Ã— 4 = 64ã€‚

---

### 14.3.3 å¤šæœºå¤šå¡é›†ç¾¤

#### ç¯å¢ƒè¦æ±‚

1. **ç½‘ç»œäº’é€š**ï¼šæ‰€æœ‰èŠ‚ç‚¹å¯é€šè¿‡ IP äº’ç›¸è®¿é—®
2. **å…±äº«æ–‡ä»¶ç³»ç»Ÿ**ï¼ˆå¯é€‰ä½†æ¨èï¼‰ï¼šNFSã€Lustre ç­‰
3. **ç›¸åŒ CUDA/PyTorch ç‰ˆæœ¬**
4. **SSH å…å¯†ç™»å½•**ï¼ˆè‹¥ä½¿ç”¨è‡ªåŠ¨å¯åŠ¨è„šæœ¬ï¼‰

#### æ‰‹åŠ¨å¯åŠ¨æ–¹å¼

**æœºå™¨ 0ï¼ˆ192.168.1.10ï¼Œ4 ä¸ª GPUï¼‰**ï¼š

```bash
export MASTER_ADDR=192.168.1.10
export MASTER_PORT=29500
export WORLD_SIZE=8  # 2 æœºå™¨ Ã— 4 GPU
export RANK=0

accelerate launch \
    --num_processes=8 \
    --num_machines=2 \
    --machine_rank=0 \
    --main_process_ip=$MASTER_ADDR \
    --main_process_port=$MASTER_PORT \
    train.py
```

**æœºå™¨ 1ï¼ˆ192.168.1.11ï¼Œ4 ä¸ª GPUï¼‰**ï¼š

```bash
export MASTER_ADDR=192.168.1.10
export MASTER_PORT=29500
export WORLD_SIZE=8
export RANK=1

accelerate launch \
    --num_processes=8 \
    --num_machines=2 \
    --machine_rank=1 \
    --main_process_ip=$MASTER_ADDR \
    --main_process_port=$MASTER_PORT \
    train.py
```

#### ä½¿ç”¨ SLURM é›†ç¾¤

```bash
#!/bin/bash
#SBATCH --job-name=accelerate_train
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4
#SBATCH --gpus-per-node=4
#SBATCH --cpus-per-task=8
#SBATCH --time=24:00:00

# åŠ è½½ç¯å¢ƒ
module load cuda/11.8
source ~/miniconda3/bin/activate transformers_env

# è·å–ä¸»èŠ‚ç‚¹ä¿¡æ¯
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=29500

# å¯åŠ¨è®­ç»ƒ
srun accelerate launch \
    --num_processes=$SLURM_NTASKS \
    --num_machines=$SLURM_NNODES \
    --machine_rank=$SLURM_NODEID \
    --main_process_ip=$MASTER_ADDR \
    --main_process_port=$MASTER_PORT \
    train.py
```

æäº¤ä»»åŠ¡ï¼š
```bash
sbatch train_slurm.sh
```

---

### 14.3.4 æ··åˆç²¾åº¦é›†æˆ

#### FP16 vs BF16 é€‰æ‹©

| ç‰¹æ€§ | FP16 | BF16 |
|------|------|------|
| **åŠ¨æ€èŒƒå›´** | å°ï¼ˆ5.96e-08 ~ 65504ï¼‰ | å¤§ï¼ˆ1.18e-38 ~ 3.39e+38ï¼‰ |
| **ç²¾åº¦** | é«˜ï¼ˆ10 ä½å°¾æ•°ï¼‰ | ä½ï¼ˆ7 ä½å°¾æ•°ï¼‰ |
| **æº¢å‡ºé£é™©** | é«˜ï¼ˆéœ€è¦ Loss Scalingï¼‰ | ä½ï¼ˆæ— éœ€ Loss Scalingï¼‰ |
| **ç¡¬ä»¶æ”¯æŒ** | V100+ã€A100ã€H100 | A100+ã€H100ï¼ˆéœ€ Ampere æ¶æ„ï¼‰ |
| **æ¨èåœºæ™¯** | å°æ¨¡å‹ã€æ¨ç† | å¤§æ¨¡å‹è®­ç»ƒï¼ˆLLMï¼‰ |

#### å¯ç”¨æ··åˆç²¾åº¦

**æ–¹å¼ 1ï¼šå¯åŠ¨å‚æ•°**

```bash
accelerate launch --mixed_precision bf16 --num_processes=4 train.py
```

**æ–¹å¼ 2ï¼šä»£ç ä¸­æŒ‡å®š**

```python
accelerator = Accelerator(mixed_precision='bf16')
```

**æ–¹å¼ 3ï¼šé…ç½®æ–‡ä»¶**

```yaml
# config.yaml
mixed_precision: bf16
```

#### FP16 çš„ Loss Scaling

FP16 è®­ç»ƒæ—¶ï¼ŒAccelerate ä¼šè‡ªåŠ¨åº”ç”¨åŠ¨æ€ Loss Scalingï¼š

```python
# å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
from torch.cuda.amp import GradScaler

scaler = GradScaler()

for batch in dataloader:
    with autocast(dtype=torch.float16):
        outputs = model(**batch)
        loss = outputs.loss
    
    # æ”¾å¤§ loss é˜²æ­¢æ¢¯åº¦ä¸‹æº¢
    scaler.scale(loss).backward()
    
    # Unscale æ¢¯åº¦å¹¶æ£€æŸ¥ inf/nan
    scaler.unscale_(optimizer)
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    
    # æ›´æ–°å‚æ•°
    scaler.step(optimizer)
    scaler.update()
    optimizer.zero_grad()
```

**ç”¨æˆ·ä»£ç **ï¼ˆæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼‰ï¼š

```python
accelerator = Accelerator(mixed_precision='fp16')
model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

for batch in dataloader:
    outputs = model(**batch)
    loss = outputs.loss
    accelerator.backward(loss)  # è‡ªåŠ¨å¤„ç† scaling
    optimizer.step()
    optimizer.zero_grad()
```

#### BF16 ä¼˜åŠ¿ç¤ºä¾‹

```python
import torch

# FP16 ä¼šæº¢å‡º
fp16_large = torch.tensor([65000.0], dtype=torch.float16)
fp16_result = fp16_large * 2  # ç»“æœï¼šinfï¼ˆæº¢å‡ºï¼‰

# BF16 ä¸ä¼šæº¢å‡º
bf16_large = torch.tensor([65000.0], dtype=torch.bfloat16)
bf16_result = bf16_large * 2  # ç»“æœï¼š130000.0ï¼ˆæ­£å¸¸ï¼‰

print(f"FP16: {fp16_result.item()}")  # inf
print(f"BF16: {bf16_result.item()}")  # 130000.0
```

---

## 14.4 Accelerator é«˜çº§åŠŸèƒ½

### 14.4.1 æ¢¯åº¦ç´¯ç§¯

æ¢¯åº¦ç´¯ç§¯å…è®¸ç”¨**æ›´å°çš„ batch size** æ¨¡æ‹Ÿ**æ›´å¤§çš„ batch size**ï¼ŒèŠ‚çœæ˜¾å­˜ã€‚

#### åŸºç¡€ç”¨æ³•

```python
accelerator = Accelerator(gradient_accumulation_steps=4)
model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

for batch in dataloader:
    with accelerator.accumulate(model):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

**å·¥ä½œåŸç†**ï¼š
- å‰ 3 æ¬¡è¿­ä»£ï¼šä»…è®¡ç®—æ¢¯åº¦ï¼Œ**ä¸æ›´æ–°å‚æ•°**
- ç¬¬ 4 æ¬¡è¿­ä»£ï¼šç´¯ç§¯çš„æ¢¯åº¦å¹³å‡åæ›´æ–°å‚æ•°

#### æ‰‹åŠ¨å®ç°å¯¹æ¯”

```python
# æ‰‹åŠ¨å®ç°æ¢¯åº¦ç´¯ç§¯ï¼ˆä¸æ¨èï¼‰
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    outputs = model(**batch)
    loss = outputs.loss / accumulation_steps  # âŒ éœ€è¦æ‰‹åŠ¨é™¤ä»¥æ­¥æ•°
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()

# Accelerate è‡ªåŠ¨å®ç°ï¼ˆæ¨èï¼‰
with accelerator.accumulate(model):
    outputs = model(**batch)
    loss = outputs.loss  # âœ… æ— éœ€æ‰‹åŠ¨é™¤æ³•
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()
```

#### åˆ†å¸ƒå¼ç¯å¢ƒä¸‹çš„æ¢¯åº¦ç´¯ç§¯

åœ¨å¤š GPU ç¯å¢ƒä¸­ï¼Œæ¢¯åº¦ç´¯ç§¯éœ€è¦ç‰¹æ®Šå¤„ç†ï¼š

```python
# 4 ä¸ª GPUï¼Œæ¯ä¸ª batch_size=8ï¼Œç´¯ç§¯ 4 æ­¥
# æœ‰æ•ˆ batch size = 8 Ã— 4 GPU Ã— 4 æ­¥ = 128

accelerator = Accelerator(gradient_accumulation_steps=4)

for batch in dataloader:
    with accelerator.accumulate(model):
        outputs = model(**batch)
        loss = outputs.loss
        
        # Accelerate ä¼šåœ¨ç´¯ç§¯æ­¥æ•°ç»“æŸæ—¶è‡ªåŠ¨åŒæ­¥æ¢¯åº¦
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

**å†…éƒ¨æœºåˆ¶**ï¼š
- ç´¯ç§¯æœŸé—´ï¼š`model.require_backward_grad_sync = False`ï¼ˆè·³è¿‡æ¢¯åº¦åŒæ­¥ï¼‰
- æœ€åä¸€æ­¥ï¼š`model.require_backward_grad_sync = True`ï¼ˆæ‰§è¡Œ all-reduceï¼‰

---

### 14.4.2 Checkpoint ä¿å­˜ä¸æ¢å¤

#### ä¿å­˜å®Œæ•´è®­ç»ƒçŠ¶æ€

```python
# ä¿å­˜ checkpointï¼ˆåŒ…å«æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€RNG çŠ¶æ€ï¼‰
output_dir = "checkpoint-1000"
accelerator.save_state(output_dir)
```

ç”Ÿæˆçš„ç›®å½•ç»“æ„ï¼š

```
checkpoint-1000/
â”œâ”€â”€ pytorch_model.bin       # æ¨¡å‹æƒé‡
â”œâ”€â”€ optimizer.bin           # ä¼˜åŒ–å™¨çŠ¶æ€
â”œâ”€â”€ scheduler.bin           # å­¦ä¹ ç‡è°ƒåº¦å™¨
â”œâ”€â”€ random_states_0.pkl     # RNG çŠ¶æ€ï¼ˆè¿›ç¨‹ 0ï¼‰
â”œâ”€â”€ random_states_1.pkl     # RNG çŠ¶æ€ï¼ˆè¿›ç¨‹ 1ï¼‰
â”œâ”€â”€ ...
â””â”€â”€ scaler.pt               # GradScaler çŠ¶æ€ï¼ˆFP16 æ—¶ï¼‰
```

#### æ¢å¤è®­ç»ƒ

```python
# æ¢å¤æ‰€æœ‰çŠ¶æ€
accelerator.load_state("checkpoint-1000")

# ç»§ç»­è®­ç»ƒ
for batch in dataloader:
    outputs = model(**batch)
    loss = outputs.loss
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()
```

#### ä»…ä¿å­˜æ¨¡å‹æƒé‡

```python
# ä»…ä¿å­˜æ¨¡å‹ï¼ˆç”¨äºæ¨ç†æˆ–åç»­å¾®è°ƒï¼‰
unwrapped_model = accelerator.unwrap_model(model)
accelerator.save(unwrapped_model.state_dict(), "model_weights.bin")
```

**ä¸ºä»€ä¹ˆéœ€è¦ `unwrap_model`**ï¼Ÿ

åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹ï¼Œ`prepare()` ä¼šåŒ…è£…æ¨¡å‹ä¸º `DDP` æˆ– `FSDP`ï¼Œå¯¼è‡´ state_dict çš„ key å‰ç¼€å‘ç”Ÿå˜åŒ–ï¼š

```python
# åŸå§‹æ¨¡å‹
model.transformer.h.0.attn.c_attn.weight

# DDP åŒ…è£…å
module.transformer.h.0.attn.c_attn.weight  # å¤šäº† "module." å‰ç¼€
```

`unwrap_model()` å¯ä»¥å»é™¤åŒ…è£…ï¼Œæ¢å¤åŸå§‹ç»“æ„ï¼š

```python
wrapped_model = accelerator.prepare(model)
print(list(wrapped_model.state_dict().keys())[:3])
# ['module.transformer.wte.weight', 'module.transformer.wpe.weight', ...]

unwrapped_model = accelerator.unwrap_model(wrapped_model)
print(list(unwrapped_model.state_dict().keys())[:3])
# ['transformer.wte.weight', 'transformer.wpe.weight', ...]
```

#### ä¸ Hugging Face Hub é›†æˆ

```python
from huggingface_hub import HfApi

# ä¿å­˜åˆ°æœ¬åœ°
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained("./my_finetuned_model")
tokenizer.save_pretrained("./my_finetuned_model")

# ä¸Šä¼ åˆ° Hub
if accelerator.is_main_process:
    api = HfApi()
    api.upload_folder(
        folder_path="./my_finetuned_model",
        repo_id="username/my-model",
        repo_type="model"
    )
```

---

### 14.4.3 Logging ä¸åŒæ­¥

#### é›†æˆ TensorBoard

```python
from accelerate import Accelerator

accelerator = Accelerator(log_with="tensorboard", project_dir="./logs")

# åˆå§‹åŒ– tracker
accelerator.init_trackers(project_name="my_experiment")

# è®­ç»ƒå¾ªç¯ä¸­è®°å½•æŒ‡æ ‡
for step, batch in enumerate(dataloader):
    outputs = model(**batch)
    loss = outputs.loss
    
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()
    
    # è®°å½• loss
    accelerator.log({"train_loss": loss.item()}, step=step)

# ç»“æŸè®°å½•
accelerator.end_training()
```

å¯åŠ¨ TensorBoardï¼š
```bash
tensorboard --logdir ./logs
```

#### é›†æˆ Weights & Biases

```python
accelerator = Accelerator(log_with="wandb")

# åˆå§‹åŒ–ï¼ˆä»…ä¸»è¿›ç¨‹ç™»å½•ï¼‰
accelerator.init_trackers(
    project_name="transformers-training",
    config={
        "learning_rate": 2e-5,
        "batch_size": 16,
        "epochs": 3
    },
    init_kwargs={"wandb": {"entity": "my-team"}}
)

# è®°å½•æŒ‡æ ‡
accelerator.log({
    "train_loss": loss.item(),
    "learning_rate": optimizer.param_groups[0]['lr'],
    "epoch": epoch
}, step=global_step)

# è®°å½•æ¨¡å‹
if accelerator.is_main_process:
    wandb.save("model_checkpoint.bin")
```

#### å¤šè¿›ç¨‹æ—¥å¿—åŒæ­¥

```python
# gather() æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„å€¼
losses = []
for batch in dataloader:
    outputs = model(**batch)
    loss = outputs.loss
    losses.append(loss)
    
    accelerator.backward(loss)
    optimizer.step()
    optimizer.zero_grad()

# æ”¶é›†æ‰€æœ‰ GPU çš„ loss
all_losses = accelerator.gather(torch.stack(losses))

# ä»…ä¸»è¿›ç¨‹æ‰“å°
if accelerator.is_main_process:
    avg_loss = all_losses.mean().item()
    print(f"Average loss across all GPUs: {avg_loss:.4f}")
```

**gather() è¯¦è§£**ï¼š

```python
# å‡è®¾ 4 ä¸ª GPUï¼Œæ¯ä¸ªè®¡ç®—äº†ä¸€ä¸ª loss
# GPU 0: loss = 0.5
# GPU 1: loss = 0.6
# GPU 2: loss = 0.55
# GPU 3: loss = 0.58

loss_tensor = torch.tensor([loss])  # å½“å‰è¿›ç¨‹çš„ loss
all_losses = accelerator.gather(loss_tensor)

# ç»“æœï¼ˆä»…åœ¨ä¸»è¿›ç¨‹æœ‰æ•ˆï¼Œå…¶ä»–è¿›ç¨‹ä¸º Noneï¼‰
# all_losses = tensor([0.5, 0.6, 0.55, 0.58])
```

---

### 14.4.4 ä¸»è¿›ç¨‹æ§åˆ¶ï¼ˆmain_process_firstï¼‰

æŸäº›æ“ä½œï¼ˆå¦‚æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹ä¸‹è½½ï¼‰åªéœ€åœ¨ä¸»è¿›ç¨‹æ‰§è¡Œï¼Œå…¶ä»–è¿›ç¨‹ç­‰å¾…ï¼š

#### æ•°æ®é›†é¢„å¤„ç†

```python
from datasets import load_dataset

with accelerator.main_process_first():
    # ä»…ä¸»è¿›ç¨‹ä¸‹è½½å’Œå¤„ç†æ•°æ®é›†
    dataset = load_dataset("glue", "sst2")
    tokenized_dataset = dataset.map(tokenize_function, batched=True)

# æ‰€æœ‰è¿›ç¨‹åœ¨æ­¤åŒæ­¥ï¼Œç¡®ä¿æ•°æ®é›†å·²å‡†å¤‡å¥½
dataloader = DataLoader(tokenized_dataset, batch_size=16)
```

**ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ª**ï¼Ÿ

åœ¨å¤š GPU ç¯å¢ƒä¸‹ï¼Œå¦‚æœæ‰€æœ‰è¿›ç¨‹åŒæ—¶ä¸‹è½½æ•°æ®é›†ï¼Œä¼šå¯¼è‡´ï¼š
- ç½‘ç»œå¸¦å®½æµªè´¹
- æ–‡ä»¶ç³»ç»Ÿç«äº‰ï¼ˆå¤šä¸ªè¿›ç¨‹å†™å…¥åŒä¸€ç¼“å­˜æ–‡ä»¶ï¼‰
- å¯èƒ½çš„æ•°æ®æŸå

`main_process_first()` ç¡®ä¿ï¼š
1. ä¸»è¿›ç¨‹ï¼ˆRank 0ï¼‰å…ˆæ‰§è¡Œ
2. å…¶ä»–è¿›ç¨‹åœ¨ barrier å¤„ç­‰å¾…
3. ä¸»è¿›ç¨‹å®Œæˆåé‡Šæ”¾ barrier
4. æ‰€æœ‰è¿›ç¨‹ç»§ç»­æ‰§è¡Œ

#### æ¨¡å‹ä¸‹è½½

```python
with accelerator.main_process_first():
    model = AutoModelForCausalLM.from_pretrained("gpt2")
    # æ¨¡å‹ä¼šç¼“å­˜åˆ° ~/.cache/huggingface/hub/

# å…¶ä»–è¿›ç¨‹ç›´æ¥ä»ç¼“å­˜åŠ è½½ï¼Œæ— éœ€é‡å¤ä¸‹è½½
```

#### è‡ªå®šä¹‰æ“ä½œ

```python
if accelerator.is_main_process:
    # ä»…ä¸»è¿›ç¨‹æ‰§è¡Œ
    print("Preparing data...")
    prepare_custom_data()

# åŒæ­¥æ‰€æœ‰è¿›ç¨‹
accelerator.wait_for_everyone()

# æ‰€æœ‰è¿›ç¨‹ç»§ç»­
dataloader = load_prepared_data()
```

---

## 14.5 ä¸ Trainer é›†æˆ

### 14.5.1 Trainer è‡ªåŠ¨æ£€æµ‹ Accelerate é…ç½®

Hugging Face `Trainer` **å†…éƒ¨ä½¿ç”¨ Accelerate**ï¼Œå› æ­¤ `accelerate config` ç”Ÿæˆçš„é…ç½®ä¼šè‡ªåŠ¨ç”Ÿæ•ˆï¼š

```python
from transformers import Trainer, TrainingArguments

# é…ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./outputs",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    # Trainer ä¼šè‡ªåŠ¨è¯»å– ~/.cache/huggingface/accelerate/default_config.yaml
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

# å¯åŠ¨è®­ç»ƒ
trainer.train()
```

å¯åŠ¨å‘½ä»¤ï¼š

```bash
# æ–¹å¼ 1: ä½¿ç”¨ accelerate launchï¼ˆæ¨èï¼‰
accelerate launch train_with_trainer.py

# æ–¹å¼ 2: ç›´æ¥è¿è¡Œï¼ˆTrainer ä¼šè‡ªåŠ¨æ£€æµ‹é…ç½®ï¼‰
python train_with_trainer.py
```

#### Trainer å†…éƒ¨ Accelerate é›†æˆ

```python
# Trainer å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
class Trainer:
    def __init__(self, args):
        # è‡ªåŠ¨åˆ›å»º Accelerator
        self.accelerator = Accelerator(
            mixed_precision=self._get_mixed_precision(args),
            gradient_accumulation_steps=args.gradient_accumulation_steps,
            log_with=args.report_to,
            project_dir=args.logging_dir
        )
        
        # ä½¿ç”¨ prepare() åŒ…è£…
        self.model = self.accelerator.prepare(self.model)
        self.optimizer = self.accelerator.prepare(self.optimizer)
    
    def training_step(self, model, inputs):
        outputs = model(**inputs)
        loss = outputs.loss
        self.accelerator.backward(loss)  # å†…éƒ¨è°ƒç”¨
        return loss
```

---

### 14.5.2 è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ vs Trainer

#### ä½•æ—¶ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼ˆAccelerateï¼‰

```python
from accelerate import Accelerator

accelerator = Accelerator()

# å®Œå…¨è‡ªå®šä¹‰çš„è®­ç»ƒé€»è¾‘
generator = Generator()
discriminator = Discriminator()

gen_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)
disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)

generator, discriminator, gen_optimizer, disc_optimizer = accelerator.prepare(
    generator, discriminator, gen_optimizer, disc_optimizer
)

for epoch in range(100):
    for real_images in dataloader:
        # è®­ç»ƒåˆ¤åˆ«å™¨
        fake_images = generator(noise)
        disc_real = discriminator(real_images)
        disc_fake = discriminator(fake_images.detach())
        
        disc_loss = -torch.mean(disc_real) + torch.mean(disc_fake)
        accelerator.backward(disc_loss)
        disc_optimizer.step()
        disc_optimizer.zero_grad()
        
        # è®­ç»ƒç”Ÿæˆå™¨
        disc_fake = discriminator(fake_images)
        gen_loss = -torch.mean(disc_fake)
        accelerator.backward(gen_loss)
        gen_optimizer.step()
        gen_optimizer.zero_grad()
```

**é€‚ç”¨åœºæ™¯**ï¼š
- GANï¼ˆç”Ÿæˆå™¨-åˆ¤åˆ«å™¨äº¤æ›¿è®­ç»ƒï¼‰
- å¼ºåŒ–å­¦ä¹ ï¼ˆç­–ç•¥ç½‘ç»œ + ä»·å€¼ç½‘ç»œï¼‰
- å¤šä»»åŠ¡å­¦ä¹ ï¼ˆå¤šä¸ªæ¨¡å‹ã€å¤šä¸ªæŸå¤±å‡½æ•°ï¼‰
- éœ€è¦è‡ªå®šä¹‰ä¼˜åŒ–å™¨æ›´æ–°ç­–ç•¥

#### ä½•æ—¶ä½¿ç”¨ Trainer

```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./outputs",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    per_device_train_batch_size=16,
    logging_steps=100
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_accuracy
)

trainer.train()
```

**é€‚ç”¨åœºæ™¯**ï¼š
- æ ‡å‡†ç›‘ç£å­¦ä¹ ï¼ˆåˆ†ç±»ã€å›å½’ã€åºåˆ—æ ‡æ³¨ï¼‰
- é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ
- ä¸éœ€è¦è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
- å¸Œæœ›ä½¿ç”¨å†…ç½®çš„ loggingã€evaluationã€checkpoint

---

## 14.6 è°ƒè¯•æŠ€å·§

### 14.6.1 ACCELERATE_DEBUG_MODE

å¯ç”¨è°ƒè¯•æ¨¡å¼ä¼šæ‰“å°è¯¦ç»†çš„åˆ†å¸ƒå¼ä¿¡æ¯ï¼š

```bash
ACCELERATE_DEBUG_MODE=1 accelerate launch --num_processes=4 train.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
[DEBUG] Initialized process group: rank=0, world_size=4
[DEBUG] Device assignment: cuda:0
[DEBUG] Model wrapped with DistributedDataParallel
[DEBUG] DataLoader using DistributedSampler
[DEBUG] Gradient accumulation steps: 1
[DEBUG] Mixed precision: bf16
...
```

#### è‡ªå®šä¹‰è°ƒè¯•ä¿¡æ¯

```python
import os

if os.environ.get("ACCELERATE_DEBUG_MODE"):
    accelerator.print(f"[DEBUG] Rank {accelerator.process_index}: Starting training")
    accelerator.print(f"[DEBUG] Model device: {next(model.parameters()).device}")
    accelerator.print(f"[DEBUG] Dataloader length: {len(dataloader)}")
```

---

### 14.6.2 gather() ä¸ reduce() æ“ä½œ

#### gather() - æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„å¼ é‡

```python
# æ¯ä¸ªè¿›ç¨‹è®¡ç®—ä¸€ä¸ªå€¼
local_accuracy = compute_accuracy(predictions, labels)

# æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„å‡†ç¡®ç‡
all_accuracies = accelerator.gather(local_accuracy)

if accelerator.is_main_process:
    global_accuracy = all_accuracies.mean()
    print(f"Global Accuracy: {global_accuracy:.4f}")
```

**ç¤ºä¾‹**ï¼š

```python
# GPU 0: local_accuracy = 0.85
# GPU 1: local_accuracy = 0.88
# GPU 2: local_accuracy = 0.82
# GPU 3: local_accuracy = 0.90

all_accuracies = accelerator.gather(torch.tensor([local_accuracy]))
# ç»“æœ: tensor([0.85, 0.88, 0.82, 0.90])

global_accuracy = all_accuracies.mean()
# ç»“æœ: 0.8625
```

#### reduce() - èšåˆæ“ä½œ

```python
# è®¡ç®—æ‰€æœ‰è¿›ç¨‹çš„ loss æ€»å’Œ
total_loss = accelerator.reduce(loss, reduction="sum")

# è®¡ç®—å¹³å‡å€¼
avg_loss = accelerator.reduce(loss, reduction="mean")

# æœ€å¤§å€¼
max_loss = accelerator.reduce(loss, reduction="max")
```

**å†…éƒ¨å®ç°**ï¼š

```python
# reduce() ä½¿ç”¨ all_reduce é€šä¿¡åŸè¯­
if reduction == "sum":
    torch.distributed.all_reduce(tensor, op=torch.distributed.ReduceOp.SUM)
elif reduction == "mean":
    torch.distributed.all_reduce(tensor, op=torch.distributed.ReduceOp.SUM)
    tensor /= world_size
```

---

### 14.6.3 æ­»é”æ’æŸ¥

#### å¸¸è§æ­»é”åŸå› 

**åŸå›  1ï¼šä¸åŒè¿›ç¨‹æ‰§è¡Œä¸åŒçš„ä»£ç è·¯å¾„**

```python
# âŒ é”™è¯¯ï¼šæŸäº›è¿›ç¨‹è·³è¿‡äº†é›†ä½“é€šä¿¡æ“ä½œ
if accelerator.is_main_process:
    loss = model(batch).loss
    accelerator.backward(loss)  # ä»…ä¸»è¿›ç¨‹è°ƒç”¨ï¼Œå…¶ä»–è¿›ç¨‹åœ¨ barrier å¤„ç­‰å¾… â†’ æ­»é”
```

**ä¿®å¤**ï¼š

```python
# âœ… æ­£ç¡®ï¼šæ‰€æœ‰è¿›ç¨‹éƒ½æ‰§è¡Œç›¸åŒçš„é€šä¿¡æ“ä½œ
loss = model(batch).loss
accelerator.backward(loss)  # æ‰€æœ‰è¿›ç¨‹éƒ½è°ƒç”¨
```

**åŸå›  2ï¼šgather() åœ¨éä¸»è¿›ç¨‹è®¿é—®ç»“æœ**

```python
# âŒ é”™è¯¯
all_losses = accelerator.gather(loss)
avg_loss = all_losses.mean()  # éä¸»è¿›ç¨‹ä¸­ all_losses æ˜¯ None â†’ å´©æºƒ
```

**ä¿®å¤**ï¼š

```python
# âœ… æ­£ç¡®
all_losses = accelerator.gather(loss)
if accelerator.is_main_process:
    avg_loss = all_losses.mean()  # ä»…ä¸»è¿›ç¨‹å¤„ç†
```

**åŸå›  3ï¼šæ•°æ®åŠ è½½å™¨é•¿åº¦ä¸ä¸€è‡´**

```python
# âŒ é”™è¯¯ï¼šæŸäº›è¿›ç¨‹çš„ dataloader æå‰ç»“æŸ
for batch in dataloader:  # ä¸åŒè¿›ç¨‹çš„è¿­ä»£æ¬¡æ•°ä¸åŒ
    loss = model(batch).loss
    accelerator.backward(loss)  # æŸäº›è¿›ç¨‹å·²é€€å‡ºå¾ªç¯ â†’ æ­»é”
```

**ä¿®å¤**ï¼š

```python
# âœ… æ–¹å¼ 1: ç¡®ä¿æ‰€æœ‰è¿›ç¨‹çš„ dataloader é•¿åº¦ç›¸åŒ
sampler = DistributedSampler(dataset, drop_last=True)

# âœ… æ–¹å¼ 2: ä½¿ç”¨ accelerator.prepare() è‡ªåŠ¨å¤„ç†
dataloader = accelerator.prepare(dataloader)
```

#### è°ƒè¯•å·¥å…·

```bash
# è®¾ç½®è¶…æ—¶ï¼ˆé»˜è®¤ 30 åˆ†é’Ÿï¼‰
export NCCL_TIMEOUT=600  # 10 åˆ†é’Ÿ

# å¯ç”¨ NCCL è°ƒè¯•ä¿¡æ¯
export NCCL_DEBUG=INFO

# å¯åŠ¨è®­ç»ƒ
accelerate launch --num_processes=4 train.py
```

**æ£€æŸ¥è¿›ç¨‹çŠ¶æ€**ï¼š

```bash
# ç›‘æ§ GPU è¿›ç¨‹
watch -n 1 nvidia-smi

# æ£€æŸ¥åƒµæ­»è¿›ç¨‹
ps aux | grep python | grep train.py

# å¼ºåˆ¶ç»ˆæ­¢
pkill -9 -f train.py
```

---

## æ€»ç»“ä¸æœ€ä½³å®è·µ

### âœ… Accelerate ä½¿ç”¨æ£€æŸ¥æ¸…å•

**ä»£ç ä¿®æ”¹**ï¼š
- [ ] å¯¼å…¥ `Accelerator`
- [ ] åˆ›å»º `accelerator = Accelerator(...)`
- [ ] ä½¿ç”¨ `prepare()` åŒ…è£…æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨
- [ ] å°† `loss.backward()` æ›¿æ¢ä¸º `accelerator.backward(loss)`
- [ ] ä½¿ç”¨ `accelerator.print()` æ›¿ä»£ `print()`ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰

**é…ç½®æ–‡ä»¶**ï¼š
- [ ] è¿è¡Œ `accelerate config` ç”Ÿæˆé…ç½®
- [ ] æ£€æŸ¥ `~/.cache/huggingface/accelerate/default_config.yaml`
- [ ] æˆ–åˆ›å»ºè‡ªå®šä¹‰ `accelerate_config.yaml`

**å¯åŠ¨å‘½ä»¤**ï¼š
- [ ] å• GPUï¼š`accelerate launch train.py`
- [ ] å¤š GPUï¼š`accelerate launch --num_processes=N train.py`
- [ ] è‡ªå®šä¹‰é…ç½®ï¼š`accelerate launch --config_file config.yaml train.py`

**è¿›é˜¶åŠŸèƒ½**ï¼š
- [ ] æ··åˆç²¾åº¦ï¼š`mixed_precision='bf16'`
- [ ] æ¢¯åº¦ç´¯ç§¯ï¼š`gradient_accumulation_steps=N`
- [ ] Loggingï¼š`log_with='tensorboard'` æˆ– `'wandb'`
- [ ] Checkpointï¼š`accelerator.save_state()` / `load_state()`

### âš ï¸ å¸¸è§é™·é˜±

1. **å¿˜è®° `prepare()`**ï¼šç›´æ¥ä½¿ç”¨æœªåŒ…è£…çš„æ¨¡å‹/ä¼˜åŒ–å™¨
2. **è®¾å¤‡ä¸ä¸€è‡´**ï¼šæ‰‹åŠ¨ `.to(device)` ä¸ `prepare()` å†²çª
3. **æ‰“å°é‡å¤**ï¼šä½¿ç”¨ `print()` è€Œé `accelerator.print()`
4. **Checkpoint ä¿å­˜**ï¼šå¿˜è®° `unwrap_model()` å¯¼è‡´åŠ è½½å¤±è´¥
5. **é›†ä½“é€šä¿¡ä¸ä¸€è‡´**ï¼šæŸäº›è¿›ç¨‹è·³è¿‡ `backward()` æˆ– `gather()`

### ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–é¡¹ | å»ºè®® | é¢„æœŸæå‡ |
|--------|------|----------|
| **æ··åˆç²¾åº¦** | ä½¿ç”¨ BF16ï¼ˆA100+ï¼‰ | 1.5-2Ã— é€Ÿåº¦ |
| **æ¢¯åº¦ç´¯ç§¯** | å¢å¤§æœ‰æ•ˆ batch size | æé«˜ GPU åˆ©ç”¨ç‡ |
| **FSDP** | 7B+ æ¨¡å‹ä½¿ç”¨ FSDP | èŠ‚çœ 60-80% æ˜¾å­˜ |
| **Flash Attention** | `use_flash_attention_2=True` | èŠ‚çœ 30-50% æ˜¾å­˜ |
| **Gradient Checkpointing** | å¤§æ¨¡å‹å¯ç”¨ | èŠ‚çœ 40-60% æ˜¾å­˜ï¼ˆç‰ºç‰² 20% é€Ÿåº¦ï¼‰ |

### ğŸ”— æ‰©å±•é˜…è¯»

- **å®˜æ–¹æ–‡æ¡£**: https://huggingface.co/docs/accelerate
- **GitHub ç¤ºä¾‹**: https://github.com/huggingface/accelerate/tree/main/examples
- **FSDP æ•™ç¨‹**: https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html
- **DeepSpeed é›†æˆ**: https://huggingface.co/docs/accelerate/usage_guides/deepspeed

---

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼šChapter 15 å°†æ·±å…¥æ¢è®¨ **FSDPï¼ˆFully Sharded Data Parallelï¼‰**ï¼ŒåŒ…æ‹¬ ZeRO ä¼˜åŒ–å™¨çš„ä¸‰ä¸ªé˜¶æ®µã€åˆ†ç‰‡ç­–ç•¥ã€ä¸ DeepSpeed çš„å¯¹æ¯”ï¼Œä»¥åŠå¦‚ä½•åœ¨å•æœº 4 å¡ä¸Šè®­ç»ƒ 70B å‚æ•°çš„å¤§æ¨¡å‹ã€‚
