# Chapter 21: Planning ä¸ Self-Critique Agent

## æœ¬ç« æ¦‚è§ˆ

å‰é¢çš„ç« èŠ‚ä¸­,æˆ‘ä»¬å­¦ä¹ äº†åŸºç¡€ Agentï¼ˆReActï¼‰å’Œå¤š Agent ç³»ç»Ÿã€‚ç„¶è€Œï¼Œå¤æ‚ä»»åŠ¡å¾€å¾€éœ€è¦æ›´å¼ºçš„è§„åˆ’èƒ½åŠ›å’Œè‡ªæˆ‘æ”¹è¿›æœºåˆ¶ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨ä¸¤ç§é«˜çº§ Agent æ¨¡å¼ï¼š**Planning Agent**ï¼ˆå…ˆè§„åˆ’åæ‰§è¡Œï¼‰å’Œ **Reflection Agent**ï¼ˆè‡ªæˆ‘æ‰¹è¯„ä¸è¿­ä»£æ”¹è¿›ï¼‰ã€‚è¿™äº›æ¨¡å¼èƒ½å¤Ÿæ˜¾è‘—æå‡ Agent åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡å’Œè¾“å‡ºè´¨é‡ã€‚

**æœ¬ç« é‡ç‚¹**ï¼š
- Plan-and-Execute æ¡†æ¶åŸç†ä¸å®ç°
- ä»»åŠ¡åˆ†è§£ç­–ç•¥ä¸åŠ¨æ€é‡è§„åˆ’
- Self-Critique æœºåˆ¶è®¾è®¡
- è¿­ä»£æ”¹è¿›å¾ªç¯ï¼ˆReflection Loopï¼‰
- Tool Error Recovery å®¹é”™æœºåˆ¶
- Memory-Augmented Agent é•¿æœŸè®°å¿†
- ä¼ä¸šçº§å¯é æ€§å·¥ç¨‹å®è·µ

---

## 21.1 Planning Agentï¼šå…ˆè§„åˆ’åæ‰§è¡Œ

### 21.1.1 ä¸ºä»€ä¹ˆéœ€è¦ Planningï¼Ÿ

ä¼ ç»Ÿ ReAct Agent çš„é—®é¢˜ï¼š

```python
# ReAct Agentï¼šè¾¹æ€è€ƒè¾¹è¡ŒåŠ¨
user: "å¸®æˆ‘ç»„ç»‡ä¸€æ¬¡å›¢å»ºæ´»åŠ¨"
agent: Thought: æˆ‘éœ€è¦å…ˆäº†è§£é¢„ç®—
      Action: ask_user("é¢„ç®—æ˜¯å¤šå°‘ï¼Ÿ")
      Observation: 5000å…ƒ
      Thought: æˆ‘éœ€è¦æŸ¥æ‰¾æ´»åŠ¨åœºåœ°
      Action: search("åŒ—äº¬å›¢å»ºåœºåœ°")
      Observation: [åœºåœ°åˆ—è¡¨]
      Thought: æˆ‘éœ€è¦...
      # é—®é¢˜ï¼šæ²¡æœ‰æ•´ä½“è§„åˆ’ï¼Œå®¹æ˜“é—æ¼æ­¥éª¤ã€é‡å¤å·¥ä½œ
```

Planning Agent çš„ä¼˜åŠ¿ï¼š

```python
# Planning Agentï¼šå…ˆè§„åˆ’ï¼Œå†æ‰§è¡Œ
user: "å¸®æˆ‘ç»„ç»‡ä¸€æ¬¡å›¢å»ºæ´»åŠ¨"

# Step 1: åˆ¶å®šè®¡åˆ’
plan = [
    "æ”¶é›†éœ€æ±‚ï¼ˆé¢„ç®—ã€äººæ•°ã€æ—¶é—´ã€åå¥½ï¼‰",
    "æœç´¢å¹¶ç­›é€‰åœºåœ°",
    "è®¾è®¡æ´»åŠ¨æµç¨‹",
    "é¢„ç®—åˆ†é…",
    "é¢„å®šåœºåœ°å’ŒæœåŠ¡",
    "å‘é€é€šçŸ¥"
]

# Step 2: æŒ‰è®¡åˆ’æ‰§è¡Œ
for step in plan:
    execute(step)
    
# ä¼˜åŠ¿ï¼šç»“æ„åŒ–ã€å¯é¢„æµ‹ã€æ˜“äºç›‘æ§
```

### 21.1.2 Plan-and-Execute æ¡†æ¶åŸç†

<div data-component="PlanExecuteFlowDiagram"></div>

æ ¸å¿ƒæµç¨‹ï¼š

```
ç”¨æˆ·è¾“å…¥
   â†“
è§„åˆ’å™¨ (Planner)
   â†“
ç”Ÿæˆè®¡åˆ’ [Step1, Step2, Step3, ...]
   â†“
æ‰§è¡Œå™¨ (Executor) â† å¾ªç¯æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
   â†“
è§‚å¯Ÿç»“æœ
   â†“
éœ€è¦é‡æ–°è§„åˆ’ï¼Ÿ 
   â”œâ”€ æ˜¯ â†’ å›åˆ°è§„åˆ’å™¨
   â””â”€ å¦ â†’ ç»§ç»­ä¸‹ä¸€æ­¥
   â†“
æ‰€æœ‰æ­¥éª¤å®Œæˆ â†’ è¾“å‡ºæœ€ç»ˆç»“æœ
```

### 21.1.3 å®ç°åŸºç¡€ Plan-and-Execute Agent

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langgraph.graph import StateGraph, END
from typing import List, TypedDict, Annotated
import operator

# 1. å®šä¹‰è®¡åˆ’ç»“æ„
class Step(BaseModel):
    """å•ä¸ªæ‰§è¡Œæ­¥éª¤"""
    id: int
    description: str
    tool: str = Field(description="éœ€è¦ä½¿ç”¨çš„å·¥å…·åç§°")
    dependencies: List[int] = Field(default=[], description="ä¾èµ–çš„æ­¥éª¤ID")

class Plan(BaseModel):
    """å®Œæ•´çš„æ‰§è¡Œè®¡åˆ’"""
    goal: str = Field(description="æ€»ç›®æ ‡")
    steps: List[Step] = Field(description="æ‰§è¡Œæ­¥éª¤åˆ—è¡¨")
    estimated_time: int = Field(description="é¢„è®¡è€—æ—¶ï¼ˆåˆ†é’Ÿï¼‰")

# 2. åˆ›å»º Planner
def create_planner():
    """åˆ›å»ºè§„åˆ’å™¨"""
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚

ä½ çš„èŒè´£ï¼š
1. ç†è§£ç”¨æˆ·çš„ç›®æ ‡
2. å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå…·ä½“çš„ã€å¯æ‰§è¡Œçš„æ­¥éª¤
3. ç¡®å®šæ­¥éª¤ä¹‹é—´çš„ä¾èµ–å…³ç³»
4. ä¸ºæ¯ä¸ªæ­¥éª¤åˆ†é…åˆé€‚çš„å·¥å…·

å¯ç”¨å·¥å…·ï¼š
- search: æœç´¢ä¿¡æ¯
- calculator: æ•°å­¦è®¡ç®—
- python: æ‰§è¡ŒPythonä»£ç 
- database: æŸ¥è¯¢æ•°æ®åº“
- email: å‘é€é‚®ä»¶

è¾“å‡ºæ ¼å¼ï¼šJSONï¼ŒåŒ…å« goal, steps, estimated_time"""),
        ("user", "{user_input}")
    ])
    
    planner = prompt | llm.with_structured_output(Plan)
    return planner

# 3. åˆ›å»º Executor
def create_executor(tools):
    """åˆ›å»ºæ‰§è¡Œå™¨"""
    from langchain.agents import create_react_agent, AgentExecutor
    
    llm = ChatOpenAI(model="gpt-4")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä»»åŠ¡æ‰§è¡Œä¸“å®¶ã€‚
        ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„æ­¥éª¤æè¿°æ‰§è¡Œä»»åŠ¡ã€‚
        ä½¿ç”¨æä¾›çš„å·¥å…·å®Œæˆä»»åŠ¡ã€‚"""),
        ("user", "æ‰§è¡Œæ­¥éª¤ï¼š{step_description}"),
        ("assistant", "æˆ‘ä¼šä½¿ç”¨åˆé€‚çš„å·¥å…·å®Œæˆè¿™ä¸ªæ­¥éª¤ã€‚"),
    ])
    
    agent = create_react_agent(llm, tools, prompt)
    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    return executor

# 4. å®šä¹‰çŠ¶æ€
class PlanExecuteState(TypedDict):
    input: str  # ç”¨æˆ·è¾“å…¥
    plan: Plan  # ç”Ÿæˆçš„è®¡åˆ’
    current_step: int  # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ æ­¥
    step_results: Annotated[List[dict], operator.add]  # æ¯æ­¥çš„æ‰§è¡Œç»“æœ
    final_output: str  # æœ€ç»ˆè¾“å‡º
    need_replan: bool  # æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’

# 5. å®ç°èŠ‚ç‚¹
def planner_node(state: PlanExecuteState):
    """è§„åˆ’èŠ‚ç‚¹"""
    planner = create_planner()
    
    # å¦‚æœæ˜¯é‡æ–°è§„åˆ’ï¼Œè€ƒè™‘å·²æœ‰ç»“æœ
    if state.get("need_replan", False):
        context = f"åŸç›®æ ‡ï¼š{state['input']}\nå·²å®Œæˆæ­¥éª¤ï¼š\n"
        for i, result in enumerate(state.get("step_results", [])):
            context += f"- æ­¥éª¤{i+1}: {result['description']} â†’ {result['status']}\n"
        
        plan_input = f"{context}\nè¯·é‡æ–°è§„åˆ’å‰©ä½™ä»»åŠ¡ã€‚"
    else:
        plan_input = state["input"]
    
    plan = planner.invoke({"user_input": plan_input})
    
    return {
        "plan": plan,
        "current_step": 0,
        "need_replan": False
    }

def executor_node(state: PlanExecuteState):
    """æ‰§è¡ŒèŠ‚ç‚¹"""
    plan = state["plan"]
    current_step = state["current_step"]
    
    if current_step >= len(plan.steps):
        # æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ
        return {"final_output": summarize_results(state["step_results"])}
    
    step = plan.steps[current_step]
    
    # æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
    for dep_id in step.dependencies:
        dep_result = state["step_results"][dep_id - 1]
        if dep_result["status"] != "success":
            # ä¾èµ–æ­¥éª¤å¤±è´¥ï¼Œéœ€è¦é‡æ–°è§„åˆ’
            return {"need_replan": True}
    
    # æ‰§è¡Œå½“å‰æ­¥éª¤
    executor = create_executor(get_tools_for_step(step.tool))
    
    try:
        result = executor.invoke({
            "step_description": step.description,
            "context": get_dependency_outputs(state["step_results"], step.dependencies)
        })
        
        step_result = {
            "id": step.id,
            "description": step.description,
            "status": "success",
            "output": result["output"]
        }
    except Exception as e:
        step_result = {
            "id": step.id,
            "description": step.description,
            "status": "failed",
            "error": str(e)
        }
        
        # æ‰§è¡Œå¤±è´¥ï¼Œè§¦å‘é‡æ–°è§„åˆ’
        return {
            "step_results": [step_result],
            "need_replan": True
        }
    
    return {
        "step_results": [step_result],
        "current_step": current_step + 1
    }

def summarize_results(results: List[dict]) -> str:
    """æ±‡æ€»æ‰€æœ‰æ­¥éª¤çš„ç»“æœ"""
    summary = "ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼\n\næ‰§è¡Œè¿‡ç¨‹ï¼š\n"
    for r in results:
        summary += f"âœ“ {r['description']}\n  ç»“æœ: {r['output'][:100]}...\n\n"
    return summary

# 6. æ„å»º Plan-Execute Graph
def build_plan_execute_graph():
    workflow = StateGraph(PlanExecuteState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("planner", planner_node)
    workflow.add_node("executor", executor_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("planner")
    
    # è§„åˆ’å™¨ â†’ æ‰§è¡Œå™¨
    workflow.add_edge("planner", "executor")
    
    # æ‰§è¡Œå™¨çš„æ¡ä»¶è·¯ç”±
    def should_continue(state: PlanExecuteState):
        if state.get("need_replan", False):
            return "planner"  # é‡æ–°è§„åˆ’
        elif state.get("final_output"):
            return "end"  # å®Œæˆ
        else:
            return "executor"  # ç»§ç»­æ‰§è¡Œ
    
    workflow.add_conditional_edges(
        "executor",
        should_continue,
        {
            "planner": "planner",
            "executor": "executor",
            "end": END
        }
    )
    
    return workflow.compile()

# ä½¿ç”¨ç¤ºä¾‹
graph = build_plan_execute_graph()

result = graph.invoke({
    "input": """å¸®æˆ‘å‡†å¤‡ä¸€ä¸ªå…³äº"LangChain Agentè®¾è®¡æ¨¡å¼"çš„æŠ€æœ¯åˆ†äº«ï¼š
    1. éœ€è¦åŒ…å«æœ€æ–°çš„æŠ€æœ¯åŠ¨æ€
    2. å‡†å¤‡ä¸€äº›ä»£ç ç¤ºä¾‹
    3. åˆ¶ä½œPPTå¤§çº²"""
})

print("=== æ‰§è¡Œè®¡åˆ’ ===")
print(f"ç›®æ ‡: {result['plan'].goal}")
for step in result['plan'].steps:
    print(f"{step.id}. {step.description} (å·¥å…·: {step.tool})")

print("\n=== æœ€ç»ˆè¾“å‡º ===")
print(result['final_output'])
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
=== æ‰§è¡Œè®¡åˆ’ ===
ç›®æ ‡: å‡†å¤‡LangChain Agentè®¾è®¡æ¨¡å¼æŠ€æœ¯åˆ†äº«
1. æœç´¢LangChainæœ€æ–°åŠ¨æ€å’ŒAgentè®¾è®¡æ¨¡å¼ (å·¥å…·: search)
2. æ•´ç†æ ¸å¿ƒè®¾è®¡æ¨¡å¼å¹¶ç¼–å†™ä»£ç ç¤ºä¾‹ (å·¥å…·: python)
3. æ ¹æ®å†…å®¹ç”ŸæˆPPTå¤§çº² (å·¥å…·: python)

=== æ‰§è¡Œè¿‡ç¨‹ ===
æ‰§è¡Œæ­¥éª¤1: æœç´¢LangChainæœ€æ–°åŠ¨æ€...
âœ“ æ‰¾åˆ°5ç¯‡ç›¸å…³æ–‡ç« å’Œæ–‡æ¡£

æ‰§è¡Œæ­¥éª¤2: ç¼–å†™ä»£ç ç¤ºä¾‹...
âœ“ ç”ŸæˆReActã€Plan-Executeã€Reflectionä¸‰ä¸ªç¤ºä¾‹

æ‰§è¡Œæ­¥éª¤3: ç”ŸæˆPPTå¤§çº²...
âœ“ åˆ›å»ºåŒ…å«10é¡µçš„æ¼”ç¤ºå¤§çº²

=== æœ€ç»ˆè¾“å‡º ===
æŠ€æœ¯åˆ†äº«å‡†å¤‡å®Œæˆï¼å†…å®¹åŒ…æ‹¬ï¼š
- æœ€æ–°æŠ€æœ¯åŠ¨æ€ï¼ˆLangGraph 0.2ã€Agentä¼˜åŒ–ï¼‰
- 3ä¸ªå®Œæ•´ä»£ç ç¤ºä¾‹
- 10é¡µPPTå¤§çº²ï¼ˆå«å¼•è¨€ã€æ¨¡å¼å¯¹æ¯”ã€æ¡ˆä¾‹åˆ†æã€æœ€ä½³å®è·µï¼‰
```

### 21.1.4 é«˜çº§è§„åˆ’ç­–ç•¥

#### åˆ†å±‚è§„åˆ’ (Hierarchical Planning)

å¯¹äºè¶…å¤§å‹ä»»åŠ¡ï¼Œå¯ä»¥ä½¿ç”¨åˆ†å±‚è§„åˆ’ï¼š

```python
class HierarchicalPlan(BaseModel):
    """åˆ†å±‚è®¡åˆ’"""
    goal: str
    high_level_steps: List[str]  # é«˜å±‚æ­¥éª¤
    detailed_plans: dict  # æ¯ä¸ªé«˜å±‚æ­¥éª¤çš„è¯¦ç»†è®¡åˆ’

def hierarchical_planner(goal: str):
    """ä¸¤å±‚è§„åˆ’å™¨"""
    
    # ç¬¬ä¸€å±‚ï¼šé«˜å±‚è§„åˆ’
    high_level_prompt = f"""å°†ç›®æ ‡åˆ†è§£ä¸º3-5ä¸ªä¸»è¦é˜¶æ®µï¼š
    ç›®æ ‡ï¼š{goal}
    
    è¾“å‡ºæ ¼å¼ï¼š
    1. é˜¶æ®µ1
    2. é˜¶æ®µ2
    3. é˜¶æ®µ3"""
    
    high_level_plan = llm.invoke(high_level_prompt)
    
    # ç¬¬äºŒå±‚ï¼šæ¯ä¸ªé˜¶æ®µçš„è¯¦ç»†è§„åˆ’
    detailed_plans = {}
    for phase in high_level_plan.phases:
        detailed_plan = create_planner().invoke({
            "user_input": f"è¯¦ç»†è§„åˆ’ï¼š{phase}"
        })
        detailed_plans[phase] = detailed_plan
    
    return HierarchicalPlan(
        goal=goal,
        high_level_steps=high_level_plan.phases,
        detailed_plans=detailed_plans
    )

# ä½¿ç”¨
plan = hierarchical_planner("æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç”µå•†ç½‘ç«™")

"""
è¾“å‡ºï¼š
é«˜å±‚è®¡åˆ’ï¼š
1. éœ€æ±‚åˆ†æå’Œç³»ç»Ÿè®¾è®¡
2. åç«¯å¼€å‘
3. å‰ç«¯å¼€å‘
4. æµ‹è¯•å’Œéƒ¨ç½²

è¯¦ç»†è®¡åˆ’ï¼ˆé˜¶æ®µ1ï¼‰ï¼š
- æ”¶é›†ä¸šåŠ¡éœ€æ±‚
- è®¾è®¡æ•°æ®åº“æ¨¡å‹
- è®¾è®¡APIæ¥å£
- åˆ¶å®šæŠ€æœ¯é€‰å‹
...
"""
```

#### åŠ¨æ€é‡è§„åˆ’ (Re-planning)

å½“æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜æ—¶ï¼Œè‡ªåŠ¨é‡æ–°è§„åˆ’ï¼š

```python
def adaptive_executor(state: PlanExecuteState):
    """è‡ªé€‚åº”æ‰§è¡Œå™¨"""
    step = state["plan"].steps[state["current_step"]]
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            result = execute_step(step)
            
            # éªŒè¯ç»“æœè´¨é‡
            if validate_output(result):
                return {"step_results": [result], "current_step": state["current_step"] + 1}
            else:
                # è´¨é‡ä¸è¾¾æ ‡ï¼Œè°ƒæ•´æ­¥éª¤æè¿°åé‡è¯•
                step.description = refine_step_description(step, result)
                
        except Exception as e:
            if attempt == max_retries - 1:
                # å¤šæ¬¡å¤±è´¥ï¼Œè§¦å‘é‡è§„åˆ’
                return {
                    "need_replan": True,
                    "replan_reason": f"æ­¥éª¤ {step.id} æ‰§è¡Œå¤±è´¥: {e}"
                }
    
    return {"need_replan": True}

def replanner_node(state: PlanExecuteState):
    """é‡è§„åˆ’èŠ‚ç‚¹"""
    original_plan = state["plan"]
    completed_steps = state["step_results"]
    
    replan_prompt = f"""åŸè®¡åˆ’æ‰§è¡Œé‡åˆ°é—®é¢˜ï¼Œéœ€è¦é‡æ–°è§„åˆ’ã€‚

åŸç›®æ ‡: {original_plan.goal}

å·²å®Œæˆæ­¥éª¤:
{format_completed_steps(completed_steps)}

å¤±è´¥åŸå› : {state.get('replan_reason', 'æœªçŸ¥')}

è¯·ç”Ÿæˆæ–°çš„æ‰§è¡Œè®¡åˆ’ï¼Œè€ƒè™‘å·²å®Œæˆçš„å·¥ä½œï¼Œé¿å…é‡å¤åŠ³åŠ¨ã€‚"""
    
    new_plan = create_planner().invoke({"user_input": replan_prompt})
    
    return {
        "plan": new_plan,
        "current_step": 0,
        "need_replan": False
    }
```

---

## 21.2 Reflection Agentï¼šè‡ªæˆ‘æ‰¹è¯„ä¸æ”¹è¿›

### 21.2.1 Self-Critique æœºåˆ¶åŸç†

Reflection Agent èƒ½å¤Ÿè¯„ä¼°è‡ªå·±çš„è¾“å‡ºè´¨é‡ï¼Œå¹¶è¿›è¡Œè¿­ä»£æ”¹è¿›ï¼š

```
åˆå§‹è¾“å‡º â†’ è‡ªæˆ‘è¯„ä¼° â†’ å‘ç°é—®é¢˜ â†’ æ”¹è¿› â†’ æ–°è¾“å‡º â†’ å†è¯„ä¼° â†’ ...
```

<div data-component="ReflectionLoopVisualizer"></div>

**æ ¸å¿ƒç†å¿µ**ï¼š
- ç¬¬ä¸€æ¬¡è¾“å‡ºå¾€å¾€ä¸æ˜¯æœ€ä¼˜çš„
- é€šè¿‡è‡ªæˆ‘æ‰¹è¯„å‘ç°é—®é¢˜
- è¿­ä»£æ”¹è¿›ç›´åˆ°æ»¡è¶³è´¨é‡æ ‡å‡†

### 21.2.2 å®ç°åŸºç¡€ Reflection Agent

```python
from langchain_core.pydantic_v1 import BaseModel, Field
from typing import List, Literal

# 1. å®šä¹‰è¯„ä¼°ç»“æ„
class Critique(BaseModel):
    """æ‰¹è¯„æ„è§"""
    aspect: str = Field(description="è¯„ä¼°çš„æ–¹é¢ï¼ˆå¦‚å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€å¯è¯»æ€§ï¼‰")
    score: int = Field(description="è¯„åˆ† 1-10")
    issues: List[str] = Field(description="å‘ç°çš„å…·ä½“é—®é¢˜")
    suggestions: List[str] = Field(description="æ”¹è¿›å»ºè®®")

class SelfAssessment(BaseModel):
    """è‡ªæˆ‘è¯„ä¼°"""
    overall_score: int = Field(description="æ€»ä½“è¯„åˆ† 1-10")
    critiques: List[Critique]
    is_acceptable: bool = Field(description="æ˜¯å¦è¾¾åˆ°å¯æ¥å—æ ‡å‡†")

# 2. åˆ›å»º Generatorï¼ˆç”Ÿæˆå™¨ï¼‰
def create_generator(task_type: str):
    """åˆ›å»ºå†…å®¹ç”Ÿæˆå™¨"""
    llm = ChatOpenAI(model="gpt-4", temperature=0.7)
    
    prompts = {
        "essay": """ä½ æ˜¯ä¸“ä¸šä½œå®¶ã€‚ä»»åŠ¡ï¼šæ’°å†™ä¸€ç¯‡æ–‡ç« ã€‚
        
è¦æ±‚ï¼š
- é€»è¾‘æ¸…æ™°ï¼Œè®ºè¯å……åˆ†
- è¯­è¨€æµç•…ï¼Œè¡¨è¾¾å‡†ç¡®
- ç»“æ„å®Œæ•´ï¼ˆå¼•è¨€ã€æ­£æ–‡ã€ç»“è®ºï¼‰""",
        
        "code": """ä½ æ˜¯èµ„æ·±å·¥ç¨‹å¸ˆã€‚ä»»åŠ¡ï¼šç¼–å†™é«˜è´¨é‡ä»£ç ã€‚
        
è¦æ±‚ï¼š
- ä»£ç æ­£ç¡®ã€é«˜æ•ˆ
- éµå¾ªæœ€ä½³å®è·µ
- æ³¨é‡Šå……åˆ†""",
        
        "analysis": """ä½ æ˜¯æ•°æ®åˆ†æå¸ˆã€‚ä»»åŠ¡ï¼šè¿›è¡Œæ·±å…¥åˆ†æã€‚
        
è¦æ±‚ï¼š
- æ•°æ®å‡†ç¡®
- åˆ†æå…¨é¢
- ç»“è®ºæœ‰è¯´æœåŠ›"""
    }
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", prompts.get(task_type, prompts["essay"])),
        ("user", "{task_description}"),
        ("assistant", "{previous_attempt}"),  # å¦‚æœæ˜¯æ”¹è¿›ç‰ˆæœ¬
        ("user", "{improvement_instructions}")  # æ”¹è¿›æŒ‡å¯¼
    ])
    
    return prompt | llm

# 3. åˆ›å»º Criticï¼ˆæ‰¹è¯„å®¶ï¼‰
def create_critic(task_type: str):
    """åˆ›å»ºè‡ªæˆ‘æ‰¹è¯„å™¨"""
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    
    critic_prompt = ChatPromptTemplate.from_messages([
        ("system", f"""ä½ æ˜¯ä¸¥æ ¼çš„è´¨é‡è¯„å®¡ä¸“å®¶ï¼Œè´Ÿè´£è¯„ä¼°{task_type}çš„è´¨é‡ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. å‡†ç¡®æ€§ (Accuracy)
2. å®Œæ•´æ€§ (Completeness)
3. æ¸…æ™°åº¦ (Clarity)
4. ä¸“ä¸šæ€§ (Professionalism)
5. åˆ›æ–°æ€§ (Creativity)

å¯¹æ¯ä¸ªç»´åº¦æ‰“åˆ†ï¼ˆ1-10ï¼‰ï¼ŒæŒ‡å‡ºå…·ä½“é—®é¢˜å’Œæ”¹è¿›å»ºè®®ã€‚
å¦‚æœæ€»ä½“è¯„åˆ†ä½äº8åˆ†ï¼Œæ ‡è®°ä¸ºä¸å¯æ¥å—ã€‚"""),
        ("user", "è¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹ï¼š\n\n{content}")
    ])
    
    return critic_prompt | llm.with_structured_output(SelfAssessment)

# 4. å®ç° Reflection Loop
class ReflectionState(TypedDict):
    task: str  # ä»»åŠ¡æè¿°
    current_output: str  # å½“å‰è¾“å‡º
    critiques: List[SelfAssessment]  # å†æ¬¡è¯„ä¼°
    iteration: int  # è¿­ä»£æ¬¡æ•°
    final_output: str  # æœ€ç»ˆè¾“å‡º

def generator_node(state: ReflectionState):
    """ç”ŸæˆèŠ‚ç‚¹"""
    generator = create_generator("essay")
    
    # é¦–æ¬¡ç”Ÿæˆ
    if state["iteration"] == 0:
        result = generator.invoke({
            "task_description": state["task"],
            "previous_attempt": "",
            "improvement_instructions": ""
        })
    else:
        # æ”¹è¿›ç‰ˆæœ¬
        last_critique = state["critiques"][-1]
        improvement_instructions = format_improvement_instructions(last_critique)
        
        result = generator.invoke({
            "task_description": state["task"],
            "previous_attempt": state["current_output"],
            "improvement_instructions": improvement_instructions
        })
    
    return {
        "current_output": result.content,
        "iteration": state["iteration"] + 1
    }

def critic_node(state: ReflectionState):
    """æ‰¹è¯„èŠ‚ç‚¹"""
    critic = create_critic("essay")
    
    assessment = critic.invoke({"content": state["current_output"]})
    
    return {
        "critiques": state.get("critiques", []) + [assessment]
    }

def should_continue(state: ReflectionState):
    """å†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£"""
    MAX_ITERATIONS = 5
    
    if state["iteration"] >= MAX_ITERATIONS:
        return "finish"  # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    last_critique = state["critiques"][-1]
    if last_critique.is_acceptable:
        return "finish"  # è´¨é‡è¾¾æ ‡
    
    return "continue"  # ç»§ç»­æ”¹è¿›

def build_reflection_graph():
    """æ„å»ºåæ€å¾ªç¯å›¾"""
    workflow = StateGraph(ReflectionState)
    
    workflow.add_node("generate", generator_node)
    workflow.add_node("critique", critic_node)
    
    workflow.set_entry_point("generate")
    
    # ç”Ÿæˆ â†’ æ‰¹è¯„
    workflow.add_edge("generate", "critique")
    
    # æ‰¹è¯„ â†’ å†³å®šä¸‹ä¸€æ­¥
    workflow.add_conditional_edges(
        "critique",
        should_continue,
        {
            "continue": "generate",  # ç»§ç»­æ”¹è¿›
            "finish": END
        }
    )
    
    return workflow.compile()

# ä½¿ç”¨ç¤ºä¾‹
reflection_graph = build_reflection_graph()

result = reflection_graph.invoke({
    "task": "å†™ä¸€ç¯‡å…³äº'AI Agent åœ¨ä¼ä¸šä¸­çš„åº”ç”¨'çš„æŠ€æœ¯åšå®¢",
    "iteration": 0,
    "critiques": []
})

print(f"è¿­ä»£æ¬¡æ•°: {result['iteration']}")
print("\n=== å†æ¬¡è¯„ä¼° ===")
for i, critique in enumerate(result['critiques'], 1):
    print(f"\nç¬¬{i}æ¬¡è¯„ä¼°:")
    print(f"æ€»åˆ†: {critique.overall_score}/10")
    for c in critique.critiques:
        print(f"- {c.aspect}: {c.score}/10")
        if c.issues:
            print(f"  é—®é¢˜: {', '.join(c.issues)}")

print("\n=== æœ€ç»ˆè¾“å‡º ===")
print(result['current_output'])
```

**æ‰§è¡Œè¿‡ç¨‹ç¤ºä¾‹**ï¼š

```
è¿­ä»£1:
ç”Ÿæˆåˆç¨¿ â†’ è¯„ä¼°: 6/10 (ç¼ºå°‘å…·ä½“æ¡ˆä¾‹ã€ç»“æ„ä¸å¤Ÿæ¸…æ™°)

è¿­ä»£2:
æ”¹è¿›ç‰ˆæœ¬ â†’ è¯„ä¼°: 7.5/10 (æ¡ˆä¾‹è¾ƒå¥½ï¼Œä½†æŠ€æœ¯æ·±åº¦ä¸è¶³)

è¿­ä»£3:
å†æ¬¡æ”¹è¿› â†’ è¯„ä¼°: 8.5/10 (è¾¾åˆ°å¯æ¥å—æ ‡å‡†) â†’ å®Œæˆ
```

### 21.2.3 å¤šè§’åº¦æ‰¹è¯„æœºåˆ¶

ä½¿ç”¨å¤šä¸ªæ‰¹è¯„å®¶ä»ä¸åŒè§’åº¦è¯„ä¼°ï¼š

```python
def create_multi_perspective_critics():
    """åˆ›å»ºå¤šè§’åº¦æ‰¹è¯„å®¶"""
    
    critics = {
        "technical": ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯æŠ€æœ¯ä¸“å®¶ï¼Œè¯„ä¼°æŠ€æœ¯å‡†ç¡®æ€§å’Œæ·±åº¦ã€‚"),
            ("user", "{content}")
        ]),
        
        "readability": ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ç¼–è¾‘ï¼Œè¯„ä¼°å¯è¯»æ€§å’Œè¡¨è¾¾è´¨é‡ã€‚"),
            ("user", "{content}")
        ]),
        
        "structure": ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯é€»è¾‘ä¸“å®¶ï¼Œè¯„ä¼°ç»“æ„å’Œè®ºè¯é€»è¾‘ã€‚"),
            ("user", "{content}")
        ])
    }
    
    return {name: prompt | llm.with_structured_output(Critique) 
            for name, prompt in critics.items()}

def comprehensive_critique(content: str):
    """ç»¼åˆè¯„ä¼°"""
    critics = create_multi_perspective_critics()
    
    critiques = {}
    for name, critic in critics.items():
        critiques[name] = critic.invoke({"content": content})
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    avg_score = sum(c.score for c in critiques.values()) / len(critiques)
    
    return {
        "critiques": critiques,
        "average_score": avg_score,
        "is_acceptable": avg_score >= 8.0
    }
```

### 21.2.4 å¯¹æ¯”æ”¹è¿›ç­–ç•¥

é™¤äº†è‡ªæˆ‘æ‰¹è¯„ï¼Œè¿˜å¯ä»¥é€šè¿‡ç”Ÿæˆå¤šä¸ªç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”ï¼š

```python
def generate_multiple_versions(task: str, num_versions: int = 3):
    """ç”Ÿæˆå¤šä¸ªç‰ˆæœ¬å¹¶é€‰æ‹©æœ€ä½³"""
    generator = create_generator("essay")
    critic = create_critic("essay")
    
    versions = []
    
    for i in range(num_versions):
        # æ¯ä¸ªç‰ˆæœ¬ä½¿ç”¨ä¸åŒçš„æ¸©åº¦å‚æ•°
        version = generator.invoke({
            "task_description": task,
            "temperature": 0.5 + i * 0.2  # 0.5, 0.7, 0.9
        })
        
        assessment = critic.invoke({"content": version.content})
        
        versions.append({
            "content": version.content,
            "score": assessment.overall_score,
            "assessment": assessment
        })
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç‰ˆæœ¬
    best_version = max(versions, key=lambda v: v["score"])
    
    return best_version
```

---

## 21.3 Memory-Augmented Agentï¼šé•¿æœŸè®°å¿†

### 21.3.1 ä¸ºä»€ä¹ˆéœ€è¦é•¿æœŸè®°å¿†ï¼Ÿ

Agent åœ¨å¤„ç†å¤šä¸ªä»»åŠ¡æ—¶ï¼Œå¯ä»¥ä»å†å²ç»éªŒä¸­å­¦ä¹ ï¼š

```python
# æ— è®°å¿†Agentï¼šæ¯æ¬¡éƒ½æ˜¯æ–°æ‰‹
task1 = agent.invoke("åˆ†æé”€å”®æ•°æ®")  # æ‘¸ç´¢å¦‚ä½•åˆ†æ
task2 = agent.invoke("åˆ†æç”¨æˆ·æ•°æ®")  # åˆé‡æ–°æ‘¸ç´¢
task3 = agent.invoke("åˆ†æè´¢åŠ¡æ•°æ®")  # å†æ¬¡æ‘¸ç´¢

# æœ‰è®°å¿†Agentï¼šç§¯ç´¯ç»éªŒ
task1 = agent.invoke("åˆ†æé”€å”®æ•°æ®")  # å­¦åˆ°åˆ†ææ–¹æ³•
# å­˜å‚¨ï¼šæˆåŠŸçš„åˆ†ææµç¨‹ã€å¸¸è§é—®é¢˜ã€æœ€ä½³å®è·µ

task2 = agent.invoke("åˆ†æç”¨æˆ·æ•°æ®")  # å¤ç”¨ä¹‹å‰çš„æ–¹æ³•
# å­˜å‚¨ï¼šæ–°çš„insightsã€æ”¹è¿›çš„æµç¨‹

task3 = agent.invoke("åˆ†æè´¢åŠ¡æ•°æ®")  # ç»¼åˆè¿ç”¨æ‰€æœ‰ç»éªŒ
```

### 21.3.2 å®ç°é•¿æœŸè®°å¿†ç³»ç»Ÿ

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from datetime import datetime

class AgentMemory:
    """Agenté•¿æœŸè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            collection_name="agent_memory",
            embedding_function=self.embeddings
        )
        self.episodic_memory = []  # æƒ…æ™¯è®°å¿†ï¼ˆå…·ä½“ä»»åŠ¡ï¼‰
        self.semantic_memory = {}  # è¯­ä¹‰è®°å¿†ï¼ˆæ¦‚å¿µã€æ–¹æ³•ï¼‰
    
    def store_episode(self, task: str, solution: str, outcome: str, success: bool):
        """å­˜å‚¨ä»»åŠ¡æ‰§è¡Œè®°å½•"""
        episode = {
            "task": task,
            "solution": solution,
            "outcome": outcome,
            "success": success,
            "timestamp": datetime.now(),
            "metadata": {
                "task_type": classify_task(task),
                "tools_used": extract_tools(solution)
            }
        }
        
        self.episodic_memory.append(episode)
        
        # åŒæ—¶å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œæ”¯æŒè¯­ä¹‰æ£€ç´¢
        self.vectorstore.add_texts(
            texts=[f"ä»»åŠ¡: {task}\nè§£å†³æ–¹æ¡ˆ: {solution}\nç»“æœ: {outcome}"],
            metadatas=[episode["metadata"]],
            ids=[f"episode_{len(self.episodic_memory)}"]
        )
    
    def retrieve_similar_experiences(self, current_task: str, k: int = 3):
        """æ£€ç´¢ç›¸ä¼¼çš„å†å²ç»éªŒ"""
        results = self.vectorstore.similarity_search(current_task, k=k)
        
        similar_episodes = []
        for doc in results:
            # è§£æå­˜å‚¨çš„episode
            similar_episodes.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        
        return similar_episodes
    
    def extract_lessons(self):
        """ä»å†å²ä¸­æå–ç»éªŒæ•™è®­"""
        # åˆ†ææˆåŠŸå’Œå¤±è´¥çš„æ¨¡å¼
        successful_tasks = [e for e in self.episodic_memory if e["success"]]
        failed_tasks = [e for e in self.episodic_memory if not e["success"]]
        
        lessons = {
            "success_patterns": analyze_patterns(successful_tasks),
            "common_pitfalls": analyze_patterns(failed_tasks),
            "best_practices": extract_best_practices(successful_tasks)
        }
        
        self.semantic_memory["lessons"] = lessons
        return lessons

# é›†æˆåˆ° Agent
class MemoryAugmentedAgent:
    """å¸¦è®°å¿†çš„Agent"""
    
    def __init__(self):
        self.agent = create_react_agent(...)
        self.memory = AgentMemory()
    
    def invoke(self, task: str):
        # 1. æ£€ç´¢ç›¸å…³å†å²ç»éªŒ
        similar_experiences = self.memory.retrieve_similar_experiences(task)
        
        # 2. å°†ç»éªŒæ³¨å…¥åˆ°prompt
        context = self.format_experiences(similar_experiences)
        enhanced_prompt = f"""{task}

å‚è€ƒä»¥ä¸‹å†å²ç»éªŒï¼š
{context}

è¯·æ ¹æ®è¿™äº›ç»éªŒæ‰§è¡Œä»»åŠ¡ã€‚"""
        
        # 3. æ‰§è¡Œä»»åŠ¡
        try:
            result = self.agent.invoke(enhanced_prompt)
            success = True
        except Exception as e:
            result = str(e)
            success = False
        
        # 4. å­˜å‚¨æœ¬æ¬¡ç»éªŒ
        self.memory.store_episode(
            task=task,
            solution=result.get("output", ""),
            outcome=result,
            success=success
        )
        
        return result
    
    def format_experiences(self, experiences: List[dict]) -> str:
        """æ ¼å¼åŒ–å†å²ç»éªŒ"""
        if not experiences:
            return "æš‚æ— ç›¸å…³å†å²ç»éªŒã€‚"
        
        formatted = "ç›¸å…³å†å²ç»éªŒï¼š\n"
        for i, exp in enumerate(experiences, 1):
            formatted += f"\n{i}. {exp['content']}\n"
        
        return formatted

# ä½¿ç”¨ç¤ºä¾‹
agent = MemoryAugmentedAgent()

# ç¬¬ä¸€æ¬¡ä»»åŠ¡
agent.invoke("åˆ†æQ1é”€å”®æ•°æ®ï¼Œæ‰¾å‡ºå¢é•¿é©±åŠ¨å› ç´ ")

# ç¬¬äºŒæ¬¡ä»»åŠ¡ï¼ˆè‡ªåŠ¨åˆ©ç”¨ç¬¬ä¸€æ¬¡çš„ç»éªŒï¼‰
agent.invoke("åˆ†æQ2é”€å”®æ•°æ®ï¼Œå¯¹æ¯”Q1æ‰¾å‡ºå˜åŒ–")

# æå–ç»éªŒæ•™è®­
lessons = agent.memory.extract_lessons()
print("å­¦åˆ°çš„æœ€ä½³å®è·µï¼š", lessons["best_practices"])
```

### 21.3.3 ç»éªŒè¿ç§»å­¦ä¹ 

å°†æˆåŠŸç»éªŒåº”ç”¨åˆ°æ–°é¢†åŸŸï¼š

```python
def transfer_learning(source_domain: str, target_domain: str):
    """é¢†åŸŸè¿ç§»å­¦ä¹ """
    
    # 1. æå–æºé¢†åŸŸçš„æˆåŠŸæ¨¡å¼
    source_experiences = memory.retrieve_by_domain(source_domain, success_only=True)
    patterns = extract_abstract_patterns(source_experiences)
    
    # 2. å°†æ¨¡å¼æŠ½è±¡åŒ–
    abstract_strategies = [
        "å…ˆæ¢ç´¢æ•°æ®ç‰¹å¾ï¼Œå†é€‰æ‹©åˆ†ææ–¹æ³•",
        "ä½¿ç”¨å¯è§†åŒ–è¾…åŠ©ç†è§£",
        "éªŒè¯å‡è®¾æ—¶ä½¿ç”¨å¤šç§æ–¹æ³•äº¤å‰éªŒè¯"
    ]
    
    # 3. åº”ç”¨åˆ°ç›®æ ‡é¢†åŸŸ
    adapted_strategies = adapt_strategies(abstract_strategies, target_domain)
    
    return adapted_strategies
```

---

## 21.4 Tool Error Recoveryï¼šå®¹é”™æœºåˆ¶

### 21.4.1 å·¥å…·è°ƒç”¨å¤±è´¥çš„å¸¸è§åŸå› 

| é”™è¯¯ç±»å‹ | åŸå›  | ç¤ºä¾‹ |
|---------|------|------|
| **å‚æ•°é”™è¯¯** | Agentä¼ é€’äº†é”™è¯¯çš„å‚æ•° | `search(query=123)` # queryåº”è¯¥æ˜¯å­—ç¬¦ä¸² |
| **è¶…æ—¶** | å·¥å…·æ‰§è¡Œæ—¶é—´è¿‡é•¿ | ç½‘ç»œè¯·æ±‚è¶…æ—¶ã€æ•°æ®åº“æŸ¥è¯¢æ…¢ |
| **æƒé™ä¸è¶³** | æ²¡æœ‰è®¿é—®æƒé™ | æ— æ³•è¯»å–å—é™æ–‡ä»¶ |
| **èµ„æºä¸å¯ç”¨** | ä¾èµ–çš„æœåŠ¡å®•æœº | APIæœåŠ¡500é”™è¯¯ |
| **ç»“æœè§£æå¤±è´¥** | è¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ | JSONè§£æé”™è¯¯ |

### 21.4.2 å®ç°å®¹é”™æœºåˆ¶

```python
from tenacity import retry, stop_after_attempt, wait_exponential
from typing import Any, Callable

class RobustTool:
    """å¸¦å®¹é”™æœºåˆ¶çš„å·¥å…·åŒ…è£…å™¨"""
    
    def __init__(self, tool: Callable, fallback_tools: List[Callable] = None):
        self.tool = tool
        self.fallback_tools = fallback_tools or []
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def invoke_with_retry(self, *args, **kwargs):
        """å¸¦é‡è¯•çš„è°ƒç”¨"""
        try:
            return self.tool(*args, **kwargs)
        except Exception as e:
            logging.warning(f"Tool {self.tool.__name__} failed: {e}")
            raise
    
    def invoke_with_fallback(self, *args, **kwargs):
        """å¸¦é™çº§çš„è°ƒç”¨"""
        try:
            return self.invoke_with_retry(*args, **kwargs)
        except Exception as e:
            logging.error(f"Primary tool failed: {e}")
            
            # å°è¯•å¤‡ç”¨å·¥å…·
            for fallback_tool in self.fallback_tools:
                try:
                    logging.info(f"Trying fallback: {fallback_tool.__name__}")
                    return fallback_tool(*args, **kwargs)
                except Exception as fallback_error:
                    logging.warning(f"Fallback {fallback_tool.__name__} also failed: {fallback_error}")
                    continue
            
            # æ‰€æœ‰å·¥å…·éƒ½å¤±è´¥
            raise Exception(f"All tools failed for {self.tool.__name__}")

# ä½¿ç”¨ç¤ºä¾‹
from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun

# ä¸»å·¥å…·ï¼šDuckDuckGoæœç´¢
primary_search = DuckDuckGoSearchRun()

# å¤‡ç”¨å·¥å…·ï¼šWikipedia
fallback_search = WikipediaQueryRun()

# åˆ›å»ºå¥å£®çš„æœç´¢å·¥å…·
robust_search = RobustTool(
    tool=primary_search,
    fallback_tools=[fallback_search]
)

# Agentä½¿ç”¨
result = robust_search.invoke_with_fallback("LangChain tutorials")
```

### 21.4.3 é”™è¯¯åé¦ˆä¸è‡ªæ„ˆ

å°†é”™è¯¯ä¿¡æ¯åé¦ˆç»™ Agentï¼Œè®©å…¶è°ƒæ•´ç­–ç•¥ï¼š

```python
class SelfHealingAgent:
    """è‡ªæ„ˆAgent"""
    
    def __init__(self, agent, max_heal_attempts: int = 3):
        self.agent = agent
        self.max_heal_attempts = max_heal_attempts
    
    def invoke(self, task: str):
        messages = [HumanMessage(content=task)]
        
        for attempt in range(self.max_heal_attempts):
            try:
                result = self.agent.invoke({"messages": messages})
                return result  # æˆåŠŸ
                
            except ToolException as e:
                # å·¥å…·é”™è¯¯ï¼Œæä¾›é”™è¯¯ä¿¡æ¯è®©Agentè°ƒæ•´
                error_feedback = f"""å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{e}

å¯èƒ½çš„åŸå› ï¼š
1. å‚æ•°æ ¼å¼ä¸æ­£ç¡®
2. å·¥å…·æš‚æ—¶ä¸å¯ç”¨
3. æƒé™ä¸è¶³

è¯·ï¼š
1. æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®
2. è€ƒè™‘ä½¿ç”¨å…¶ä»–å·¥å…·
3. è°ƒæ•´æ‰§è¡Œç­–ç•¥

è¯·é‡æ–°å°è¯•ã€‚"""
                
                messages.append(AIMessage(content=str(result)))
                messages.append(HumanMessage(content=error_feedback))
                
                logging.info(f"Self-healing attempt {attempt + 1}/{self.max_heal_attempts}")
                
        raise Exception(f"Agent failed after {self.max_heal_attempts} self-healing attempts")

# ä½¿ç”¨
agent = SelfHealingAgent(create_react_agent(...))
result = agent.invoke("æœç´¢LangChainæœ€æ–°åŠŸèƒ½å¹¶æ€»ç»“")
```

<div data-component="ErrorRecoveryFlowDiagram"></div>

### 21.4.4 éƒ¨åˆ†ç»“æœå¤„ç†

å³ä½¿æŸäº›æ­¥éª¤å¤±è´¥ï¼Œä¹Ÿèƒ½åˆ©ç”¨å·²æˆåŠŸçš„éƒ¨åˆ†ï¼š

```python
class PartialResultHandler:
    """éƒ¨åˆ†ç»“æœå¤„ç†å™¨"""
    
    def execute_plan_with_partial_results(self, plan: Plan):
        """æ‰§è¡Œè®¡åˆ’ï¼Œå®¹å¿éƒ¨åˆ†å¤±è´¥"""
        results = {
            "successful_steps": [],
            "failed_steps": [],
            "partial_output": None
        }
        
        for step in plan.steps:
            try:
                result = execute_step(step)
                results["successful_steps"].append({
                    "step": step,
                    "result": result
                })
            except Exception as e:
                results["failed_steps"].append({
                    "step": step,
                    "error": str(e)
                })
                
                # è¯„ä¼°æ˜¯å¦å¯ä»¥ç»§ç»­
                if step.critical:
                    # å…³é”®æ­¥éª¤å¤±è´¥ï¼Œç»ˆæ­¢
                    break
                else:
                    # éå…³é”®æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ
                    logging.warning(f"Non-critical step {step.id} failed, continuing...")
        
        # åŸºäºæˆåŠŸçš„éƒ¨åˆ†ç”Ÿæˆè¾“å‡º
        if results["successful_steps"]:
            results["partial_output"] = generate_partial_output(
                results["successful_steps"]
            )
        
        return results
```

---

## 21.5 ä¼ä¸šçº§ Agent å¯é æ€§å·¥ç¨‹

### 21.5.1 è¶…æ—¶æ§åˆ¶

```python
from langchain_core.runnables import RunnableConfig
import signal

class TimeoutAgent:
    """å¸¦è¶…æ—¶æ§åˆ¶çš„Agent"""
    
    def invoke_with_timeout(self, input_data: dict, timeout_seconds: int = 60):
        """è®¾ç½®è¶…æ—¶æ—¶é—´"""
        
        config = RunnableConfig(
            timeout=timeout_seconds,
            max_concurrency=5
        )
        
        try:
            result = self.agent.invoke(input_data, config=config)
            return result
        except TimeoutError:
            logging.error(f"Agent timed out after {timeout_seconds} seconds")
            return {
                "status": "timeout",
                "partial_result": self.get_partial_result()
            }

# ä½¿ç”¨UNIXä¿¡å·å®ç°æ›´ä¸¥æ ¼çš„è¶…æ—¶
def timeout_handler(signum, frame):
    raise TimeoutError("Operation timed out")

def strict_timeout_invoke(agent, input_data, timeout: int):
    """ä¸¥æ ¼çš„è¶…æ—¶æ§åˆ¶"""
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(timeout)
    
    try:
        result = agent.invoke(input_data)
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
        return result
    except TimeoutError:
        signal.alarm(0)
        return {"error": "timeout"}
```

### 21.5.2 æˆæœ¬æ§åˆ¶

```python
class CostAwareAgent:
    """æˆæœ¬æ„ŸçŸ¥Agent"""
    
    def __init__(self, budget_tokens: int = 100000):
        self.budget_tokens = budget_tokens
        self.used_tokens = 0
    
    def invoke(self, input_data: dict):
        # é¢„ä¼°tokenæ¶ˆè€—
        estimated_tokens = estimate_tokens(input_data)
        
        if self.used_tokens + estimated_tokens > self.budget_tokens:
            raise BudgetExceededError(
                f"Token budget exceeded: {self.used_tokens}/{self.budget_tokens}"
            )
        
        # ä½¿ç”¨å›è°ƒè¿½è¸ªå®é™…æ¶ˆè€—
        from langchain.callbacks import get_openai_callback
        
        with get_openai_callback() as cb:
            result = self.agent.invoke(input_data)
            
            self.used_tokens += cb.total_tokens
            
            logging.info(f"Used {cb.total_tokens} tokens, "
                        f"Total: {self.used_tokens}/{self.budget_tokens}")
        
        return result
    
    def get_cost_report(self):
        """æˆæœ¬æŠ¥å‘Š"""
        return {
            "total_budget": self.budget_tokens,
            "used": self.used_tokens,
            "remaining": self.budget_tokens - self.used_tokens,
            "utilization": f"{self.used_tokens/self.budget_tokens*100:.1f}%"
        }
```

### 21.5.3 å¹»è§‰æ£€æµ‹ä¸ç¼“è§£

```python
class HallucinationDetector:
    """å¹»è§‰æ£€æµ‹å™¨"""
    
    def detect(self, output: str, context: str) -> dict:
        """æ£€æµ‹æ½œåœ¨çš„å¹»è§‰"""
        
        checks = {
            "factual_consistency": self.check_factual_consistency(output, context),
            "citation_validity": self.check_citations(output),
            "numerical_accuracy": self.check_numbers(output, context)
        }
        
        hallucination_score = sum(
            1 for check in checks.values() if not check["passed"]
        ) / len(checks)
        
        return {
            "is_likely_hallucination": hallucination_score > 0.3,
            "confidence": 1 - hallucination_score,
            "checks": checks
        }
    
    def check_factual_consistency(self, output: str, context: str):
        """æ£€æŸ¥äº‹å®ä¸€è‡´æ€§"""
        # ä½¿ç”¨LLMéªŒè¯
        verifier = ChatOpenAI(model="gpt-4")
        
        prompt = f"""éªŒè¯ä»¥ä¸‹è¾“å‡ºæ˜¯å¦ä¸ç»™å®šä¸Šä¸‹æ–‡ä¸€è‡´ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

è¾“å‡ºï¼š
{output}

è¿”å›ï¼š
- consistent: true/false
- inconsistencies: [åˆ—å‡ºä¸ä¸€è‡´çš„åœ°æ–¹]"""
        
        result = verifier.invoke(prompt)
        # è§£æç»“æœ
        return {"passed": "consistent: true" in result.content.lower()}

# ä½¿ç”¨
detector = HallucinationDetector()

output = agent.invoke("ä»‹ç»LangChain")
detection = detector.detect(output, context=search_results)

if detection["is_likely_hallucination"]:
    logging.warning("Potential hallucination detected!")
    # è§¦å‘é‡æ–°ç”Ÿæˆæˆ–äººå·¥å®¡æ ¸
```

### 21.5.4 è¾“å‡ºéªŒè¯

```python
class OutputValidator:
    """è¾“å‡ºéªŒè¯å™¨"""
    
    def validate(self, output: Any, schema: BaseModel) -> dict:
        """éªŒè¯è¾“å‡ºæ ¼å¼å’Œå†…å®¹"""
        
        validations = {
            "format": self.validate_format(output, schema),
            "completeness": self.validate_completeness(output, schema),
            "quality": self.validate_quality(output)
        }
        
        all_passed = all(v["passed"] for v in validations.values())
        
        return {
            "valid": all_passed,
            "validations": validations,
            "issues": [v["error"] for v in validations.values() if not v["passed"]]
        }
    
    def validate_format(self, output: Any, schema: BaseModel):
        """éªŒè¯æ ¼å¼"""
        try:
            schema.parse_obj(output)
            return {"passed": True}
        except Exception as e:
            return {"passed": False, "error": f"Format error: {e}"}
    
    def validate_completeness(self, output: Any, schema: BaseModel):
        """éªŒè¯å®Œæ•´æ€§"""
        required_fields = get_required_fields(schema)
        missing = [f for f in required_fields if f not in output]
        
        return {
            "passed": len(missing) == 0,
            "error": f"Missing fields: {missing}" if missing else None
        }
    
    def validate_quality(self, output: str):
        """éªŒè¯è´¨é‡"""
        quality_checks = {
            "min_length": len(output) >= 100,
            "has_structure": bool(re.search(r'\n\s*\n', output)),  # æœ‰æ®µè½
            "no_placeholders": "TODO" not in output and "..." not in output
        }
        
        passed = all(quality_checks.values())
        
        return {
            "passed": passed,
            "error": f"Quality issues: {[k for k, v in quality_checks.items() if not v]}" if not passed else None
        }
```

---

## 21.6 å®Œæ•´æ¡ˆä¾‹ï¼šæ™ºèƒ½ç ”ç©¶åŠ©æ‰‹

å°† Planningã€Reflectionã€Memory ç»“åˆçš„å®Œæ•´ç³»ç»Ÿï¼š

```python
class AdvancedResearchAssistant:
    """é«˜çº§ç ”ç©¶åŠ©æ‰‹ï¼šPlanning + Reflection + Memory"""
    
    def __init__(self):
        self.planner = create_planner()
        self.executor = create_executor(tools)
        self.critic = create_critic("research")
        self.memory = AgentMemory()
    
    def research(self, topic: str, quality_threshold: float = 8.0):
        """æ‰§è¡Œç ”ç©¶ä»»åŠ¡"""
        
        # Phase 1: Planning
        print("ğŸ“‹ åˆ¶å®šç ”ç©¶è®¡åˆ’...")
        
        # æ£€ç´¢ç›¸ä¼¼å†å²ç»éªŒ
        similar_research = self.memory.retrieve_similar_experiences(topic)
        
        plan = self.planner.invoke({
            "user_input": topic,
            "historical_insights": format_insights(similar_research)
        })
        
        print(f"è®¡åˆ’åŒ…å« {len(plan.steps)} ä¸ªæ­¥éª¤")
        
        # Phase 2: Execute with Reflection
        research_output = None
        iteration = 0
        max_iterations = 3
        
        while iteration < max_iterations:
            print(f"\nğŸ”„ æ‰§è¡Œè½®æ¬¡ {iteration + 1}")
            
            # æ‰§è¡Œè®¡åˆ’
            execution_results = []
            for step in plan.steps:
                print(f"  æ‰§è¡Œ: {step.description}")
                result = self.executor.invoke(step)
                execution_results.append(result)
            
            # æ•´åˆç»“æœ
            research_output = synthesize_results(execution_results)
            
            # Self-Critique
            print("  ğŸ” è´¨é‡è¯„ä¼°...")
            critique = self.critic.invoke({"content": research_output})
            
            print(f"  è¯„åˆ†: {critique.overall_score}/10")
            
            if critique.overall_score >= quality_threshold:
                print("  âœ“ è¾¾åˆ°è´¨é‡æ ‡å‡†")
                break
            else:
                print(f"  âœ— éœ€è¦æ”¹è¿›: {', '.join(critique.critiques[0].issues)}")
                
                # æ ¹æ®æ‰¹è¯„æ”¹è¿›è®¡åˆ’
                plan = self.refine_plan(plan, critique, execution_results)
                iteration += 1
        
        # Phase 3: Store Experience
        self.memory.store_episode(
            task=topic,
            solution=str(plan),
            outcome=research_output,
            success=critique.overall_score >= quality_threshold
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(
            topic=topic,
            plan=plan,
            output=research_output,
            critique=critique,
            iterations=iteration + 1
        )
        
        return report
    
    def refine_plan(self, original_plan: Plan, critique: SelfAssessment, 
                    results: List) -> Plan:
        """æ ¹æ®æ‰¹è¯„æ„è§æ”¹è¿›è®¡åˆ’"""
        
        refinement_prompt = f"""åŸè®¡åˆ’å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
{format_critique(critique)}

å·²æ‰§è¡Œæ­¥éª¤åŠç»“æœï¼š
{format_results(results)}

è¯·ç”Ÿæˆæ”¹è¿›çš„è®¡åˆ’ï¼Œé’ˆå¯¹æ€§åœ°è§£å†³è¿™äº›é—®é¢˜ã€‚"""
        
        new_plan = self.planner.invoke({"user_input": refinement_prompt})
        return new_plan
    
    def generate_report(self, **kwargs) -> dict:
        """ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""
        return {
            "topic": kwargs["topic"],
            "final_output": kwargs["output"],
            "quality_score": kwargs["critique"].overall_score,
            "iterations": kwargs["iterations"],
            "plan_summary": summarize_plan(kwargs["plan"]),
            "timestamp": datetime.now()
        }

# ä½¿ç”¨
assistant = AdvancedResearchAssistant()

report = assistant.research(
    topic="LangGraphåœ¨ä¼ä¸šAIç³»ç»Ÿä¸­çš„åº”ç”¨æ¨¡å¼ä¸æœ€ä½³å®è·µ",
    quality_threshold=8.5
)

print("\n" + "="*60)
print("ç ”ç©¶æŠ¥å‘Š")
print("="*60)
print(f"ä¸»é¢˜: {report['topic']}")
print(f"è´¨é‡è¯„åˆ†: {report['quality_score']}/10")
print(f"è¿­ä»£æ¬¡æ•°: {report['iterations']}")
print(f"\n{report['final_output']}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
ğŸ“‹ åˆ¶å®šç ”ç©¶è®¡åˆ’...
æ‰¾åˆ°3æ¡ç›¸ä¼¼å†å²ç ”ç©¶
è®¡åˆ’åŒ…å« 5 ä¸ªæ­¥éª¤

ğŸ”„ æ‰§è¡Œè½®æ¬¡ 1
  æ‰§è¡Œ: æœç´¢LangGraphæœ€æ–°æ–‡æ¡£å’Œæ¡ˆä¾‹
  æ‰§è¡Œ: åˆ†æä¼ä¸šåº”ç”¨æ¨¡å¼
  æ‰§è¡Œ: æ•´ç†æœ€ä½³å®è·µ
  æ‰§è¡Œ: ç¼–å†™æŠ€æœ¯åˆ†æ
  æ‰§è¡Œ: ç”Ÿæˆä»£ç ç¤ºä¾‹
  ğŸ” è´¨é‡è¯„ä¼°...
  è¯„åˆ†: 7.5/10
  âœ— éœ€è¦æ”¹è¿›: ç¼ºå°‘å®é™…æ¡ˆä¾‹æ•°æ®, æœ€ä½³å®è·µä¸å¤Ÿå…·ä½“

ğŸ”„ æ‰§è¡Œè½®æ¬¡ 2
  æ‰§è¡Œ: è¡¥å……å®é™…æ¡ˆä¾‹ç ”ç©¶
  æ‰§è¡Œ: æ·±åŒ–æœ€ä½³å®è·µåˆ†æ
  æ‰§è¡Œ: ä¼˜åŒ–æŠ€æœ¯åˆ†ææ·±åº¦
  ğŸ” è´¨é‡è¯„ä¼°...
  è¯„åˆ†: 8.7/10
  âœ“ è¾¾åˆ°è´¨é‡æ ‡å‡†

============================================================
ç ”ç©¶æŠ¥å‘Š
============================================================
ä¸»é¢˜: LangGraphåœ¨ä¼ä¸šAIç³»ç»Ÿä¸­çš„åº”ç”¨æ¨¡å¼ä¸æœ€ä½³å®è·µ
è´¨é‡è¯„åˆ†: 8.7/10
è¿­ä»£æ¬¡æ•°: 2

[è¯¦ç»†çš„ç ”ç©¶å†…å®¹...]
```

---

## æœ¬ç« æ€»ç»“

æœ¬ç« æ·±å…¥æ¢è®¨äº†é«˜çº§ Agent æ¨¡å¼ï¼š

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
- **Planning Agent**ï¼šå…ˆè§„åˆ’åæ‰§è¡Œï¼Œç»“æ„åŒ–ä»»åŠ¡å¤„ç†
- **Reflection Agent**ï¼šè‡ªæˆ‘æ‰¹è¯„ä¸è¿­ä»£æ”¹è¿›
- **Memory-Augmented Agent**ï¼šä»å†å²ç»éªŒä¸­å­¦ä¹ 
- **Error Recovery**ï¼šå·¥å…·å¤±è´¥çš„å®¹é”™ä¸è‡ªæ„ˆ

**å…³é”®æŠ€æœ¯**ï¼š
- Plan-and-Execute æ¡†æ¶å®ç°
- åˆ†å±‚è§„åˆ’ä¸åŠ¨æ€é‡è§„åˆ’
- å¤šè§’åº¦æ‰¹è¯„æœºåˆ¶
- é•¿æœŸè®°å¿†çš„å­˜å‚¨ä¸æ£€ç´¢
- å·¥å…·è°ƒç”¨çš„é‡è¯•ä¸é™çº§
- æˆæœ¬æ§åˆ¶ä¸è´¨é‡éªŒè¯

**æœ€ä½³å®è·µ**ï¼š
- è®¾ç½®åˆç†çš„è¿­ä»£æ¬¡æ•°ä¸Šé™ï¼ˆ3-5æ¬¡ï¼‰
- ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæå‡è§„åˆ’è´¨é‡
- å»ºç«‹å¤šç»´åº¦çš„è¯„ä¼°æ ‡å‡†
- å¹³è¡¡è´¨é‡è¦æ±‚ä¸æ‰§è¡Œæˆæœ¬
- å®Œå–„çš„ç›‘æ§å’Œæ—¥å¿—

**ç”Ÿäº§éƒ¨ç½²å»ºè®®**ï¼š
- è¶…æ—¶æ§åˆ¶ï¼šé˜²æ­¢æ— é™æ‰§è¡Œ
- æˆæœ¬æ§åˆ¶ï¼šTokené¢„ç®—ç®¡ç†
- è´¨é‡ä¿è¯ï¼šè¾“å‡ºéªŒè¯ä¸å¹»è§‰æ£€æµ‹
- å¯è§‚æµ‹æ€§ï¼šå®Œæ•´çš„æ‰§è¡Œè¿½è¸ª

è¿™äº›é«˜çº§æ¨¡å¼æ˜¾è‘—æå‡äº† Agent åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ˜¯æ„å»ºä¼ä¸šçº§ AI åº”ç”¨çš„å…³é”®æŠ€æœ¯ã€‚

---

## ç»ƒä¹ é¢˜

1. **Planningä¼˜åŒ–**ï¼šè®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿå¹¶è¡Œæ‰§è¡Œç‹¬ç«‹æ­¥éª¤çš„ Plan-Execute Agent

2. **Reflectionæ”¹è¿›**ï¼šå®ç°ä¸€ä¸ªæ”¯æŒ"å¤šä¸“å®¶æŠ•ç¥¨"çš„æ‰¹è¯„æœºåˆ¶

3. **Memoryåº”ç”¨**ï¼šæ„å»ºä¸€ä¸ªèƒ½å¤Ÿä»å¤±è´¥ä¸­å­¦ä¹ çš„ Agentï¼ˆåˆ†æå¤±è´¥æ¨¡å¼ï¼‰

4. **å®¹é”™æŒ‘æˆ˜**ï¼šå®ç°ä¸€ä¸ªæ”¯æŒ"éƒ¨åˆ†é‡è¯•"çš„ Agentï¼ˆåªé‡è¯•å¤±è´¥çš„æ­¥éª¤ï¼‰

5. **ç»¼åˆæ¡ˆä¾‹**ï¼šæ„å»ºä¸€ä¸ª"æ™ºèƒ½ä»£ç å®¡æŸ¥Agent"ï¼Œç»“åˆPlanningï¼ˆå®¡æŸ¥è®¡åˆ’ï¼‰+ Reflectionï¼ˆå¤šè½®æ”¹è¿›ï¼‰+ Memoryï¼ˆç¼–ç è§„èŒƒåº“ï¼‰

---

## æ‰©å±•é˜…è¯»

- [Plan-and-Solve Prompting (Paper)](https://arxiv.org/abs/2305.04091)
- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366)
- [LangGraph Plan-and-Execute Tutorial](https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/)
- [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)
- [Tree of Thoughts: Deliberate Problem Solving with LLM](https://arxiv.org/abs/2305.10601)
