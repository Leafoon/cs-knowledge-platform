# Chapter 24: LangSmith ç”Ÿäº§ç›‘æ§

## æœ¬ç« æ¦‚è§ˆ

åœ¨å®Œæˆäº† Tracingï¼ˆè¿½è¸ªï¼‰å’Œ Evaluationï¼ˆè¯„ä¼°ï¼‰åï¼Œç”Ÿäº§ç¯å¢ƒè¿˜éœ€è¦**æŒç»­ç›‘æ§**ã€‚LangSmith çš„ç›‘æ§ç³»ç»Ÿæä¾›å®æ—¶ä»ªè¡¨ç›˜ã€æ™ºèƒ½å‘Šè­¦ã€åœ¨çº¿ Playgroundã€è¿è¡Œç»“æœæ ‡æ³¨ä¸æˆæœ¬åˆ†æï¼Œå¸®åŠ©ä½ åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¿æŒåº”ç”¨çš„ç¨³å®šæ€§ã€æ€§èƒ½ä¸æˆæœ¬å¯æ§æ€§ã€‚æœ¬ç« å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨ LangSmith æ„å»ºå®Œæ•´çš„ç”Ÿäº§çº§å¯è§‚æµ‹æ€§ä½“ç³»ã€‚

**æœ¬ç« é‡ç‚¹**ï¼š
- ç›‘æ§é¢æ¿ï¼ˆDashboardï¼‰ï¼šå®æ—¶æŒ‡æ ‡ä¸è¶‹åŠ¿åˆ†æ
- å‘Šè­¦ï¼ˆAlertsï¼‰ï¼šè‡ªåŠ¨åŒ–é—®é¢˜æ£€æµ‹ä¸é€šçŸ¥
- Playgroundï¼šåœ¨çº¿æç¤ºè°ƒè¯•ä¸å¯¹æ¯”
- Annotation & Curationï¼šè¿è¡Œç»“æœæ ‡æ³¨ä¸æ•°æ®é›†æ„å»º
- æˆæœ¬åˆ†æï¼šToken æ¶ˆè€—è¿½è¸ªä¸ä¼˜åŒ–

---

## 24.1 ç›‘æ§é¢æ¿ï¼ˆMonitoring Dashboardï¼‰

### 24.1.1 å®æ—¶è¯·æ±‚é‡ç›‘æ§

<div data-component="MonitoringDashboard"></div>

**è®¿é—®ç›‘æ§é¢æ¿**ï¼š

1. ç™»å½• [https://smith.langchain.com](https://smith.langchain.com)
2. è¿›å…¥é¡¹ç›® â†’ **Monitoring** æ ‡ç­¾
3. æŸ¥çœ‹å®æ—¶æŒ‡æ ‡

**å…³é”®æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡å€¼ |
|------|------|--------|
| **Requests/min** | æ¯åˆ†é’Ÿè¯·æ±‚æ•° | å–å†³äºæµé‡ |
| **Success Rate** | æˆåŠŸç‡ | > 99% |
| **Error Rate** | é”™è¯¯ç‡ | < 1% |
| **Avg Latency** | å¹³å‡å»¶è¿Ÿ | < 2s |
| **P95 Latency** | 95% è¯·æ±‚å»¶è¿Ÿ | < 5s |
| **P99 Latency** | 99% è¯·æ±‚å»¶è¿Ÿ | < 10s |

**ä»£ç ä¸­æŸ¥è¯¢æŒ‡æ ‡**ï¼š

```python
from langsmith import Client
from datetime import datetime, timedelta

client = Client()

# æŸ¥è¯¢æœ€è¿‘ 1 å°æ—¶çš„ Runs
end_time = datetime.now()
start_time = end_time - timedelta(hours=1)

runs = client.list_runs(
    project_name="production-chatbot",
    start_time=start_time,
    end_time=end_time
)

# è®¡ç®—æŒ‡æ ‡
total_runs = 0
successful_runs = 0
failed_runs = 0
latencies = []

for run in runs:
    total_runs += 1
    if run.status == "success":
        successful_runs += 1
    else:
        failed_runs += 1
    
    if run.end_time and run.start_time:
        latency_ms = (run.end_time - run.start_time).total_seconds() * 1000
        latencies.append(latency_ms)

# ç»Ÿè®¡
success_rate = (successful_runs / total_runs * 100) if total_runs > 0 else 0
error_rate = (failed_runs / total_runs * 100) if total_runs > 0 else 0
avg_latency = sum(latencies) / len(latencies) if latencies else 0

# P95ã€P99 å»¶è¿Ÿ
latencies_sorted = sorted(latencies)
p95_index = int(len(latencies_sorted) * 0.95)
p99_index = int(len(latencies_sorted) * 0.99)
p95_latency = latencies_sorted[p95_index] if p95_index < len(latencies_sorted) else 0
p99_latency = latencies_sorted[p99_index] if p99_index < len(latencies_sorted) else 0

print(f"ğŸ“Š ç›‘æ§æŠ¥å‘Šï¼ˆæœ€è¿‘ 1 å°æ—¶ï¼‰")
print(f"æ€»è¯·æ±‚æ•°: {total_runs}")
print(f"æˆåŠŸç‡: {success_rate:.2f}%")
print(f"é”™è¯¯ç‡: {error_rate:.2f}%")
print(f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.0f}ms")
print(f"P95 å»¶è¿Ÿ: {p95_latency:.0f}ms")
print(f"P99 å»¶è¿Ÿ: {p99_latency:.0f}ms")
```

### 24.1.2 å»¶è¿Ÿåˆ†å¸ƒï¼ˆP50ã€P95ã€P99ï¼‰

**ä¸ºä»€ä¹ˆä½¿ç”¨ç™¾åˆ†ä½æ•°ï¼Ÿ**

```python
# ç¤ºä¾‹ï¼š10 ä¸ªè¯·æ±‚çš„å»¶è¿Ÿï¼ˆmsï¼‰
latencies = [100, 110, 120, 95, 105, 130, 140, 3000, 115, 125]

# å¹³å‡å€¼ä¼šè¢«æç«¯å€¼æ‹‰é«˜
avg = sum(latencies) / len(latencies)  # 1044ms

# P95 æ›´èƒ½åæ˜ å¤§å¤šæ•°ç”¨æˆ·ä½“éªŒ
sorted_latencies = sorted(latencies)
p95 = sorted_latencies[int(len(sorted_latencies) * 0.95)]  # 140ms

print(f"å¹³å‡å»¶è¿Ÿ: {avg}ms (è¢« 3000ms æ‹‰é«˜)")
print(f"P95 å»¶è¿Ÿ: {p95}ms (95% ç”¨æˆ·çš„ä½“éªŒ)")
```

**å¯è§†åŒ–å»¶è¿Ÿåˆ†å¸ƒ**ï¼š

```python
import matplotlib.pyplot as plt
import numpy as np

# ç”Ÿæˆå»¶è¿Ÿåˆ†å¸ƒç›´æ–¹å›¾
plt.figure(figsize=(10, 6))
plt.hist(latencies, bins=50, edgecolor='black', alpha=0.7)
plt.axvline(avg_latency, color='red', linestyle='--', label=f'Average: {avg_latency:.0f}ms')
plt.axvline(p95_latency, color='orange', linestyle='--', label=f'P95: {p95_latency:.0f}ms')
plt.axvline(p99_latency, color='purple', linestyle='--', label=f'P99: {p99_latency:.0f}ms')
plt.xlabel('Latency (ms)')
plt.ylabel('Frequency')
plt.title('Latency Distribution')
plt.legend()
plt.show()
```

### 24.1.3 é”™è¯¯ç‡è¿½è¸ª

**é”™è¯¯åˆ†ç±»**ï¼š

```python
from collections import defaultdict

# æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»
error_types = defaultdict(int)

for run in runs:
    if run.error:
        # æå–é”™è¯¯ç±»å‹
        error_message = str(run.error)
        if "RateLimitError" in error_message:
            error_types["Rate Limit"] += 1
        elif "Timeout" in error_message:
            error_types["Timeout"] += 1
        elif "AuthenticationError" in error_message:
            error_types["Authentication"] += 1
        elif "ValidationError" in error_message:
            error_types["Validation"] += 1
        else:
            error_types["Other"] += 1

# æ‰“å°é”™è¯¯åˆ†å¸ƒ
print("\nğŸš¨ é”™è¯¯ç±»å‹åˆ†å¸ƒ")
for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
    percentage = (count / failed_runs * 100) if failed_runs > 0 else 0
    print(f"{error_type:20} {count:5} ({percentage:5.1f}%)")
```

**é”™è¯¯è¶‹åŠ¿åˆ†æ**ï¼š

```python
from datetime import datetime, timedelta
import pandas as pd

# æŒ‰å°æ—¶åˆ†ç»„ç»Ÿè®¡é”™è¯¯
hourly_errors = {}

for run in runs:
    hour_key = run.start_time.replace(minute=0, second=0, microsecond=0)
    if hour_key not in hourly_errors:
        hourly_errors[hour_key] = {"total": 0, "errors": 0}
    
    hourly_errors[hour_key]["total"] += 1
    if run.status != "success":
        hourly_errors[hour_key]["errors"] += 1

# è½¬ä¸º DataFrame
df = pd.DataFrame([
    {
        "hour": hour,
        "error_rate": (data["errors"] / data["total"] * 100) if data["total"] > 0 else 0
    }
    for hour, data in sorted(hourly_errors.items())
])

print("\nğŸ“ˆ é”™è¯¯ç‡è¶‹åŠ¿ï¼ˆæŒ‰å°æ—¶ï¼‰")
print(df)
```

### 24.1.4 Token æ¶ˆè€—è¶‹åŠ¿

```python
# ç»Ÿè®¡ Token æ¶ˆè€—
total_prompt_tokens = 0
total_completion_tokens = 0
total_cost = 0

# GPT-4 ä»·æ ¼ï¼ˆç¤ºä¾‹ï¼‰
PRICE_PER_1K_PROMPT = 0.03
PRICE_PER_1K_COMPLETION = 0.06

for run in runs:
    if run.outputs and "token_usage" in run.outputs:
        usage = run.outputs["token_usage"]
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        
        total_prompt_tokens += prompt_tokens
        total_completion_tokens += completion_tokens
        
        # è®¡ç®—æˆæœ¬
        total_cost += (prompt_tokens / 1000 * PRICE_PER_1K_PROMPT)
        total_cost += (completion_tokens / 1000 * PRICE_PER_1K_COMPLETION)

print(f"\nğŸ’° Token æ¶ˆè€—ç»Ÿè®¡")
print(f"Prompt Tokens: {total_prompt_tokens:,}")
print(f"Completion Tokens: {total_completion_tokens:,}")
print(f"Total Tokens: {total_prompt_tokens + total_completion_tokens:,}")
print(f"ä¼°ç®—æˆæœ¬: ${total_cost:.4f}")
```

---

## 24.2 å‘Šè­¦ï¼ˆAlertsï¼‰

### 24.2.1 å‘Šè­¦è§„åˆ™é…ç½®

<div data-component="AlertRuleBuilder"></div>

**åœ¨ LangSmith UI ä¸­é…ç½®å‘Šè­¦**ï¼š

1. è¿›å…¥é¡¹ç›® â†’ **Settings** â†’ **Alerts**
2. ç‚¹å‡» **Create Alert**
3. é…ç½®è§„åˆ™ï¼š
   - **Metric**: é€‰æ‹©æŒ‡æ ‡ï¼ˆError Rateã€Latencyã€Token Usageï¼‰
   - **Condition**: è®¾ç½®æ¡ä»¶ï¼ˆ> é˜ˆå€¼ï¼‰
   - **Threshold**: é˜ˆå€¼ï¼ˆå¦‚ 5%ã€2000msï¼‰
   - **Duration**: æŒç»­æ—¶é—´ï¼ˆå¦‚ 5 åˆ†é’Ÿï¼‰
   - **Notifications**: é€šçŸ¥æ¸ é“

**ç¤ºä¾‹ï¼šé«˜é”™è¯¯ç‡å‘Šè­¦**

```yaml
Alert Name: High Error Rate
Metric: Error Rate
Condition: Greater than
Threshold: 5%
Duration: 5 minutes
Notifications:
  - Email: team@example.com
  - Slack: #production-alerts
```

### 24.2.2 é˜ˆå€¼å‘Šè­¦ï¼ˆå»¶è¿Ÿã€é”™è¯¯ç‡ï¼‰

**ç¼–ç¨‹æ–¹å¼é…ç½®å‘Šè­¦**ï¼š

```python
from langsmith import Client

client = Client()

# åˆ›å»ºå‘Šè­¦è§„åˆ™ï¼ˆä¼ªä»£ç ï¼Œå®é™…éœ€è¦ UI é…ç½®ï¼‰
alert_config = {
    "name": "High Latency Alert",
    "metric": "p95_latency",
    "condition": "greater_than",
    "threshold": 3000,  # 3 ç§’
    "window": 300,  # 5 åˆ†é’Ÿ
    "notifications": [
        {"type": "email", "to": "team@example.com"},
        {"type": "slack", "webhook": "https://hooks.slack.com/..."}
    ]
}

# æ³¨æ„ï¼šLangSmith SDK å¯èƒ½ä¸æ”¯æŒç›´æ¥åˆ›å»ºå‘Šè­¦ï¼Œé€šå¸¸é€šè¿‡ UI é…ç½®
```

**è‡ªå®šä¹‰å‘Šè­¦é€»è¾‘**ï¼š

```python
import time
from datetime import datetime, timedelta

def monitor_and_alert(project_name: str, check_interval: int = 60):
    """è‡ªå®šä¹‰ç›‘æ§ä¸å‘Šè­¦"""
    client = Client()
    
    while True:
        # æŸ¥è¯¢æœ€è¿‘ 5 åˆ†é’Ÿçš„æ•°æ®
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=5)
        
        runs = list(client.list_runs(
            project_name=project_name,
            start_time=start_time,
            end_time=end_time
        ))
        
        if not runs:
            time.sleep(check_interval)
            continue
        
        # è®¡ç®—é”™è¯¯ç‡
        failed = sum(1 for r in runs if r.status != "success")
        error_rate = (failed / len(runs)) * 100
        
        # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
        if error_rate > 5:
            send_alert(
                title="ğŸš¨ High Error Rate Detected",
                message=f"Error rate: {error_rate:.1f}% (threshold: 5%)",
                severity="high"
            )
        
        # è®¡ç®— P95 å»¶è¿Ÿ
        latencies = [
            (r.end_time - r.start_time).total_seconds() * 1000
            for r in runs if r.end_time and r.start_time
        ]
        if latencies:
            latencies_sorted = sorted(latencies)
            p95 = latencies_sorted[int(len(latencies_sorted) * 0.95)]
            
            if p95 > 3000:
                send_alert(
                    title="â±ï¸ High Latency Detected",
                    message=f"P95 latency: {p95:.0f}ms (threshold: 3000ms)",
                    severity="medium"
                )
        
        time.sleep(check_interval)

def send_alert(title: str, message: str, severity: str):
    """å‘é€å‘Šè­¦ï¼ˆé›†æˆ Slackã€é‚®ä»¶ç­‰ï¼‰"""
    print(f"\n{'='*60}")
    print(f"[{severity.upper()}] {title}")
    print(message)
    print(f"{'='*60}\n")
    
    # å®é™…åº”ç”¨ï¼šå‘é€åˆ° Slack / Email / PagerDuty
    # slack_webhook("https://hooks.slack.com/...", message)
    # send_email("team@example.com", title, message)
```

### 24.2.3 å¼‚å¸¸æ£€æµ‹å‘Šè­¦

**åŸºäºç»Ÿè®¡çš„å¼‚å¸¸æ£€æµ‹**ï¼š

```python
import numpy as np

def detect_anomalies(metric_values: list, threshold_std: float = 3) -> list:
    """ä½¿ç”¨ 3-sigma è§„åˆ™æ£€æµ‹å¼‚å¸¸"""
    mean = np.mean(metric_values)
    std = np.std(metric_values)
    
    anomalies = []
    for i, value in enumerate(metric_values):
        z_score = abs(value - mean) / std if std > 0 else 0
        if z_score > threshold_std:
            anomalies.append({
                "index": i,
                "value": value,
                "z_score": z_score,
                "mean": mean,
                "std": std
            })
    
    return anomalies

# ä½¿ç”¨ç¤ºä¾‹
latencies = [100, 110, 95, 105, 3000, 120, 115, 130]  # 3000 æ˜¯å¼‚å¸¸å€¼
anomalies = detect_anomalies(latencies)

for anomaly in anomalies:
    print(f"ğŸ”´ å¼‚å¸¸æ£€æµ‹: å€¼ {anomaly['value']} åç¦»å‡å€¼ {anomaly['z_score']:.1f} ä¸ªæ ‡å‡†å·®")
```

### 24.2.4 é€šçŸ¥æ¸ é“ï¼ˆé‚®ä»¶ã€Slackã€Webhookï¼‰

**Slack é€šçŸ¥**ï¼š

```python
import requests

def send_slack_alert(webhook_url: str, message: str):
    """å‘é€ Slack é€šçŸ¥"""
    payload = {
        "text": message,
        "attachments": [
            {
                "color": "danger",
                "fields": [
                    {"title": "Project", "value": "production-chatbot", "short": True},
                    {"title": "Time", "value": datetime.now().isoformat(), "short": True}
                ]
            }
        ]
    }
    
    response = requests.post(webhook_url, json=payload)
    if response.status_code == 200:
        print("âœ… Slack é€šçŸ¥å·²å‘é€")
    else:
        print(f"âŒ Slack é€šçŸ¥å¤±è´¥: {response.status_code}")

# ä½¿ç”¨
slack_webhook = "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
send_slack_alert(slack_webhook, "ğŸš¨ é”™è¯¯ç‡è¶…è¿‡ 5%ï¼")
```

**é‚®ä»¶é€šçŸ¥**ï¼š

```python
import smtplib
from email.mime.text import MIMEText

def send_email_alert(to_email: str, subject: str, body: str):
    """å‘é€é‚®ä»¶é€šçŸ¥"""
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = 'alerts@example.com'
    msg['To'] = to_email
    
    # SMTP é…ç½®
    smtp_server = 'smtp.gmail.com'
    smtp_port = 587
    smtp_user = 'your-email@gmail.com'
    smtp_password = 'your-password'
    
    with smtplib.SMTP(smtp_server, smtp_port) as server:
        server.starttls()
        server.login(smtp_user, smtp_password)
        server.send_message(msg)
    
    print("âœ… é‚®ä»¶é€šçŸ¥å·²å‘é€")
```

---

## 24.3 Playground

### 24.3.1 Prompt åœ¨çº¿ç¼–è¾‘ä¸æµ‹è¯•

**Playground åŠŸèƒ½**ï¼š

1. **åœ¨çº¿ç¼–è¾‘ Prompt**ï¼šæ— éœ€ä¿®æ”¹ä»£ç å³å¯æµ‹è¯•ä¸åŒæç¤º
2. **å³æ—¶è¿è¡Œ**ï¼šæŸ¥çœ‹è¾“å‡ºã€Token æ¶ˆè€—ã€å»¶è¿Ÿ
3. **ç‰ˆæœ¬å¯¹æ¯”**ï¼šå¹¶æ’å¯¹æ¯”å¤šä¸ªæç¤ºç‰ˆæœ¬
4. **ä¿å­˜åˆ° Hub**ï¼šä¼˜ç§€æç¤ºä¸€é”®åˆ†äº«

**è®¿é—® Playground**ï¼š

1. åœ¨ LangSmith UI ä¸­é€‰æ‹©ä¸€ä¸ª Run
2. ç‚¹å‡» **Open in Playground**
3. ç¼–è¾‘ Prompt æˆ–å‚æ•°
4. ç‚¹å‡» **Run** æµ‹è¯•

**ç¤ºä¾‹ï¼šä¼˜åŒ–ç¿»è¯‘æç¤º**

```
# åŸå§‹ Promptï¼ˆåœ¨ Playground ä¸­ç¼–è¾‘ï¼‰
Translate to French: {text}

# ä¼˜åŒ–å Prompt
You are a professional French translator with expertise in cultural nuances.

Translate the following text to French while:
- Preserving the original tone and style
- Using appropriate French idioms when applicable
- Maintaining grammatical accuracy

Text: {text}

# åœ¨ Playground ä¸­å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬
```

### 24.3.2 æ¨¡å‹å‚æ•°è°ƒä¼˜

**å¯è°ƒå‚æ•°**ï¼š

```python
# åœ¨ Playground ä¸­è°ƒæ•´è¿™äº›å‚æ•°
{
    "temperature": 0.7,       # åˆ›é€ æ€§ï¼š0-2ï¼ˆ0=ç¡®å®šï¼Œ2=éšæœºï¼‰
    "max_tokens": 150,        # æœ€å¤§è¾“å‡ºé•¿åº¦
    "top_p": 0.9,            # æ ¸é‡‡æ ·é˜ˆå€¼
    "frequency_penalty": 0,  # é‡å¤è¯æƒ©ç½šï¼š-2 åˆ° 2
    "presence_penalty": 0,   # æ–°è¯é¢˜é¼“åŠ±ï¼š-2 åˆ° 2
}
```

**å‚æ•°æ•ˆæœå¯¹æ¯”**ï¼š

| å‚æ•° | å€¼ | æ•ˆæœ |
|------|-----|------|
| temperature | 0.0 | ç¡®å®šæ€§å¼ºï¼Œé€‚åˆç¿»è¯‘ã€æ‘˜è¦ |
| temperature | 1.0 | å¹³è¡¡åˆ›é€ æ€§ä¸è¿è´¯æ€§ |
| temperature | 2.0 | é«˜åº¦åˆ›é€ æ€§ï¼Œé€‚åˆå¤´è„‘é£æš´ |
| top_p | 0.5 | ä¿å®ˆï¼Œé€‰æ‹©é«˜æ¦‚ç‡è¯ |
| top_p | 0.95 | å®½æ¾ï¼Œå…è®¸å¤šæ ·æ€§ |

### 24.3.3 å¯¹æ¯”ä¸åŒé…ç½®

**åœ¨ Playground ä¸­å¯¹æ¯”**ï¼š

```
é…ç½® A:
- Model: gpt-4
- Temperature: 0.7
- Prompt: "Translate to French: {text}"

é…ç½® B:
- Model: gpt-3.5-turbo
- Temperature: 0.3
- Prompt: "Professional French translation: {text}"

è¾“å…¥: "The weather is nice today."

ç»“æœå¯¹æ¯”:
é…ç½® A: "Le temps est agrÃ©able aujourd'hui."
é…ç½® B: "Il fait beau aujourd'hui."

Token æ¶ˆè€—:
é…ç½® A: 45 tokens, $0.0027
é…ç½® B: 35 tokens, $0.0007

é€‰æ‹©: é…ç½® Bï¼ˆæ›´ä¾¿å®œï¼Œè´¨é‡ç›¸è¿‘ï¼‰
```

### 24.3.4 ä¿å­˜ä¸º Hub Prompt

```python
from langchain import hub

# åœ¨ Playground ä¸­æµ‹è¯•å¹¶ä¼˜åŒ–åï¼Œä¿å­˜åˆ° Hub
prompt = hub.pull("your-username/optimized-translation-prompt")

# å›¢é˜Ÿå…¶ä»–æˆå‘˜å¯ä»¥ç›´æ¥ä½¿ç”¨
# prompt = hub.pull("your-username/optimized-translation-prompt")
```

---

## 24.4 Annotation & Curation

### 24.4.1 è¿è¡Œç»“æœæ ‡æ³¨

**ä¸ºä»€ä¹ˆéœ€è¦æ ‡æ³¨ï¼Ÿ**

ç”Ÿäº§ç¯å¢ƒä¸­çš„è¿è¡Œç»“æœæ˜¯å®è´µçš„è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡æ ‡æ³¨å¯ä»¥ï¼š
- æ„å»ºé«˜è´¨é‡è¯„ä¼°æ•°æ®é›†
- å‘ç°è¾¹ç•Œæƒ…å†µä¸å¤±è´¥æ¨¡å¼
- æŒç»­æ”¹è¿›æ¨¡å‹ä¸æç¤º

**åœ¨ UI ä¸­æ ‡æ³¨**ï¼š

1. é€‰æ‹©ä¸€ä¸ª Run
2. ç‚¹å‡» **Add to Dataset**
3. é€‰æ‹©ç›®æ ‡æ•°æ®é›†
4. å¯é€‰ï¼šä¿®æ­£è¾“å‡ºï¼ˆå¦‚æœ AI è¾“å‡ºæœ‰è¯¯ï¼‰
5. ä¿å­˜

**ç¼–ç¨‹æ–¹å¼æ ‡æ³¨**ï¼š

```python
from langsmith import Client

client = Client()

# æŸ¥è¯¢éœ€è¦æ ‡æ³¨çš„ Runsï¼ˆä¾‹å¦‚ï¼šç”¨æˆ·ç»™äº†å¥½è¯„çš„ï¼‰
high_quality_runs = client.list_runs(
    project_name="production-chatbot",
    filter='feedback.user_rating.score = 1'  # å¥½è¯„
)

# æ·»åŠ åˆ°æ•°æ®é›†
dataset = client.read_dataset(dataset_name="golden-responses")

for run in list(high_quality_runs)[:50]:  # å–å‰ 50 ä¸ª
    client.create_example(
        dataset_id=dataset.id,
        inputs=run.inputs,
        outputs=run.outputs,
        metadata={
            "source": "production",
            "user_rating": "positive",
            "run_id": str(run.id)
        }
    )

print(f"âœ… å·²æ·»åŠ  50 ä¸ªé«˜è´¨é‡æ ·æœ¬åˆ°æ•°æ®é›†")
```

### 24.4.2 æ„å»ºé»„é‡‘æ•°æ®é›†

**é»„é‡‘æ•°æ®é›†ç‰¹å¾**ï¼š

- âœ… **é«˜è´¨é‡**ï¼šç»è¿‡äººå·¥å®¡æ ¸æˆ–ç”¨æˆ·å¥½è¯„
- âœ… **ä»£è¡¨æ€§**ï¼šè¦†ç›–çœŸå®åœºæ™¯
- âœ… **å¤šæ ·æ€§**ï¼šä¸åŒç±»å‹è¾“å…¥
- âœ… **å¯ç»´æŠ¤**ï¼šå®šæœŸæ›´æ–°

**ç­–ç•¥ 1ï¼šä»ç”¨æˆ·åé¦ˆç­›é€‰**

```python
def build_golden_dataset_from_feedback(min_score: float = 0.8):
    """ä»ç”¨æˆ·åé¦ˆä¸­æ„å»ºé»„é‡‘æ•°æ®é›†"""
    client = Client()
    
    # åˆ›å»ºé»„é‡‘æ•°æ®é›†
    golden_dataset = client.create_dataset(
        dataset_name=f"golden-set-{datetime.now().strftime('%Y%m%d')}",
        description="ä»ç”Ÿäº§ç¯å¢ƒé«˜åˆ†æ ·æœ¬ä¸­æ„å»º"
    )
    
    # æŸ¥è¯¢é«˜åˆ† Runs
    high_rated = client.list_runs(
        project_name="production-chatbot",
        filter=f'feedback.user_rating.score >= {min_score}'
    )
    
    # æ·»åŠ åˆ°æ•°æ®é›†
    added = 0
    for run in high_rated:
        if added >= 100:  # é™åˆ¶æ•°é‡
            break
        
        client.create_example(
            dataset_id=golden_dataset.id,
            inputs=run.inputs,
            outputs=run.outputs
        )
        added += 1
    
    print(f"âœ… é»„é‡‘æ•°æ®é›†å·²åˆ›å»ºï¼ŒåŒ…å« {added} ä¸ªæ ·æœ¬")
    return golden_dataset
```

**ç­–ç•¥ 2ï¼šä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰**

```python
def active_learning_curation(uncertainty_threshold: float = 0.6):
    """é€‰æ‹©æ¨¡å‹ä¸ç¡®å®šçš„æ ·æœ¬è¿›è¡Œäººå·¥æ ‡æ³¨"""
    client = Client()
    
    # æŸ¥è¯¢æ‰€æœ‰ Runs
    runs = client.list_runs(project_name="production-chatbot")
    
    uncertain_runs = []
    for run in runs:
        # å‡è®¾è¾“å‡ºä¸­æœ‰ confidence åˆ†æ•°
        if run.outputs and "confidence" in run.outputs:
            confidence = run.outputs["confidence"]
            if confidence < uncertainty_threshold:
                uncertain_runs.append(run)
    
    print(f"ğŸ” å‘ç° {len(uncertain_runs)} ä¸ªä¸ç¡®å®šæ ·æœ¬ï¼Œå»ºè®®äººå·¥å®¡æ ¸")
    
    # å¯¼å‡ºå¾…æ ‡æ³¨æ ·æœ¬
    for run in uncertain_runs[:10]:  # å±•ç¤ºå‰ 10 ä¸ª
        print(f"\nRun ID: {run.id}")
        print(f"Input: {run.inputs}")
        print(f"Output: {run.outputs}")
        print(f"Confidence: {run.outputs.get('confidence')}")
        print("è¯·äººå·¥å®¡æ ¸å¹¶æ ‡æ³¨ â†‘")
```

### 24.4.3 æŒç»­æ”¹è¿›å·¥ä½œæµ

**å®Œæ•´é—­ç¯**ï¼š

```
1. ç”Ÿäº§è¿è¡Œ â†’ æ”¶é›†æ•°æ®
   â†“
2. ç”¨æˆ·åé¦ˆ â†’ ç­›é€‰é«˜è´¨é‡æ ·æœ¬
   â†“
3. æ„å»ºæ•°æ®é›† â†’ å®šæœŸè¯„ä¼°
   â†“
4. å‘ç°é—®é¢˜ â†’ ä¼˜åŒ–æç¤º/æ¨¡å‹
   â†“
5. A/B æµ‹è¯• â†’ éƒ¨ç½²æ”¹è¿›ç‰ˆæœ¬
   â†“
å›åˆ°ç¬¬ 1 æ­¥
```

**è‡ªåŠ¨åŒ–è„šæœ¬**ï¼š

```python
import schedule
import time

def weekly_improvement_workflow():
    """æ¯å‘¨è‡ªåŠ¨æ”¹è¿›æµç¨‹"""
    print("ğŸ”„ å¼€å§‹æ¯å‘¨æ”¹è¿›æµç¨‹...")
    
    # 1. æ„å»ºé»„é‡‘æ•°æ®é›†
    golden_dataset = build_golden_dataset_from_feedback(min_score=0.8)
    
    # 2. è¯„ä¼°å½“å‰ç‰ˆæœ¬
    from langsmith.evaluation import evaluate
    
    current_results = evaluate(
        current_chain,
        data=golden_dataset.name,
        evaluators=[...],
        experiment_prefix="weekly-baseline"
    )
    
    # 3. è¯„ä¼°å®éªŒç‰ˆæœ¬
    experimental_results = evaluate(
        experimental_chain,
        data=golden_dataset.name,
        evaluators=[...],
        experiment_prefix="weekly-experiment"
    )
    
    # 4. å†³ç­–
    if experimental_results['avg_score'] > current_results['avg_score'] * 1.03:
        print("âœ… å®éªŒç‰ˆæœ¬æå‡ 3%+ï¼Œå»ºè®®éƒ¨ç½²")
        # è‡ªåŠ¨éƒ¨ç½²æˆ–å‘é€é€šçŸ¥ç»™å›¢é˜Ÿå†³ç­–
    else:
        print("â¸ï¸ æ”¹è¿›ä¸æ˜¾è‘—ï¼Œä¿æŒå½“å‰ç‰ˆæœ¬")

# æ¯å‘¨ä¸€å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œ
schedule.every().monday.at("02:00").do(weekly_improvement_workflow)

while True:
    schedule.run_pending()
    time.sleep(3600)
```

---

## 24.5 æˆæœ¬åˆ†æ

### 24.5.1 Token æ¶ˆè€—æˆæœ¬è®¡ç®—

<div data-component="CostAnalysisDashboard"></div>

**ä»·æ ¼è¡¨ï¼ˆ2024 å¹´ 1 æœˆï¼‰**ï¼š

| æ¨¡å‹ | Prompt ($/1K tokens) | Completion ($/1K tokens) |
|------|---------------------|--------------------------|
| GPT-4 | $0.03 | $0.06 |
| GPT-4 Turbo | $0.01 | $0.03 |
| GPT-3.5 Turbo | $0.0005 | $0.0015 |
| Claude 3 Opus | $0.015 | $0.075 |
| Claude 3 Sonnet | $0.003 | $0.015 |

**è®¡ç®—æˆæœ¬**ï¼š

```python
from langsmith import Client
from datetime import datetime, timedelta

client = Client()

# ä»·æ ¼é…ç½®
PRICING = {
    "gpt-4": {"prompt": 0.03, "completion": 0.06},
    "gpt-4-turbo": {"prompt": 0.01, "completion": 0.03},
    "gpt-3.5-turbo": {"prompt": 0.0005, "completion": 0.0015},
}

def calculate_cost(project_name: str, days: int = 7):
    """è®¡ç®—æŒ‡å®šå¤©æ•°çš„æˆæœ¬"""
    end_time = datetime.now()
    start_time = end_time - timedelta(days=days)
    
    runs = client.list_runs(
        project_name=project_name,
        start_time=start_time,
        end_time=end_time
    )
    
    total_cost = 0
    model_costs = {}
    
    for run in runs:
        if not run.outputs or "token_usage" not in run.outputs:
            continue
        
        usage = run.outputs["token_usage"]
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        
        # è¯†åˆ«æ¨¡å‹
        model_name = run.extra.get("invocation_params", {}).get("model", "gpt-3.5-turbo")
        
        # æŸ¥æ‰¾ä»·æ ¼
        pricing = PRICING.get(model_name, PRICING["gpt-3.5-turbo"])
        
        # è®¡ç®—æˆæœ¬
        cost = (prompt_tokens / 1000 * pricing["prompt"]) + \
               (completion_tokens / 1000 * pricing["completion"])
        
        total_cost += cost
        model_costs[model_name] = model_costs.get(model_name, 0) + cost
    
    # æŠ¥å‘Š
    print(f"\nğŸ’° æˆæœ¬åˆ†ææŠ¥å‘Šï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
    print(f"{'='*60}")
    print(f"æ€»æˆæœ¬: ${total_cost:.4f}")
    print(f"\næŒ‰æ¨¡å‹åˆ†è§£:")
    for model, cost in sorted(model_costs.items(), key=lambda x: x[1], reverse=True):
        percentage = (cost / total_cost * 100) if total_cost > 0 else 0
        print(f"  {model:20} ${cost:8.4f} ({percentage:5.1f}%)")
    
    return total_cost, model_costs

# ä½¿ç”¨
total_cost, model_costs = calculate_cost("production-chatbot", days=7)
```

### 24.5.2 æ¨¡å‹è°ƒç”¨æˆæœ¬æ‹†åˆ†

**æŒ‰åŠŸèƒ½æ‹†åˆ†**ï¼š

```python
def analyze_cost_by_function(project_name: str):
    """æŒ‰åŠŸèƒ½æ‹†åˆ†æˆæœ¬"""
    client = Client()
    
    runs = client.list_runs(project_name=project_name)
    
    function_costs = {}
    
    for run in runs:
        # ä» metadata æˆ– tags ä¸­è¯†åˆ«åŠŸèƒ½
        function_name = run.tags[0] if run.tags else "unknown"
        
        if run.outputs and "token_usage" in run.outputs:
            usage = run.outputs["token_usage"]
            cost = calculate_run_cost(usage)
            function_costs[function_name] = function_costs.get(function_name, 0) + cost
    
    # æ’åºå¹¶æ‰“å°
    print("\nğŸ“Š æŒ‰åŠŸèƒ½æ‹†åˆ†æˆæœ¬")
    for func, cost in sorted(function_costs.items(), key=lambda x: x[1], reverse=True):
        print(f"{func:30} ${cost:.4f}")

def calculate_run_cost(usage: dict) -> float:
    """è®¡ç®—å•ä¸ª Run çš„æˆæœ¬"""
    prompt_tokens = usage.get("prompt_tokens", 0)
    completion_tokens = usage.get("completion_tokens", 0)
    return (prompt_tokens / 1000 * 0.03) + (completion_tokens / 1000 * 0.06)
```

### 24.5.3 ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

**è‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–å»ºè®®**ï¼š

```python
def generate_optimization_recommendations(project_name: str):
    """åˆ†ææˆæœ¬å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    client = Client()
    
    runs = list(client.list_runs(project_name=project_name))
    
    recommendations = []
    
    # åˆ†æ 1ï¼šæ˜¯å¦è¿‡åº¦ä½¿ç”¨ GPT-4
    gpt4_usage = sum(1 for r in runs if "gpt-4" in str(r.extra.get("invocation_params", {}).get("model", "")))
    gpt4_ratio = gpt4_usage / len(runs) if runs else 0
    
    if gpt4_ratio > 0.5:
        recommendations.append({
            "priority": "HIGH",
            "issue": f"GPT-4 ä½¿ç”¨ç‡ {gpt4_ratio*100:.1f}%",
            "suggestion": "è€ƒè™‘å¯¹ç®€å•ä»»åŠ¡é™çº§ä½¿ç”¨ GPT-3.5 Turbo",
            "potential_savings": "70-90%"
        })
    
    # åˆ†æ 2ï¼šPrompt æ˜¯å¦è¿‡é•¿
    avg_prompt_tokens = sum(
        r.outputs.get("token_usage", {}).get("prompt_tokens", 0)
        for r in runs if r.outputs and "token_usage" in r.outputs
    ) / len(runs) if runs else 0
    
    if avg_prompt_tokens > 1000:
        recommendations.append({
            "priority": "MEDIUM",
            "issue": f"å¹³å‡ Prompt é•¿åº¦ {avg_prompt_tokens:.0f} tokens",
            "suggestion": "ä¼˜åŒ– Prompt æ¨¡æ¿ï¼Œç§»é™¤å†—ä½™æŒ‡ä»¤",
            "potential_savings": "20-40%"
        })
    
    # åˆ†æ 3ï¼šç¼“å­˜å‘½ä¸­ç‡ä½
    # ï¼ˆéœ€è¦é›†æˆç¼“å­˜ç›‘æ§æ•°æ®ï¼‰
    
    # æ‰“å°å»ºè®®
    print("\nğŸ”§ æˆæœ¬ä¼˜åŒ–å»ºè®®")
    print("="*60)
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. [{rec['priority']}] {rec['issue']}")
        print(f"   ğŸ’¡ å»ºè®®: {rec['suggestion']}")
        print(f"   ğŸ’° æ½œåœ¨èŠ‚çœ: {rec['potential_savings']}")
    
    return recommendations

# ä½¿ç”¨
recommendations = generate_optimization_recommendations("production-chatbot")
```

---

## 24.6 æœ€ä½³å®è·µ

### 24.6.1 ç›‘æ§æŒ‡æ ‡é€‰æ‹©

**å¿…é¡»ç›‘æ§çš„æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | ç›®æ ‡å€¼ | å‘Šè­¦é˜ˆå€¼ |
|---------|---------|--------|---------|
| **å¯ç”¨æ€§** | Success Rate | > 99.5% | < 99% |
| **æ€§èƒ½** | P95 Latency | < 2s | > 5s |
| **æˆæœ¬** | Daily Cost | é¢„ç®—å†… | > é¢„ç®— * 1.2 |
| **è´¨é‡** | User Rating | > 4.0/5 | < 3.5/5 |

### 24.6.2 å‘Šè­¦ç–²åŠ³é¢„é˜²

```python
# âŒ ä¸å¥½çš„å‘Šè­¦ï¼šæ¯æ¬¡é”™è¯¯éƒ½å‘Šè­¦
if error_rate > 0:
    send_alert("æœ‰é”™è¯¯å‘ç”Ÿ")

# âœ… å¥½çš„å‘Šè­¦ï¼šé”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼ä¸”æŒç»­ä¸€æ®µæ—¶é—´
if error_rate > 5 and duration > 5_minutes:
    send_alert("é”™è¯¯ç‡å¼‚å¸¸é«˜")
```

### 24.6.3 æˆæœ¬æ§åˆ¶ç­–ç•¥

1. **é¢„ç®—å‘Šè­¦**ï¼šè®¾ç½®æ¯æ—¥æˆæœ¬ä¸Šé™
2. **æ¨¡å‹é™çº§**ï¼šç®€å•ä»»åŠ¡ä½¿ç”¨ä¾¿å®œæ¨¡å‹
3. **ç¼“å­˜ä¼˜åŒ–**ï¼šç›¸ä¼¼é—®é¢˜é‡ç”¨ç»“æœ
4. **Prompt ä¼˜åŒ–**ï¼šå‡å°‘ä¸å¿…è¦çš„ Token
5. **æ‰¹å¤„ç†**ï¼šåˆå¹¶å¤šä¸ªè¯·æ±‚

---

## æœ¬ç« æ€»ç»“

**æ ¸å¿ƒæ”¶è·**ï¼š

1. âœ… **ç›‘æ§é¢æ¿**ï¼šå®æ—¶è¿½è¸ªè¯·æ±‚é‡ã€å»¶è¿Ÿã€é”™è¯¯ç‡ã€Token æ¶ˆè€—
2. âœ… **æ™ºèƒ½å‘Šè­¦**ï¼šè‡ªåŠ¨æ£€æµ‹å¼‚å¸¸ï¼ŒåŠæ—¶é€šçŸ¥å›¢é˜Ÿ
3. âœ… **åœ¨çº¿ Playground**ï¼šå¿«é€Ÿæµ‹è¯•æç¤ºä¸å‚æ•°ï¼Œæ— éœ€éƒ¨ç½²
4. âœ… **è¿è¡Œç»“æœæ ‡æ³¨**ï¼šä»ç”Ÿäº§æ•°æ®æ„å»ºé»„é‡‘æ•°æ®é›†
5. âœ… **æˆæœ¬åˆ†æ**ï¼šç²¾ç»†åŒ–æˆæœ¬ç®¡ç†ä¸ä¼˜åŒ–

**å®Œæ•´å¯è§‚æµ‹æ€§ä½“ç³»**ï¼š

```
Chapter 22 (Tracing) â†’ çœ‹åˆ°å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆè°ƒè¯•ï¼‰
Chapter 23 (Evaluation) â†’ åˆ¤æ–­åšå¾—å¥½ä¸å¥½ï¼ˆè´¨é‡ï¼‰
Chapter 24 (Monitoring) â†’ æŒç»­ä¿æŒç¨³å®šï¼ˆç”Ÿäº§ï¼‰
```

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼š
Chapter 25 å°†å­¦ä¹  **LangServe åŸºç¡€**ï¼ŒæŒæ¡å¦‚ä½•å°† LangChain åº”ç”¨éƒ¨ç½²ä¸ºç”Ÿäº§çº§ REST APIã€‚

---

## ç»ƒä¹ é¢˜

### åŸºç¡€ç»ƒä¹ 

1. **è®¡ç®—ç›‘æ§æŒ‡æ ‡**ï¼šæŸ¥è¯¢æœ€è¿‘ 1 å°æ—¶çš„ Runsï¼Œè®¡ç®—æˆåŠŸç‡ã€å¹³å‡å»¶è¿Ÿã€P95 å»¶è¿Ÿã€‚

2. **é…ç½®å‘Šè­¦**ï¼šåœ¨ LangSmith UI ä¸­é…ç½®ä¸€ä¸ªé«˜é”™è¯¯ç‡å‘Šè­¦ï¼ˆ> 5%ï¼‰ã€‚

3. **Playground æµ‹è¯•**ï¼šåœ¨ Playground ä¸­æµ‹è¯•ä¸åŒ temperature å‚æ•°å¯¹è¾“å‡ºçš„å½±å“ã€‚

### è¿›é˜¶ç»ƒä¹ 

4. **è‡ªå®šä¹‰ç›‘æ§è„šæœ¬**ï¼šç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œæ¯åˆ†é’Ÿæ£€æŸ¥é”™è¯¯ç‡ï¼Œè¶…è¿‡ 5% æ—¶å‘é€ Slack é€šçŸ¥ã€‚

5. **æˆæœ¬åˆ†æ**ï¼šè®¡ç®—æœ€è¿‘ 7 å¤©çš„æ€»æˆæœ¬ï¼Œå¹¶æŒ‰æ¨¡å‹æ‹†åˆ†ã€‚

6. **é»„é‡‘æ•°æ®é›†æ„å»º**ï¼šä»ç”¨æˆ·å¥½è¯„ Runs ä¸­ç­›é€‰ 50 ä¸ªé«˜è´¨é‡æ ·æœ¬ï¼Œæ„å»ºé»„é‡‘æ•°æ®é›†ã€‚

### æŒ‘æˆ˜ç»ƒä¹ 

7. **å¼‚å¸¸æ£€æµ‹**ï¼šå®ç°åŸºäº 3-sigma è§„åˆ™çš„å»¶è¿Ÿå¼‚å¸¸æ£€æµ‹ã€‚

8. **æŒç»­æ”¹è¿›æµç¨‹**ï¼šè®¾è®¡ä¸€ä¸ªæ¯å‘¨è‡ªåŠ¨è¿è¡Œçš„è„šæœ¬ï¼Œä»ç”Ÿäº§æ•°æ®æ›´æ–°æ•°æ®é›†å¹¶é‡æ–°è¯„ä¼°ã€‚

9. **æˆæœ¬ä¼˜åŒ–æ–¹æ¡ˆ**ï¼šåˆ†æå½“å‰æˆæœ¬ç»“æ„ï¼Œæå‡ºè‡³å°‘ 3 ä¸ªä¼˜åŒ–å»ºè®®å¹¶ä¼°ç®—èŠ‚çœé‡‘é¢ã€‚

---

## æ‰©å±•é˜…è¯»

- [LangSmith Monitoring Guide](https://docs.smith.langchain.com/monitoring)
- [LangSmith Alerts Documentation](https://docs.smith.langchain.com/alerts)
- [LangSmith Playground Tutorial](https://blog.langchain.dev/langsmith-playground/)
- [Cost Optimization Best Practices](https://blog.langchain.dev/optimizing-llm-costs/)
