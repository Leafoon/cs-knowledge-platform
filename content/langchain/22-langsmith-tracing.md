# Chapter 22: LangSmith Tracing åŸºç¡€

## æœ¬ç« æ¦‚è§ˆ

å½“ LangChain åº”ç”¨å˜å¾—å¤æ‚æ—¶ï¼Œè°ƒè¯•ä¸æ€§èƒ½ä¼˜åŒ–æˆä¸ºæœ€å¤§æŒ‘æˆ˜ï¼šä¸ºä»€ä¹ˆè¿™ä¸ªé“¾å¤±è´¥äº†ï¼Ÿå“ªä¸ªæ­¥éª¤æœ€æ…¢ï¼ŸToken æ¶ˆè€—åœ¨å“ªé‡Œï¼ŸLangSmith çš„ Tracing ç³»ç»Ÿé€šè¿‡**å®Œæ•´çš„æ‰§è¡Œè¿½è¸ª**å’Œ**å¯è§†åŒ–åˆ†æ**ï¼Œè®©å¤æ‚é“¾çš„å†…éƒ¨è¿è¡Œè¿‡ç¨‹ä¸€ç›®äº†ç„¶ã€‚æœ¬ç« å°†æ·±å…¥å­¦ä¹  LangSmith Tracing çš„é…ç½®ã€ç»“æ„ã€åˆ†ææ–¹æ³•å’Œè‡ªå®šä¹‰æŠ€æœ¯ã€‚

**æœ¬ç« é‡ç‚¹**ï¼š
- LangSmith Tracing çš„æ ¸å¿ƒä»·å€¼ä¸åº”ç”¨åœºæ™¯
- Tracing é…ç½®ä¸é¡¹ç›®ç®¡ç†
- Trace ç»“æ„è§£æï¼ˆRunã€Spanã€åµŒå¥—å…³ç³»ï¼‰
- Trace æŸ¥çœ‹ä¸æ€§èƒ½åˆ†æ
- è‡ªå®šä¹‰ Tracing ä¸ Metadata

---

## 22.1 ä¸ºä»€ä¹ˆéœ€è¦ LangSmithï¼Ÿ

### 22.1.1 å¤æ‚é“¾çš„è°ƒè¯•å›°å¢ƒ

éšç€ LangChain åº”ç”¨å˜å¾—å¤æ‚ï¼Œä¼ ç»Ÿè°ƒè¯•æ–¹æ³•å¤±æ•ˆï¼š

**é—®é¢˜ç¤ºä¾‹**ï¼šä¸€ä¸ª RAG åº”ç”¨å¤±è´¥äº†

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA

# å¤æ‚çš„ RAG é“¾
vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4"),
    chain_type="stuff",
    retriever=retriever,
)

# æ‰§è¡Œå¤±è´¥ï¼ä½†æ— æ³•çŸ¥é“å“ªé‡Œå‡ºé”™äº†
result = qa_chain.invoke("What is LangChain?")
# Error: ... ï¼ˆé”™è¯¯ä¿¡æ¯æ¨¡ç³Šï¼‰
```

**è°ƒè¯•éš¾ç‚¹**ï¼š
1. â“ **æ‰§è¡Œè·¯å¾„ä¸é€æ˜**ï¼šæ— æ³•çœ‹åˆ°å†…éƒ¨è°ƒç”¨é“¾
2. â“ **é”™è¯¯å®šä½å›°éš¾**ï¼šä¸çŸ¥é“åœ¨å“ªä¸€æ­¥å¤±è´¥
3. â“ **æ€§èƒ½ç“¶é¢ˆæœªçŸ¥**ï¼šå“ªä¸ªæ­¥éª¤æœ€æ…¢ï¼Ÿ
4. â“ **Token æ¶ˆè€—ä¸æ˜**ï¼šé’±èŠ±åœ¨å“ªé‡Œäº†ï¼Ÿ
5. â“ **è¾“å…¥è¾“å‡ºä¸å¯è§**ï¼šæ¯ä¸€æ­¥çš„ä¸­é—´ç»“æœæ˜¯ä»€ä¹ˆï¼Ÿ

### 22.1.2 ç”Ÿäº§ç›‘æ§éœ€æ±‚

ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½ éœ€è¦å›ç­”è¿™äº›é—®é¢˜ï¼š

| é—®é¢˜ | ä¼ ç»Ÿæ–¹æ³• | LangSmith æ–¹æ¡ˆ |
|------|---------|----------------|
| ç³»ç»Ÿæ˜¯å¦æ­£å¸¸è¿è¡Œï¼Ÿ | æ‰‹åŠ¨æ—¥å¿—æŸ¥çœ‹ | å®æ—¶ Dashboard |
| å“ªäº›è¯·æ±‚å¤±è´¥äº†ï¼Ÿ | grep é”™è¯¯æ—¥å¿— | è‡ªåŠ¨å¤±è´¥è¿½è¸ª |
| å¹³å‡å»¶è¿Ÿå¤šå°‘ï¼Ÿ | è‡ªå·±å†™æŒ‡æ ‡æ”¶é›† | å†…ç½®æ€§èƒ½åˆ†æ |
| Token æˆæœ¬è¶‹åŠ¿ï¼Ÿ | æ‰‹åŠ¨è®¡ç®— | è‡ªåŠ¨æˆæœ¬è¿½è¸ª |
| ç”¨æˆ·ä½“éªŒå¦‚ä½•ï¼Ÿ | ç”¨æˆ·åé¦ˆ | Feedback æœºåˆ¶ |

### 22.1.3 LangSmith æ ¸å¿ƒä»·å€¼

LangSmith æä¾›**ä¸‰ä½ä¸€ä½“**çš„è§£å†³æ–¹æ¡ˆï¼š

```
1. ğŸ” Tracingï¼ˆè¿½è¸ªï¼‰
   â”œâ”€ å®Œæ•´çš„æ‰§è¡Œè¿‡ç¨‹å¯è§†åŒ–
   â”œâ”€ åµŒå¥—è°ƒç”¨é“¾å±•ç¤º
   â””â”€ è¾“å…¥è¾“å‡ºå®Œæ•´è®°å½•

2. ğŸ“Š Evaluationï¼ˆè¯„ä¼°ï¼‰
   â”œâ”€ æ•°æ®é›†ç®¡ç†
   â”œâ”€ æ‰¹é‡è¯„ä¼°
   â””â”€ å¤šç»´åº¦æŒ‡æ ‡

3. ğŸ“ˆ Monitoringï¼ˆç›‘æ§ï¼‰
   â”œâ”€ ç”Ÿäº§ç¯å¢ƒå®æ—¶è¿½è¸ª
   â”œâ”€ å‘Šè­¦ä¸å¼‚å¸¸æ£€æµ‹
   â””â”€ æˆæœ¬ä¸æ€§èƒ½åˆ†æ
```

**ä¸å…¶ä»–å·¥å…·å¯¹æ¯”**ï¼š

| å·¥å…· | è¿½è¸ª | è¯„ä¼° | ç›‘æ§ | LangChain é›†æˆ |
|------|------|------|------|----------------|
| LangSmith | âœ… åŸç”Ÿ | âœ… å†…ç½® | âœ… å®æ—¶ | âœ… æ— ç¼ |
| Weights & Biases | âš ï¸ é€šç”¨ | âœ… ML è¯„ä¼° | âœ… å®éªŒè¿½è¸ª | âš ï¸ éœ€é€‚é… |
| MLflow | âš ï¸ é€šç”¨ | âš ï¸ ML æŒ‡æ ‡ | âœ… æ¨¡å‹ç®¡ç† | âš ï¸ éœ€é€‚é… |
| è‡ªå»ºæ—¥å¿— | âŒ æ‰‹åŠ¨ | âŒ æ—  | âš ï¸ éœ€è‡ªå»º | âš ï¸ å¤æ‚ |

---

## 22.2 Tracing é…ç½®

### 22.2.1 ç¯å¢ƒå˜é‡é…ç½®

æœ€ç®€å•çš„å¯ç”¨æ–¹å¼ï¼šè®¾ç½®ç¯å¢ƒå˜é‡

```bash
# 1. å¯ç”¨ Tracing V2ï¼ˆå¿…éœ€ï¼‰
export LANGCHAIN_TRACING_V2=true

# 2. è®¾ç½® API Keyï¼ˆå¿…éœ€ï¼‰
export LANGCHAIN_API_KEY="lsv2_pt_..."  # ä» https://smith.langchain.com è·å–

# 3. è®¾ç½®é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º "default"ï¼‰
export LANGCHAIN_PROJECT="my-rag-app"

# 4. è®¾ç½® Endpointï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå®˜æ–¹æœåŠ¡å™¨ï¼‰
export LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
```

**éªŒè¯é…ç½®**ï¼š

```python
import os

print("Tracing Enabled:", os.getenv("LANGCHAIN_TRACING_V2"))
print("API Key:", os.getenv("LANGCHAIN_API_KEY")[:20] + "...")
print("Project:", os.getenv("LANGCHAIN_PROJECT"))
```

### 22.2.2 ä»£ç ä¸­åŠ¨æ€é…ç½®

æ›´çµæ´»çš„æ–¹å¼ï¼šåœ¨ä»£ç ä¸­æ§åˆ¶

```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# æ–¹æ³• 1ï¼šå…¨å±€å¯ç”¨
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "lsv2_pt_..."
os.environ["LANGCHAIN_PROJECT"] = "debug-session"

# æ–¹æ³• 2ï¼šä»…å¯¹ç‰¹å®šé“¾å¯ç”¨ï¼ˆæ¨èï¼‰
from langchain_core.tracers import LangChainTracer

tracer = LangChainTracer(project_name="experiment-v2")

chain = (
    ChatPromptTemplate.from_template("Tell me a joke about {topic}")
    | ChatOpenAI(model="gpt-4")
)

# ä»…æ­¤æ¬¡è°ƒç”¨å¯ç”¨ tracing
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": [tracer]}
)

# å…¶ä»–è°ƒç”¨ä¸ä¼šè¢«è¿½è¸ª
result2 = chain.invoke({"topic": "Python"})  # ä¸è¿½è¸ª
```

### 22.2.3 é¡¹ç›®ç®¡ç†æœ€ä½³å®è·µ

**é¡¹ç›®å‘½åç­–ç•¥**ï¼š

```python
# æŒ‰ç¯å¢ƒåŒºåˆ†
os.environ["LANGCHAIN_PROJECT"] = "production"  # ç”Ÿäº§
os.environ["LANGCHAIN_PROJECT"] = "staging"     # æµ‹è¯•
os.environ["LANGCHAIN_PROJECT"] = "dev-alice"   # å¼€å‘

# æŒ‰åŠŸèƒ½åŒºåˆ†
os.environ["LANGCHAIN_PROJECT"] = "rag-customer-support"
os.environ["LANGCHAIN_PROJECT"] = "agent-code-gen"
os.environ["LANGCHAIN_PROJECT"] = "chatbot-hr"

# æŒ‰å®éªŒåŒºåˆ†
os.environ["LANGCHAIN_PROJECT"] = "exp-gpt4-vs-claude"
os.environ["LANGCHAIN_PROJECT"] = "exp-prompt-v3"
```

**åŠ¨æ€åˆ‡æ¢é¡¹ç›®**ï¼š

```python
from contextlib import contextmanager

@contextmanager
def langsmith_project(project_name: str):
    """ä¸´æ—¶åˆ‡æ¢ LangSmith é¡¹ç›®"""
    old_project = os.getenv("LANGCHAIN_PROJECT")
    os.environ["LANGCHAIN_PROJECT"] = project_name
    try:
        yield
    finally:
        if old_project:
            os.environ["LANGCHAIN_PROJECT"] = old_project
        else:
            os.environ.pop("LANGCHAIN_PROJECT", None)

# ä½¿ç”¨ç¤ºä¾‹
with langsmith_project("experiment-2024-01"):
    result = chain.invoke({"topic": "LLM"})
    # æ­¤è°ƒç”¨ä¼šè®°å½•åˆ° "experiment-2024-01" é¡¹ç›®
```

### 22.2.4 ç¦ç”¨ Tracingï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¯èƒ½éœ€è¦é€‰æ‹©æ€§ç¦ç”¨ï¼š

```python
# å…¨å±€ç¦ç”¨
os.environ["LANGCHAIN_TRACING_V2"] = "false"

# æˆ–åˆ é™¤ç¯å¢ƒå˜é‡
os.environ.pop("LANGCHAIN_TRACING_V2", None)

# å¯¹å•æ¬¡è°ƒç”¨ç¦ç”¨
result = chain.invoke(
    {"topic": "AI"},
    config={"callbacks": []}  # ç©º callbacks åˆ—è¡¨
)
```

---

## 22.3 Trace ç»“æ„è§£æ

### 22.3.1 Runï¼ˆè¿è¡Œï¼‰ï¼šåŸºæœ¬å•ä½

æ¯æ¬¡ LangChain ç»„ä»¶æ‰§è¡Œéƒ½ä¼šç”Ÿæˆä¸€ä¸ª **Run**ï¼š

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4")
result = llm.invoke("Hello!")
# â†‘ è¿™ä¼šç”Ÿæˆä¸€ä¸ª "llm" ç±»å‹çš„ Run
```

**Run çš„æ ¸å¿ƒå±æ€§**ï¼š

```python
{
    "id": "run-abc123...",           # å”¯ä¸€æ ‡è¯†
    "name": "ChatOpenAI",             # ç»„ä»¶åç§°
    "run_type": "llm",                # ç±»å‹ï¼šllm/chain/tool/retriever
    "start_time": "2024-01-20T10:30:00Z",
    "end_time": "2024-01-20T10:30:02Z",
    "inputs": {"messages": [...]},    # è¾“å…¥æ•°æ®
    "outputs": {"generations": [...]}, # è¾“å‡ºæ•°æ®
    "error": null,                    # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    "extra": {
        "metadata": {...},            # è‡ªå®šä¹‰å…ƒæ•°æ®
        "tags": ["gpt-4", "chat"],    # æ ‡ç­¾
    },
    "parent_run_id": null,            # çˆ¶ Run IDï¼ˆåµŒå¥—æ—¶æœ‰å€¼ï¼‰
    "child_runs": [],                 # å­ Run åˆ—è¡¨
}
```

### 22.3.2 Run ç±»å‹è¯¦è§£

LangSmith æ”¯æŒ 5 ç§ä¸»è¦ Run ç±»å‹ï¼š

<div data-component="TraceTreeVisualizer"></div>

**1. Chain Run**

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

chain = (
    ChatPromptTemplate.from_template("Translate to {language}: {text}")
    | ChatOpenAI()
)

result = chain.invoke({"language": "French", "text": "Hello"})
# â†‘ ç”Ÿæˆä¸€ä¸ª Chain Runï¼ŒåŒ…å« 2 ä¸ªå­ Runï¼š
#   â”œâ”€ PromptTemplate Run
#   â””â”€ ChatOpenAI Run
```

**2. LLM Run**

```python
llm = ChatOpenAI(model="gpt-4")
result = llm.invoke("What is 2+2?")
# â†‘ ç”Ÿæˆä¸€ä¸ª LLM Runï¼Œè®°å½•ï¼š
#   - æ¨¡å‹åç§°ï¼ˆgpt-4ï¼‰
#   - Token ä½¿ç”¨é‡
#   - å»¶è¿Ÿ
```

**3. Tool Run**

```python
from langchain.tools import Tool

def search(query: str) -> str:
    return f"Results for: {query}"

search_tool = Tool(
    name="search",
    func=search,
    description="Search the web"
)

result = search_tool.invoke("LangChain")
# â†‘ ç”Ÿæˆä¸€ä¸ª Tool Run
```

**4. Retriever Run**

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma(embedding_function=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

docs = retriever.invoke("What is RAG?")
# â†‘ ç”Ÿæˆä¸€ä¸ª Retriever Runï¼Œè®°å½•ï¼š
#   - æŸ¥è¯¢å†…å®¹
#   - æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡
#   - ç›¸ä¼¼åº¦åˆ†æ•°
```

**5. Embedding Run**

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vectors = embeddings.embed_query("Hello world")
# â†‘ ç”Ÿæˆä¸€ä¸ª Embedding Run
```

### 22.3.3 Spanï¼ˆè·¨åº¦ï¼‰ä¸åµŒå¥—ç»“æ„

å¤æ‚é“¾ä¼šå½¢æˆ**æ ‘å½¢åµŒå¥—ç»“æ„**ï¼š

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# å®šä¹‰é“¾
prompt = ChatPromptTemplate.from_template("Tell me about {topic}")
llm = ChatOpenAI(model="gpt-4")
parser = StrOutputParser()

chain = prompt | llm | parser

result = chain.invoke({"topic": "LangSmith"})
```

**ç”Ÿæˆçš„ Trace æ ‘**ï¼š

```
RunnableSequence (Chain)              â† æ ¹ Run
â”œâ”€ ChatPromptTemplate (Prompt)        â† å­ Run 1
â”œâ”€ ChatOpenAI (LLM)                   â† å­ Run 2
â”‚  â””â”€ OpenAI API Call                 â† å­™ Run
â””â”€ StrOutputParser (Parser)           â† å­ Run 3
```

**Span çš„æ—¶é—´å…³ç³»**ï¼š

```
æ—¶é—´çº¿ï¼š
0ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ 2000ms
â”‚
â”œâ”€ Prompt [0-10ms]        â–“
â”œâ”€ LLM [10-1900ms]        â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“
â”‚  â””â”€ API Call [50-1850ms]  â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“
â””â”€ Parser [1900-2000ms]                    â–“
```

### 22.3.4 Parent-Child å…³ç³»

é€šè¿‡ `parent_run_id` å’Œ `child_runs` æ„å»ºè°ƒç”¨é“¾ï¼š

```python
# ç¤ºä¾‹ï¼šä¸€ä¸ª RAG é“¾çš„ Run æ ‘
{
    "id": "run-root",
    "name": "RetrievalQA",
    "run_type": "chain",
    "child_runs": [
        {
            "id": "run-retriever",
            "name": "VectorStoreRetriever",
            "run_type": "retriever",
            "parent_run_id": "run-root",
            "child_runs": [
                {
                    "id": "run-embedding",
                    "name": "OpenAIEmbeddings",
                    "run_type": "embedding",
                    "parent_run_id": "run-retriever"
                }
            ]
        },
        {
            "id": "run-llm",
            "name": "ChatOpenAI",
            "run_type": "llm",
            "parent_run_id": "run-root"
        }
    ]
}
```

---

## 22.4 Trace æŸ¥çœ‹ä¸åˆ†æ

### 22.4.1 LangSmith UI å¯¼èˆª

è®¿é—® [https://smith.langchain.com](https://smith.langchain.com) åï¼š

**1. Projects é¡µé¢**
- æŸ¥çœ‹æ‰€æœ‰é¡¹ç›®åˆ—è¡¨
- åˆ‡æ¢æ´»åŠ¨é¡¹ç›®
- æŸ¥çœ‹é¡¹ç›®ç»Ÿè®¡ï¼ˆæ€» Run æ•°ã€æˆåŠŸç‡ã€å¹³å‡å»¶è¿Ÿï¼‰

**2. Runs é¡µé¢**
- æŒ‰æ—¶é—´ã€çŠ¶æ€ã€Run ç±»å‹è¿‡æ»¤
- æœç´¢ç‰¹å®š Runï¼ˆæŒ‰ IDã€åç§°ã€Tagï¼‰
- æŸ¥çœ‹ Run åˆ—è¡¨ï¼ˆæ—¶é—´ã€å»¶è¿Ÿã€Tokenã€çŠ¶æ€ï¼‰

**3. Run è¯¦æƒ…é¡µ**
- **Overview**ï¼šRun åŸºæœ¬ä¿¡æ¯
- **Inputs/Outputs**ï¼šå®Œæ•´è¾“å…¥è¾“å‡º
- **Metadata**ï¼šè‡ªå®šä¹‰å…ƒæ•°æ®
- **Timeline**ï¼šæ—¶é—´çº¿è§†å›¾
- **Tree**ï¼šæ ‘å½¢ç»“æ„è§†å›¾

### 22.4.2 æ—¶é—´çº¿è§†å›¾ï¼ˆTimelineï¼‰

<div data-component="SpanTimelineChart"></div>

æ—¶é—´çº¿è§†å›¾å±•ç¤º**æ¯ä¸ª Span çš„æ‰§è¡Œæ—¶é—´**ï¼š

**ç¤ºä¾‹åˆ†æ**ï¼š

```
Chain Execution Timeline (Total: 3.2s)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

0.0s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ 3.2s

Retriever      [0.0s - 1.2s]  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  â”œâ”€ Embedding [0.1s - 0.6s]   â–ˆâ–ˆâ–ˆâ–ˆ
  â””â”€ Search    [0.6s - 1.2s]       â–ˆâ–ˆâ–ˆâ–ˆ

LLM Call       [1.2s - 3.0s]           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  â””â”€ API Wait  [1.3s - 2.9s]            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Parser         [3.0s - 3.2s]                    â–ˆ
```

**æ€§èƒ½ç“¶é¢ˆè¯†åˆ«**ï¼š
- âš ï¸ LLM Call å ç”¨ 56% æ—¶é—´ï¼ˆ1.8s / 3.2sï¼‰
- âœ… Retriever å’Œ Parser è¾ƒå¿«
- ğŸ’¡ ä¼˜åŒ–æ–¹å‘ï¼šè€ƒè™‘ Streaming æˆ–å¼‚æ­¥è°ƒç”¨

### 22.4.3 Tree è§†å›¾ï¼ˆæ ‘å½¢ç»“æ„ï¼‰

æ ‘å½¢è§†å›¾å±•ç¤º**çˆ¶å­å…³ç³»ä¸æ•°æ®æµ**ï¼š

```
ğŸ“¦ RetrievalQA Chain
â”œâ”€ ğŸ“¥ Input: "What is LangChain?"
â”œâ”€ ğŸ” VectorStoreRetriever
â”‚  â”œâ”€ ğŸ“¥ Input: "What is LangChain?"
â”‚  â”œâ”€ ğŸ§® OpenAIEmbeddings
â”‚  â”‚  â”œâ”€ ğŸ“¥ Input: "What is LangChain?"
â”‚  â”‚  â””â”€ ğŸ“¤ Output: [0.123, -0.456, ...]
â”‚  â”œâ”€ ğŸ” Chroma Search
â”‚  â””â”€ ğŸ“¤ Output: [Document(page_content="LangChain is..."), ...]
â”œâ”€ ğŸ¤– ChatOpenAI
â”‚  â”œâ”€ ğŸ“¥ Input: {"context": "...", "question": "..."}
â”‚  â””â”€ ğŸ“¤ Output: "LangChain is a framework for..."
â””â”€ ğŸ“¤ Final Output: "LangChain is a framework for..."
```

**è°ƒè¯•ä»·å€¼**ï¼š
- æŸ¥çœ‹æ¯ä¸€æ­¥çš„å®é™…è¾“å…¥è¾“å‡º
- éªŒè¯æ•°æ®æ˜¯å¦æŒ‰é¢„æœŸæµåŠ¨
- å®šä½é”™è¯¯å‘ç”Ÿçš„å…·ä½“æ­¥éª¤

### 22.4.4 Token æ¶ˆè€—åˆ†æ

<div data-component="TokenUsageBreakdown"></div>

LangSmith è‡ªåŠ¨ç»Ÿè®¡ Token ä½¿ç”¨é‡ï¼š

**Token ç»Ÿè®¡ç¤ºä¾‹**ï¼š

```python
Total Tokens: 1,234
â”œâ”€ Prompt Tokens: 856
â”‚  â”œâ”€ System Prompt: 120
â”‚  â”œâ”€ User Input: 36
â”‚  â””â”€ Retrieved Context: 700  â† å¤§å¤´ï¼
â””â”€ Completion Tokens: 378
```

**æˆæœ¬è®¡ç®—**ï¼š

```
GPT-4 Pricing (2024-01):
- Prompt: $0.03 / 1K tokens
- Completion: $0.06 / 1K tokens

Cost = (856 * 0.03 + 378 * 0.06) / 1000
     = $0.0257 + $0.0227
     = $0.0484 per request
```

**ä¼˜åŒ–å»ºè®®**ï¼š
- ğŸ”§ ç¼©çŸ­ System Prompt
- ğŸ”§ å‡å°‘æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆk=3 â†’ k=2ï¼‰
- ğŸ”§ ä½¿ç”¨ GPT-3.5-Turbo æ›¿ä»£ GPT-4ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰

### 22.4.5 å»¶è¿Ÿçƒ­ç‚¹è¯†åˆ«

**æŒ‰ç»„ä»¶ç±»å‹ç»Ÿè®¡å»¶è¿Ÿ**ï¼š

```python
Component Latency Breakdown:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Retriever:    1.2s  (37.5%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
LLM Call:     1.8s  (56.3%)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Parser:       0.2s  (6.2%)   â–ˆâ–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:        3.2s  (100%)
```

**æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**ï¼š

| ç“¶é¢ˆ | ä¼˜åŒ–æ–¹æ¡ˆ |
|------|----------|
| Retriever æ…¢ | 1. ä½¿ç”¨æ›´å¿«çš„å‘é‡æ•°æ®åº“ï¼ˆFAISSï¼‰<br>2. å‡å°‘æ£€ç´¢æ•°é‡<br>3. æ·»åŠ ç¼“å­˜å±‚ |
| LLM æ…¢ | 1. Streamingï¼ˆç”¨æˆ·æ„ŸçŸ¥æ›´å¿«ï¼‰<br>2. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆGPT-4 Turboï¼‰<br>3. å¼‚æ­¥è°ƒç”¨<br>4. æ‰¹å¤„ç† |
| Embedding æ…¢ | 1. æ‰¹é‡åµŒå…¥<br>2. ç¼“å­˜å¸¸è§æŸ¥è¯¢ |

---

## 22.5 è‡ªå®šä¹‰ Tracing

### 22.5.1 @traceable è£…é¥°å™¨

ä¸ºè‡ªå®šä¹‰å‡½æ•°æ·»åŠ  Tracingï¼š

```python
from langsmith import traceable

@traceable(run_type="custom", name="DataProcessor")
def process_data(data: dict) -> dict:
    """è‡ªå®šä¹‰æ•°æ®å¤„ç†å‡½æ•°"""
    # å¤æ‚çš„ä¸šåŠ¡é€»è¾‘
    processed = {k: v.upper() for k, v in data.items()}
    return processed

# è°ƒç”¨æ—¶è‡ªåŠ¨è¿½è¸ª
result = process_data({"name": "Alice", "city": "NYC"})
```

**ç”Ÿæˆçš„ Trace**ï¼š

```
Custom Run
â”œâ”€ Name: DataProcessor
â”œâ”€ Run Type: custom
â”œâ”€ Input: {"name": "Alice", "city": "NYC"}
â”œâ”€ Output: {"name": "ALICE", "city": "NYC"}
â””â”€ Duration: 0.002s
```

### 22.5.2 åµŒå¥—è‡ªå®šä¹‰ Trace

```python
@traceable(name="Step1-FetchData")
def fetch_data(user_id: str) -> dict:
    return {"user_id": user_id, "name": "Alice"}

@traceable(name="Step2-ValidateData")
def validate_data(data: dict) -> bool:
    return "name" in data and len(data["name"]) > 0

@traceable(name="MainPipeline")
def main_pipeline(user_id: str) -> str:
    data = fetch_data(user_id)      # â† å­ Trace
    valid = validate_data(data)      # â† å­ Trace
    
    if valid:
        return f"Welcome {data['name']}!"
    else:
        return "Invalid data"

# æ‰§è¡Œç”ŸæˆåµŒå¥— Trace
result = main_pipeline("user123")
```

**Trace æ ‘**ï¼š

```
MainPipeline
â”œâ”€ Input: "user123"
â”œâ”€ Step1-FetchData
â”‚  â”œâ”€ Input: "user123"
â”‚  â””â”€ Output: {"user_id": "user123", "name": "Alice"}
â”œâ”€ Step2-ValidateData
â”‚  â”œâ”€ Input: {"user_id": "user123", "name": "Alice"}
â”‚  â””â”€ Output: true
â””â”€ Output: "Welcome Alice!"
```

### 22.5.3 æ·»åŠ  Metadata ä¸ Tags

```python
from langsmith import traceable

@traceable(
    name="UserQuery",
    metadata={"version": "v2.1", "environment": "production"},
    tags=["user-facing", "critical"]
)
def handle_user_query(query: str) -> str:
    # å¤„ç†é€»è¾‘
    return f"Answer to: {query}"

result = handle_user_query("What is LangChain?")
```

**åŠ¨æ€ Metadata**ï¼š

```python
from langsmith import Client
import uuid

@traceable
def process_request(request: dict) -> dict:
    # è·å–å½“å‰ Run
    client = Client()
    run_id = uuid.uuid4()  # å®é™…ä¼šè‡ªåŠ¨ç”Ÿæˆ
    
    # æ·»åŠ åŠ¨æ€å…ƒæ•°æ®
    client.update_run(
        run_id=run_id,
        extra={
            "metadata": {
                "user_id": request.get("user_id"),
                "request_ip": request.get("ip"),
                "timestamp": "2024-01-20T10:30:00Z"
            }
        }
    )
    
    return {"status": "success"}
```

### 22.5.4 é”™è¯¯è¿½è¸ª

```python
@traceable(name="RiskyOperation")
def risky_operation(data: dict) -> dict:
    try:
        if "required_field" not in data:
            raise ValueError("Missing required field")
        
        result = {"processed": data["required_field"].upper()}
        return result
    
    except Exception as e:
        # LangSmith è‡ªåŠ¨è®°å½•å¼‚å¸¸
        raise

# å¤±è´¥çš„è°ƒç”¨ä¼šåœ¨ Trace ä¸­æ˜¾ç¤ºé”™è¯¯
try:
    risky_operation({})  # ç¼ºå°‘ required_field
except ValueError:
    pass
```

**Trace ä¸­çš„é”™è¯¯ä¿¡æ¯**ï¼š

```
RiskyOperation (FAILED)
â”œâ”€ Status: Error
â”œâ”€ Error: ValueError("Missing required field")
â”œâ”€ Stack Trace:
â”‚  File "example.py", line 5, in risky_operation
â”‚    raise ValueError("Missing required field")
â””â”€ Duration: 0.001s
```

### 22.5.5 LangChain é›†æˆçš„é«˜çº§ç”¨æ³•

**ä¸ºé“¾æ·»åŠ è‡ªå®šä¹‰åç§°**ï¼š

```python
from langchain_core.runnables import RunnableConfig

chain = prompt | llm | parser

result = chain.invoke(
    {"topic": "AI"},
    config=RunnableConfig(
        run_name="TranslationChain-v2",  # è‡ªå®šä¹‰ Run åç§°
        tags=["translation", "v2"],       # æ·»åŠ æ ‡ç­¾
        metadata={"user": "alice"}        # æ·»åŠ å…ƒæ•°æ®
    )
)
```

**æ‰¹é‡æ“ä½œçš„ Tracing**ï¼š

```python
inputs = [
    {"topic": "AI"},
    {"topic": "ML"},
    {"topic": "LLM"}
]

# æ¯ä¸ªè¾“å…¥ç”Ÿæˆç‹¬ç«‹çš„ Trace
results = chain.batch(
    inputs,
    config={"tags": ["batch-job", "experiment-1"]}
)
```

---

## 22.6 å®æˆ˜æ¡ˆä¾‹ï¼šè°ƒè¯•å¤æ‚ RAG é“¾

### 22.6.1 é—®é¢˜åœºæ™¯

ä¸€ä¸ªå®¢æœ RAG ç³»ç»Ÿå“åº”ç¼“æ…¢ï¼ˆ>5ç§’ï¼‰ä¸”ç­”æ¡ˆè´¨é‡å·®ã€‚

**åŸå§‹ä»£ç **ï¼š

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate

# åˆå§‹åŒ–ç»„ä»¶
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(
    persist_directory="./customer_kb",
    embedding_function=embeddings
)

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 10}  # â† å¯èƒ½çš„é—®é¢˜ï¼Ÿ
)

template = """You are a customer service agent. 
Use the following context to answer the question. 
If you don't know, say you don't know.

Context: {context}

Question: {question}

Detailed Answer:"""

prompt = PromptTemplate(template=template, input_variables=["context", "question"])

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4", temperature=0),  # â† GPT-4 å¾ˆæ…¢
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt}
)

# å¯ç”¨ Tracing
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "debug-slow-rag"

# æ‰§è¡ŒæŸ¥è¯¢
result = qa_chain.invoke("How do I reset my password?")
```

### 22.6.2 Trace åˆ†æ

æŸ¥çœ‹ LangSmith Trace åå‘ç°ï¼š

**æ—¶é—´çº¿åˆ†æ**ï¼š

```
Total Time: 5.3s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Retriever        [0.0s - 2.1s]  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  â”œâ”€ Embedding   [0.0s - 0.3s]   â–ˆâ–ˆ
  â””â”€ Search      [0.3s - 2.1s]     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â† æ…¢ï¼

LLM Call         [2.1s - 5.2s]               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â† å¾ˆæ…¢ï¼
  â””â”€ API Wait    [2.2s - 5.1s]                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Parser           [5.2s - 5.3s]                              â–ˆ
```

**Token åˆ†æ**ï¼š

```
Prompt Tokens: 3,456  â† å¼‚å¸¸é«˜ï¼
â”œâ”€ System Prompt: 120
â”œâ”€ User Question: 20
â””â”€ Context: 3,316  â† 10 ä¸ªæ–‡æ¡£å¤ªå¤šäº†ï¼

Completion Tokens: 287
```

**é—®é¢˜è¯Šæ–­**ï¼š
1. ğŸ”´ æ£€ç´¢äº† 10 ä¸ªæ–‡æ¡£ï¼ˆk=10ï¼‰ï¼Œå¯¼è‡´ Context è¿‡é•¿
2. ğŸ”´ ä½¿ç”¨ GPT-4ï¼Œå»¶è¿Ÿè¾ƒé«˜
3. ğŸ”´ Chroma æœç´¢è¾ƒæ…¢ï¼ˆå¯èƒ½ç´¢å¼•é—®é¢˜ï¼‰

### 22.6.3 ä¼˜åŒ–æ–¹æ¡ˆ

```python
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA

# ä¼˜åŒ– 1ï¼šåˆ‡æ¢åˆ° FAISSï¼ˆæ›´å¿«ï¼‰
vectorstore = FAISS.load_local(
    "customer_kb_faiss",
    embeddings,
    allow_dangerous_deserialization=True
)

# ä¼˜åŒ– 2ï¼šå‡å°‘æ£€ç´¢æ•°é‡
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}  # 10 â†’ 3
)

# ä¼˜åŒ– 3ï¼šä½¿ç”¨ GPT-3.5-Turboï¼ˆæ›´å¿«æ›´ä¾¿å®œï¼‰
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo", temperature=0),
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt}
)

# é‡æ–°æµ‹è¯•
result = qa_chain.invoke("How do I reset my password?")
```

**ä¼˜åŒ–åçš„ Trace**ï¼š

```
Total Time: 1.2s  (åŸ 5.3sï¼Œæå‡ 77%)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Retriever        [0.0s - 0.3s]  â–ˆâ–ˆâ–ˆâ–ˆ
  â”œâ”€ Embedding   [0.0s - 0.1s]   â–ˆ
  â””â”€ Search      [0.1s - 0.3s]    â–ˆâ–ˆ

LLM Call         [0.3s - 1.1s]      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  â””â”€ API Wait    [0.4s - 1.0s]       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Parser           [1.1s - 1.2s]            â–ˆ
```

**Token åˆ†æ**ï¼š

```
Prompt Tokens: 856  (åŸ 3,456ï¼Œå‡å°‘ 75%)
â”œâ”€ System Prompt: 120
â”œâ”€ User Question: 20
â””â”€ Context: 716  (3 ä¸ªæ–‡æ¡£è€Œé 10 ä¸ª)

Completion Tokens: 198
```

**æˆæœ¬å¯¹æ¯”**ï¼š

```
Before: $0.0484 per request (GPT-4 + 3,743 tokens)
After:  $0.0016 per request (GPT-3.5 + 1,054 tokens)
èŠ‚çœ:   97% æˆæœ¬
```

---

## 22.7 æœ€ä½³å®è·µ

### 22.7.1 ä½•æ—¶å¯ç”¨ Tracingï¼Ÿ

| åœºæ™¯ | æ˜¯å¦å¯ç”¨ | åŸå›  |
|------|----------|------|
| å¼€å‘è°ƒè¯• | âœ… å§‹ç»ˆå¯ç”¨ | å¿«é€Ÿå®šä½é—®é¢˜ |
| å•å…ƒæµ‹è¯• | âš ï¸ é€‰æ‹©æ€§ | é¿å…å¤§é‡æ— ç”¨ Trace |
| é›†æˆæµ‹è¯• | âœ… å¯ç”¨ | éªŒè¯å®Œæ•´æµç¨‹ |
| ç”Ÿäº§ç¯å¢ƒ | âš ï¸ é‡‡æ ·å¯ç”¨ | é¿å…æ€§èƒ½å¼€é”€ï¼ŒæŒ‰ 1-10% é‡‡æ · |
| æ€§èƒ½åŸºå‡† | âŒ ç¦ç”¨ | é¿å… Tracing æœ¬èº«çš„å¼€é”€ |

**ç”Ÿäº§é‡‡æ ·ç¤ºä¾‹**ï¼š

```python
import random

def should_trace() -> bool:
    """10% é‡‡æ ·"""
    return random.random() < 0.1

if should_trace():
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
else:
    os.environ["LANGCHAIN_TRACING_V2"] = "false"

result = chain.invoke(input_data)
```

### 22.7.2 é¡¹ç›®å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
"production-customer-chatbot"
"staging-rag-v2"
"dev-alice-experiment-prompt-v3"

# âŒ ä¸å¥½çš„å‘½å
"test"
"my-project"
"aaa"
```

### 22.7.3 æ ‡ç­¾ä½¿ç”¨ç­–ç•¥

```python
# ä¸ºä¸åŒç±»å‹çš„è¯·æ±‚æ‰“æ ‡ç­¾
tags = []

if request.get("user_type") == "premium":
    tags.append("premium-user")

if request.get("query_type") == "complex":
    tags.append("complex-query")

tags.append(f"version-{app_version}")

result = chain.invoke(
    input_data,
    config={"tags": tags}
)
```

### 22.7.4 æ•æ„Ÿä¿¡æ¯å¤„ç†

```python
from langsmith import traceable

@traceable(
    name="ProcessUserData",
    # éšè—æ•æ„Ÿå­—æ®µ
    hide_inputs=["password", "credit_card"],
    hide_outputs=["api_key"]
)
def process_user_data(data: dict) -> dict:
    # å¤„ç†åŒ…å«æ•æ„Ÿä¿¡æ¯çš„æ•°æ®
    return {
        "status": "success",
        "api_key": "sk-..."  # ä¼šè¢«éšè—
    }
```

---

## æœ¬ç« æ€»ç»“

**æ ¸å¿ƒæ”¶è·**ï¼š

1. âœ… **LangSmith Tracing æ˜¯å¤æ‚é“¾è°ƒè¯•çš„å¿…å¤‡å·¥å…·**
   - å¯è§†åŒ–æ‰§è¡Œè¿‡ç¨‹
   - å®šä½æ€§èƒ½ç“¶é¢ˆ
   - è¿½è¸ª Token æ¶ˆè€—

2. âœ… **Trace ç»“æ„ç†è§£**
   - Runï¼šåŸºæœ¬å•ä½ï¼ˆChainã€LLMã€Toolã€Retrieverï¼‰
   - Spanï¼šæ—¶é—´ç»´åº¦çš„æ‰§è¡Œç‰‡æ®µ
   - åµŒå¥—å…³ç³»ï¼šçˆ¶å­ Run æ ‘

3. âœ… **ä¸‰ç§è§†å›¾äº’è¡¥ä½¿ç”¨**
   - Timelineï¼šæ‰¾æ€§èƒ½ç“¶é¢ˆ
   - Treeï¼šæŸ¥æ•°æ®æµ
   - Metadataï¼šçœ‹ä¸šåŠ¡ä¿¡æ¯

4. âœ… **è‡ªå®šä¹‰ Tracing æ‰©å±•èƒ½åŠ›**
   - @traceable è£…é¥°å™¨
   - Metadata ä¸ Tags
   - é”™è¯¯è¿½è¸ª

5. âœ… **ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ**
   - é‡‡æ ·ç­–ç•¥ï¼ˆ1-10%ï¼‰
   - é¡¹ç›®å‘½åè§„èŒƒ
   - æ•æ„Ÿä¿¡æ¯ä¿æŠ¤

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼š
Chapter 23 å°†æ·±å…¥å­¦ä¹  **LangSmith è¯„ä¼°ç³»ç»Ÿ**ï¼ŒæŒæ¡æ•°æ®é›†ç®¡ç†ã€æ‰¹é‡è¯„ä¼°ã€è‡ªå®šä¹‰ Evaluatorã€LLM-as-Judge ç­‰æŠ€æœ¯ï¼Œå»ºç«‹ LLM åº”ç”¨çš„è´¨é‡ä¿éšœä½“ç³»ã€‚

---

## ç»ƒä¹ é¢˜

### åŸºç¡€ç»ƒä¹ 

1. **å¯ç”¨ Tracing**ï¼šä¸ºç°æœ‰çš„èŠå¤©æœºå™¨äººé¡¹ç›®å¯ç”¨ LangSmith Tracingï¼Œè§‚å¯Ÿæ‰§è¡Œæµç¨‹ã€‚

2. **æ€§èƒ½åˆ†æ**ï¼šæ‰¾å‡ºä½ çš„åº”ç”¨ä¸­æœ€æ…¢çš„ 3 ä¸ªæ­¥éª¤ï¼Œä½¿ç”¨ Timeline è§†å›¾åˆ†æã€‚

3. **Token ä¼˜åŒ–**ï¼šç»Ÿè®¡ä½ çš„åº”ç”¨çš„å¹³å‡ Token ä½¿ç”¨é‡ï¼Œå°è¯•ä¼˜åŒ–æç¤ºè¯å‡å°‘æ¶ˆè€—ã€‚

### è¿›é˜¶ç»ƒä¹ 

4. **è‡ªå®šä¹‰ Trace**ï¼šä¸ºè‡ªå®šä¹‰çš„æ•°æ®å¤„ç†å‡½æ•°æ·»åŠ  @traceableï¼Œè®°å½•å…³é”®ä¸šåŠ¡æŒ‡æ ‡ã€‚

5. **é”™è¯¯è°ƒè¯•**ï¼šæ•…æ„å¼•å…¥ä¸€ä¸ªé”™è¯¯ï¼ˆå¦‚ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼‰ï¼Œè§‚å¯Ÿ LangSmith å¦‚ä½•è®°å½•é”™è¯¯ä¿¡æ¯ã€‚

6. **å¤šé¡¹ç›®ç®¡ç†**ï¼šåˆ›å»º 3 ä¸ªä¸åŒçš„é¡¹ç›®ï¼ˆdevã€stagingã€productionï¼‰ï¼Œä¸ºä¸åŒç¯å¢ƒçš„è¯·æ±‚è·¯ç”±åˆ°ä¸åŒé¡¹ç›®ã€‚

### æŒ‘æˆ˜ç»ƒä¹ 

7. **é‡‡æ ·ç­–ç•¥**ï¼šå®ç°ä¸€ä¸ªæ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼šå¯¹å¤±è´¥çš„è¯·æ±‚ 100% è¿½è¸ªï¼ŒæˆåŠŸçš„è¯·æ±‚ 5% è¿½è¸ªã€‚

8. **æˆæœ¬ç›‘æ§**ï¼šç¼–å†™è„šæœ¬ï¼Œä» LangSmith API æå–è¿‡å»ä¸€å‘¨çš„ Token ä½¿ç”¨é‡ï¼Œç”Ÿæˆæˆæœ¬æŠ¥å‘Šã€‚

9. **æ€§èƒ½å¯¹æ¯”å®éªŒ**ï¼šå¯¹åŒä¸€ä¸ªä»»åŠ¡ä½¿ç”¨ GPT-4 å’Œ GPT-3.5ï¼Œé€šè¿‡ Tracing å¯¹æ¯”å»¶è¿Ÿå’Œæˆæœ¬å·®å¼‚ã€‚

---

## æ‰©å±•é˜…è¯»

- [LangSmith Documentation - Tracing](https://docs.smith.langchain.com/tracing)
- [LangSmith API Reference](https://api.smith.langchain.com/docs)
- [LangChain Callbacks](https://python.langchain.com/docs/modules/callbacks/)
- [Observability Best Practices for LLM Applications](https://blog.langchain.dev/observability-best-practices/)
